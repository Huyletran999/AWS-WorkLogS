[{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/4-eventparticipated/4.1-event1/","title":"Sự kiện 1","tags":[],"description":"","content":"Báo cáo tóm tắt: “Vòng đời phát triển định hướng AI: Tái định hình Kỹ thuật phần mềm” Mục tiêu sự kiện Khám phá sự chuyển đổi mang tính cách mạng trong phát triển phần mềm được thúc đẩy bởi AI tạo sinh. Giới thiệu Vòng đời phát triển định hướng AI (AI-DLC) và các khái niệm cốt lõi của nó. Demo Kiro và Amazon Q Developer Diễn giả Toan Huynh – Specialist SA, PACE My Nguyen - Sr. Prototyping Architect, Amazon Web Services - ASEAN Những điểm nổi bật Tập trung vào khái niệm AI-DLC, một khuôn khổ nơi AI điều phối quy trình phát triển, bao gồm lập kế hoạch, phân rã tác vụ và đề xuất kiến trúc, trong khi các nhà phát triển giữ trách nhiệm cuối cùng về việc xác nhận, ra quyết định và giám sát. - Khái niệm cốt lõi của AI-DLC: Cách tiếp cận này lấy Con người làm trung tâm, với AI đóng vai trò là Cộng tác viên để nâng cao năng lực của nhà phát triển, dẫn đến Tăng tốc độ phân phối (chu kỳ được tính bằng giờ/ngày thay vì tuần/tháng).\n- Quy trình làm việc AI-DLC: Đây là một vòng lặp lặp lại bao gồm các Tác vụ AI (Tạo kế hoạch, Thực hiện kế hoạch, Tìm kiếm sự làm rõ) và Tác vụ con người (Cung cấp sự làm rõ, Thực hiện kế hoạch), trong đó AI liên tục đặt câu hỏi làm rõ và chỉ thực hiện các giải pháp sau khi con người xác nhận.\n- Các giai đoạn AI-DLC: Vòng đời được chia thành Khởi tạo, Xây dựng và Vận hành. Mỗi giai đoạn xây dựng ngữ cảnh phong phú hơn cho giai đoạn tiếp theo:\nKhởi tạo (Inception): Bao gồm xây dựng ngữ cảnh, mô tả chi tiết ý định với User Stories và lập kế hoạch với các Đơn vị công việc (Units of Work).\nXây dựng (Construction): Liên quan đến Mô hình hóa miền (Domain Modeling), tạo mã và kiểm thử, thêm các thành phần kiến trúc và triển khai với IaC \u0026amp; kiểm thử.\nVận hành (Operation): Tập trung vào triển khai trong môi trường production và quản lý sự cố.\n- Những thách thức mà AI-DLC hướng tới giải quyết:\nMở rộng phát triển AI: Các công cụ lập trình AI có thể thất bại với các dự án phức tạp.\nKiểm soát hạn chế: Các công cụ hiện có gây khó khăn trong việc cộng tác và quản lý các tác nhân AI.\nChất lượng mã: Việc duy trì kiểm soát chất lượng khi chuyển từ bằng chứng khái niệm (PoC) sang môi trường production trở nên khó khăn.\nĐi sâu chi tiết: Kiro - IDE AI cho Nguyên mẫu đến Production Kiro, một Môi trường phát triển tích hợp (IDE) ưu tiên AI hỗ trợ AI-DLC, tập trung vào phát triển dựa trên đặc tả (Spec-driven development). - Phát triển dựa trên đặc tả: Kiro chuyển đổi một câu lệnh cấp cao (ví dụ: \u0026ldquo;Tôi muốn tạo một ứng dụng trò chuyện giống Slack\u0026rdquo;) thành các yêu cầu rõ ràng (requirements.md), thiết kế hệ thống (design.md) và các tác vụ riêng biệt (tasks.md), thay đổi căn bản việc phát triển từ \u0026ldquo;viết code theo cảm tính\u0026rdquo; (vibe coding) sang một quy trình có cấu trúc, có thể truy xuất nguồn gốc. Các nhà phát triển cộng tác với Kiro trên các thông số kỹ thuật này, đóng vai trò là nguồn sự thật.\n- Quy trình làm việc tác nhân (Agentic Workflows): Các tác nhân AI của Kiro thực hiện đặc tả trong khi vẫn giữ nhà phát triển con người nắm quyền kiểm soát, với các tính năng chính là:\n+ Kế hoạch thực hiện: Kiro tạo ra một Kế hoạch thực hiện chi tiết với các tác vụ bắt đầu, tác vụ phụ (ví dụ: \u0026ldquo;Triển khai đăng ký người dùng và endpoint đăng nhập\u0026rdquo;, \u0026ldquo;Triển khai phần mềm trung gian JWT\u0026rdquo;) và liên kết chúng lại với các yêu cầu cụ thể để xác nhận.\n+ Agent Hooks: Các hook này ủy quyền các tác vụ cho các tác nhân AI kích hoạt dựa trên các sự kiện như \u0026ldquo;lưu tệp\u0026rdquo;. Chúng tự động thực thi trong nền dựa trên các lời nhắc được xác định trước, giúp mở rộng công việc bằng cách tạo tài liệu, kiểm thử đơn vị hoặc tối ưu hóa hiệu suất mã.\nNhững điểm chính cần ghi nhớ - AI đảm bảo sự sẵn sàng cho Production: Việc Kiro tạo ra các tài liệu thiết kế chi tiết (như sơ đồ luồng dữ liệu và hợp đồng API) và tạo các bài kiểm tra đơn vị trước khi mã được viết, đảm bảo rằng mã do AI tạo ra đã sẵn sàng cho production và có thể bảo trì, không chỉ là một nguyên mẫu nhanh chóng.\n- Kiểm soát của con người thông qua các tạo tác: Các nhà phát triển duy trì quyền kiểm soát không phải bằng cách viết phần lớn mã, mà bằng cách xác nhận và tinh chỉnh các tạo tác—các yêu cầu, thiết kế và kế hoạch tác vụ—trước khi các tác nhân AI thực hiện việc triển khai.\nỨng dụng vào công việc - Tích hợp Amazon Q Developer/Các công cụ tương tự: Tích hợp các trợ lý lập trình AI vào các dự án học thuật của tôi để tự động hóa mã mẫu và các tác vụ chung nhằm tăng năng suất.\n- Tập trung vào các tác vụ giá trị cao: Bằng cách để AI tự động hóa những công việc nặng nhọc không phân biệt, tôi có thể tập trung thời gian vào việc làm chủ các tác vụ sáng tạo, có giá trị cao hơn như Mô hình hóa miền và Thiết kế kiến trúc, vốn là những hoạt động lấy con người làm trung tâm rất quan trọng trong giai đoạn Xây dựng.\nTrải nghiệm sự kiện Việc tham dự sự kiện Vòng đời phát triển định hướng AI: Tái định hình Kỹ thuật phần mềm đã mang lại cái nhìn hấp dẫn về tương lai của phát triển phần mềm. Rõ ràng là AI tạo sinh không chỉ là một trợ lý lập trình; nó đang ở vị thế trở thành người điều phối cốt lõi của toàn bộ quy trình phát triển. Phiên làm việc được cấu trúc tốt, đi từ khái niệm bao quát của AI-DLC đến các bản demo cụ thể của Amazon Q Developer và Kiro. Bản demo của Kiro đặc biệt ấn tượng, cho thấy cách một lời nhắc văn bản đơn lẻ có thể được chuyển đổi thành một kế hoạch phát triển đầy đủ, có thể thực thi và có thể truy xuất nguồn gốc ngay bên trong IDE.\nBài học rút ra Ba thách thức chính với sự phát triển AI hiện tại (mở rộng quy mô, kiểm soát hạn chế và chất lượng mã) làm cho cách tiếp cận có cấu trúc, được con người xác nhận của AI-DLC trở nên vô cùng cần thiết và được cân nhắc kỹ lưỡng. Một số hình ảnh sự kiện "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"SQL to NoSQL: Hiện đại hóa lớp truy cập dữ liệu với Amazon DynamoDB AWS Database Blog Bởi Ramana Mannava, Mahesh Kumar Vemula, và Akber Rizwan Shaik 03 JUL 2025 Chuyên mục: Advanced (300), Amazon DynamoDB, Migration, Technical How-to\nTrong Phần 1 của loạt bài, chúng tôi đã khám phá cách di chuyển hiệu quả từ SQL sang Amazon DynamoDB. Sau khi thiết lập các chiến lược mô hình hóa dữ liệu được thảo luận trong Phần 2, giờ đây chúng tôi xem xét những cân nhắc chính để phân tích và thiết kế bộ lọc, phân trang, các trường hợp biên (edge cases) và các phép tổng hợp, xây dựng trên các mô hình dữ liệu đã thiết kế nhằm tạo ra một lớp truy cập dữ liệu hiệu quả.\nThành phần này kết nối ứng dụng của bạn với các tính năng và khả năng của DynamoDB. Việc chuyển đổi từ các mẫu truy cập dựa trên SQL sang cách tiếp cận điều khiển bằng API của DynamoDB mở ra cơ hội tối ưu hóa cách ứng dụng tương tác với lớp dữ liệu của nó.\nPhần cuối cùng của loạt bài này tập trung vào việc triển khai một lớp trừu tượng hiệu quả và xử lý các mẫu truy cập dữ liệu khác nhau trong DynamoDB.\nThiết kế lại mô hình thực thể Mô hình thực thể, đại diện cho cấu trúc dữ liệu trong ứng dụng của bạn, sẽ cần được thiết kế lại để phù hợp với mô hình dữ liệu của DynamoDB. Điều này có thể bao gồm việc phi chuẩn hóa (de-normalizing) các mô hình và tái cấu trúc các mối quan hệ giữa các thực thể.\nBên cạnh đó, hãy cân nhắc công sức liên quan tới các cấu hình sau:\nChú thích thuộc tính DynamoDB: Gắn chú thích cho các thuộc tính thực thể với các thuộc tính đặc thù của DynamoDB, bao gồm partition key, sort key, thông tin local secondary index (LSI) và thông tin global secondary index (GSI). Ví dụ, khi sử dụng mô hình persistence đối tượng .NET, bạn cần ánh xạ các lớp và thuộc tính với các bảng và thuộc tính DynamoDB. Cấu hình tiền tố khóa: Trong thiết kế một bảng đơn (single table design), bạn có thể phải cấu hình tiền tố cho partition key và sort key trong các mô hình thực thể. Phân tích cách những tiền tố này sẽ được sử dụng để truy vấn trong lớp truy cập dữ liệu của bạn. Đoạn code sau là ví dụ minh họa cho việc cấu hình tiền tố khóa trong các mô hình thực thể:\npublic class Post { private const string PREFIX = \u0026#34;POST#\u0026#34;; public string Id { get; private set; } public string Content { get; private set; } public string AuthorId { get; private set; } public Post(string id, string content, string authorId) { Id = id; Content = content; AuthorId = authorId; } // Property that automatically adds prefix public string PartitionKey =\u0026gt; $\u0026#34;{PREFIX}{Id}\u0026#34;; } // Usage example var post = new Post(\u0026#34;123\u0026#34;, \u0026#34;Hello World\u0026#34;, \u0026#34;USER#456\u0026#34;); var queryKey = post.PartitionKey; // Gets \u0026#34;POST#123\u0026#34; Thiết kế lại quy tắc ánh xạ: Do thay đổi trong mô hình thực thể, các quy tắc ánh xạ hiện có giữa view models của ứng dụng và các mô hình thực thể có thể cần được thiết kế lại.\nThiết kế lớp trừu tượng API DynamoDB Lớp trừu tượng API DynamoDB đóng gói các thao tác DynamoDB bên dưới đồng thời cung cấp cho ứng dụng của bạn một giao diện sạch sẽ. Hãy cùng khám phá các thành phần bạn có thể cần triển khai trong lớp này.\nXử lý lỗi và cơ chế thử lại Các kịch bản lưu lượng cao thường dẫn tới các lỗi tạm thời cần xử lý. Ví dụ, khi nội dung lan truyền mạnh hoặc một bài đăng của người nổi tiếng thu hút sự chú ý đột ngột, bạn có thể gặp ngoại lệ vượt quá throughput. Bạn có thể cần triển khai:\nCơ chế thử lại tự động với exponential backoff cho các lỗi tạm thời. Chuyển dịch ngoại lệ DynamoDB thành các lỗi có ý nghĩa cho ứng dụng. Ghi nhật ký lỗi nhất quán để phục vụ khắc phục sự cố. Xử lý thất bại kiểm tra điều kiện (conditional check failures) trong các cập nhật đồng thời. Quản lý thao tác hàng loạt (Batch operation management) Ứng dụng thường cần xử lý nhiều mục một cách hiệu quả để cung cấp trải nghiệm người dùng tốt. Xem xét các kịch bản như tải một news feed cá nhân hóa kết hợp bài đăng từ nhiều người theo dõi. Bạn có thể cần triển khai:\nTự động chia nhỏ các yêu cầu trong giới hạn của DynamoDB. Xử lý song song để tối ưu hiệu năng. Cơ chế khôi phục cho các thất bại một phần trong batch. Theo dõi tiến độ cho các thao tác chạy dài. Tải dữ liệu liên quan của thực thể (Loading related entity data) Khi di chuyển từ cơ sở dữ liệu quan hệ sang DynamoDB, có một nhận thức phổ biến rằng dữ liệu quan hệ thường được phi chuẩn hóa và việc truy cập dữ liệu liên quan trở nên đơn giản. Tuy nhiên, điều này không phải lúc nào cũng đúng. Mặc dù trong một số trường hợp các quan hệ có thể được mô hình hóa bằng chiến lược single-item modeling, tùy theo chi phí và cân nhắc hiệu năng, các quan hệ có thể được mô hình hóa bằng các chiến lược khác như vertical partitioning hoặc composite sort keys.\nKhi thích nghi với DynamoDB, bạn có thể phải phát triển các phương thức trợ giúp trong lớp trừu tượng của mình để tải dữ liệu quan hệ của một thực thể (navigation properties) một cách hiệu quả. Các phương thức này cần xem xét kiến trúc ứng dụng, mẫu truy cập và chiến lược mô hình hóa dữ liệu.\nVí dụ, trong ứng dụng mạng xã hội của chúng tôi, việc tải các comment cho một bài đăng có thể yêu cầu các phương pháp khác nhau tùy thuộc vào chiến lược mô hình hóa được chọn – từ việc lấy thuộc tính đơn giản trong single-item models đến các thao tác truy vấn trong vertical partitioning.\nĐối với các thực thể liên quan sử dụng chiến lược single-item, có thể không cần logic tải cụ thể vì tất cả dữ liệu được truy xuất trong một thao tác API duy nhất. Tuy nhiên, đối với các chiến lược mô hình khác như vertical partitioning, các phương thức trong lớp trừu tượng của bạn cần xử lý truy vấn hiệu quả dựa trên điều kiện lọc và phân trang. Ví dụ, khi comments được lưu như các item riêng biệt chia sẻ partition key của bài đăng, phương thức phải truy vấn và phân trang các item liên quan một cách hiệu quả. Xây dựng dựa trên khả năng vận hành batch, bạn có thể mở rộng các phương thức này để xử lý tải dữ liệu liên quan cho nhiều mục. Ví dụ, khi tải comments cho nhiều bài đăng, sử dụng BatchGetItem để thực hiện các việc sau: Sử dụng cơ chế batching đã thiết lập để nhóm các yêu cầu. Áp dụng retry và chiến lược xử lý lỗi. Cung cấp giao diện nhất quán cho cả thao tác đơn lẻ và thao tác hàng loạt. Khi sử dụng GSI, bạn có thể cần truy xuất các thuộc tính bổ sung không được bao gồm trong projection của GSI. Thiết kế các chiến lược để tải hiệu quả dữ liệu cần thiết trong khi tối thiểu hóa các cuộc gọi API và tối ưu hóa hiệu năng và chi phí. Phương thức trong lớp trừu tượng của bạn có thể cần cung cấp:\nGiao diện nhất quán để tải dữ liệu liên quan. Tối ưu hóa các cuộc gọi API và chi phí. Đơn giản hóa bảo trì thông qua triển khai tập trung. Đoạn code sau là ví dụ minh họa cho việc tải các navigation properties:\n// Entity with navigation property public class Post { public string Id { get; set; } public string Content { get; set; } public IEnumerable\u0026lt;Comment\u0026gt; Comments { get; set; } } // Interface for loading related data public interface INavigationPropertyManager { Task\u0026lt;IEnumerable\u0026lt;T\u0026gt;\u0026gt; LoadRelatedItemsAsync\u0026lt;T\u0026gt;(string parentId); Task\u0026lt;IDictionary\u0026lt;string, IEnumerable\u0026lt;T\u0026gt;\u0026gt;\u0026gt; LoadRelatedItemsInBatchAsync\u0026lt;T\u0026gt;(IEnumerable\u0026lt;string\u0026gt; parentIds); } // Service using the loader public class PostService { private readonly INavigationPropertyManager _navigationPropertyManager; public PostService(INavigationPropertyManager navigationPropertyManager) { _navigationPropertyManager = navigationPropertyManager; } public async Task\u0026lt;IEnumerable\u0026lt;Comment\u0026gt;\u0026gt; GetPostCommentsAsync(string postId) { return await _navigationPropertyManager.LoadRelatedItemsAsync\u0026lt;Comment\u0026gt;(postId); } } Khi thiết kế các phương thức này, hãy phân tích các mẫu tải hiện tại của ứng dụng và đánh giá liệu việc duy trì các mẫu tương tự trong DynamoDB có thể mang lại lợi ích cho hiệu năng và trải nghiệm người dùng hay không.\nÁnh xạ phản hồi (Response mapping) Khi ứng dụng phát triển, cấu trúc dữ liệu và yêu cầu thay đổi theo thời gian. Ví dụ, khi thêm các tính năng mới như phản ứng (reactions) cho bài đăng ngoài lượt thích đơn giản, hoặc giới thiệu nội dung đa phương tiện phong phú trong hồ sơ người dùng, khả năng tương thích ngược (backward compatibility) trở nên quan trọng. Bạn có thể cần triển khai logic ánh xạ để thực hiện các chức năng sau:\nChuyển các item DynamoDB thành các domain object. Xử lý tương thích ngược khi mô hình dữ liệu tiến hóa. Quản lý giá trị mặc định cho các thuộc tính thiếu. Hỗ trợ các phiên bản khác nhau của cùng một thực thể. Xây dựng biểu thức filter (Filter expression building) Các nhu cầu truy xuất dữ liệu phức tạp thường xuất hiện trong các ứng dụng hiện đại. Ví dụ, khi người dùng muốn tìm bài đăng trong khung thời gian cụ thể có mức tương tác cao, hoặc khi lọc comment dựa trên các mẫu tương tác người dùng. Lớp trừu tượng của bạn có thể cần:\nChuyển đổi tiêu chí tìm kiếm phức tạp thành các biểu thức filter DynamoDB. Xử lý nhiều điều kiện filter một cách động. Quản lý expression attribute names và values. Hỗ trợ lọc thuộc tính lồng nhau. Triển khai phân trang (Pagination implementation) Việc điều hướng dữ liệu hiệu quả quan trọng đối với trải nghiệm người dùng. Xem xét các kịch bản như người dùng cuộn qua news feed vô hạn, hoặc người kiểm duyệt duyệt các comment trên các bài viral. Bạn có thể cần triển khai:\nPhân trang dựa trên token sử dụng LastEvaluatedKey. Cấu hình kích thước trang (page size) có thể tùy chỉnh. Xử lý hiệu quả các tập kết quả lớn. Hành vi phân trang nhất quán trên các truy vấn khác nhau. Đoạn code sau là ví dụ minh họa cho việc phân trang:\n// Enhanced interface adding pagination support public interface INavigationPropertyManager { Task\u0026lt;IEnumerable\u0026lt;T\u0026gt;\u0026gt; LoadRelatedItemsAsync\u0026lt;T\u0026gt;(string parentId); Task\u0026lt;IDictionary\u0026lt;string, IEnumerable\u0026lt;T\u0026gt;\u0026gt;\u0026gt; LoadRelatedItemsInBatchAsync\u0026lt;T\u0026gt;(IEnumerable\u0026lt;string\u0026gt; parentIds); // method for paginated loading Task\u0026lt;PagedResult\u0026lt;T\u0026gt;\u0026gt; LoadRelatedItemsPagedAsync\u0026lt;T\u0026gt;(string parentId, PaginationOptions options); } public class PaginationOptions { public int PageSize { get; set; } = 20; public string ExclusiveStartKey { get; set; } } public class PagedResult\u0026lt;T\u0026gt; { public IEnumerable\u0026lt;T\u0026gt; Items { get; set; } public string LastEvaluatedKey { get; set; } } // With pagination support public class PostService { private readonly INavigationPropertyManager _navigationPropertyManager; public PostService(INavigationPropertyManager navigationPropertyManager) { _navigationPropertyManager = navigationPropertyManager; } public async Task\u0026lt;PagedResult\u0026lt;Comment\u0026gt;\u0026gt; GetPostCommentsPagedAsync(string postId, int pageSize = 20, string nextToken = null) { var options = new PaginationOptions { PageSize = pageSize, ExclusiveStartKey = nextToken }; return await _navigationPropertyManager.LoadRelatedItemsPagedAsync\u0026lt;Comment\u0026gt;(postId, options); } } Mã hóa dữ liệu (Data encryption) Bảo vệ dữ liệu nhạy cảm của người dùng là điều tối quan trọng trong các ứng dụng hiện đại. Bạn có thể cần triển khai:\nMã hóa phía client sử dụng AWS Database Encryption SDK bên cạnh mã hóa phía server do DynamoDB cung cấp. Mã hóa chọn lọc các thuộc tính. Xử lý lỗi cho các thao tác mã hóa. Observability (Quan sát/Giám sát) Giám sát sức khỏe ứng dụng và hiệu năng là điều cần thiết. Hãy xem xét giám sát các chỉ số Amazon CloudWatch sau:\nTheo dõi độ trễ request: Giám sát các chỉ số DynamoDB như SuccessfulRequestLatency, và tạo các metric tùy chỉnh cho TransactionConflict và ConditionalCheckFailedRequests. Tiêu thụ capacity: Theo dõi ConsumedReadCapacityUnits và ConsumedWriteCapacityUnits. Tỷ lệ lỗi và các mẫu lỗi: Giám sát ConditionalCheckFailedRequests, SystemErrors, UserErrors. Hiệu năng truy vấn: Theo dõi ThrottledRequests, ScannedCount hoặc Count, thời gian lọc phía client, và độ trễ cuộc gọi dịch vụ bên ngoài. Quản lý giao dịch (Transaction management) Duy trì tính nhất quán dữ liệu là điều quan trọng trong nhiều kịch bản. Bạn có thể cần:\nXử lý các thao tác giao dịch. Quản lý timeout và xung đột. Logic bù trừ (compensation) cho các giao dịch thất bại. Xử lý bộ lọc (Handling filters) Sau khi bạn thiết kế lớp trừu tượng API DynamoDB với các thao tác cơ bản và khả năng tải dữ liệu, hãy phân tích cách thích nghi các mẫu truy vấn hiện có để phù hợp với cách truy vấn của DynamoDB.\nTrong khi các cơ sở dữ liệu quan hệ sử dụng trình tối ưu hóa truy vấn cho các điều kiện WHERE, DynamoDB trao quyền cho nhà phát triển kiểm soát chính xác luồng thực thi truy vấn. DynamoDB xử lý truy vấn theo hai bước:\nĐầu tiên, nó truy xuất các item khớp với key condition expression dựa trên partition và sort keys. Sau đó, trước khi trả kết quả, nó áp dụng filter expressions lên các thuộc tính không phải khóa. Mặc dù filter expressions không giảm tiêu thụ RCU vì toàn bộ tập kết quả vẫn được đọc trước khi lọc, chúng giảm chi phí truyền tải dữ liệu và cải thiện hiệu năng ứng dụng bằng cách lọc dữ liệu ở cấp độ dịch vụ DynamoDB.\nXử lý các yêu cầu lọc phức tạp (Handling complex filter requirements) Khả năng biểu thức linh hoạt của DynamoDB xử lý nhiều kịch bản lọc trực tiếp, và bạn có thể triển khai lọc phía client cho bất kỳ yêu cầu bổ sung nào. Một vài ví dụ bao gồm:\nCác hàm hoặc phương thức không được hỗ trợ: Khi làm việc với các bộ lọc tham chiếu đến các hàm hệ thống (như SUBSTRING, CONCAT, DATEADD, DATEDIFF), hãy truy xuất dữ liệu từ DynamoDB và áp dụng các bộ lọc chuyên biệt này ở lớp ứng dụng. Tải dữ liệu thực thể liên quan: Đối với các truy vấn lọc dựa trên thuộc tính của các thực thể liên quan, ứng dụng có thể cần tải dữ liệu từ nhiều bảng DynamoDB hoặc các bộ sưu tập item và áp dụng lọc tại lớp ứng dụng. Tích hợp với nguồn dữ liệu bên ngoài: Trong kiến trúc microservice, lọc có thể yêu cầu dữ liệu từ các dịch vụ hoặc cơ sở dữ liệu khác. Hãy xem xét trường hợp sử dụng truy xuất comment bài đăng theo tác giả đang hoạt động (active) và điểm sentiment, yêu cầu dữ liệu từ dịch vụ người dùng ngoài và cơ sở dữ liệu phân tích:\nOriginal SQL Query demonstrating filters across different data sources:\nSELECT c.*, u.name, u.profile_pic, u.status, m.sentiment_score FROM comments c JOIN users u ON c.user_id = u.id JOIN comment_analytics m ON c.id = m.comment_id WHERE c.post_id = \u0026#39;123\u0026#39; AND c.created_at \u0026gt; DATEADD(year, -1, GETUTCDATE()) AND u.status = \u0026#39;ACTIVE\u0026#39; AND m.sentiment_score \u0026gt; 0.8 Mã C# minh họa:\npublic class PostCommentService { // ... Initialize readonly fields ... public async Task\u0026lt;IEnumerable\u0026lt;Comment\u0026gt;\u0026gt; GetPostCommentsAsync( string postId, DateTime startDate, double minSentimentScore) { // Step 1: Query DynamoDB for comments var comments = await _dynamoDbContext.QueryAsync\u0026lt;Comment\u0026gt;(postId, QueryOperator.GreaterThanOrEqual, new [] { startDate.ToString(\u0026#34;yyyy-MM-dd\u0026#34;) }).GetRemainingAsync(); // Step 2: Get user details and filter by active status var userIds = comments.Select(c =\u0026gt; c.UserId).Distinct(); var userDetails = await _userService.GetUserDetailsAsync(userIds); comments = comments.Where(c =\u0026gt; userDetails[c.UserId].Status == \u0026#34;ACTIVE\u0026#34;); // Step 3: Apply sentiment score filter from analytics var commentIds = comments.Select(c =\u0026gt; c.CommentId); var sentimentScores = await _analyticsDb.GetSentimentScoresAsync(commentIds); return comments.Where(c =\u0026gt; sentimentScores[c.CommentId] \u0026gt; minSentimentScore); } } Khi phân tích các truy vấn hiện có, hãy xác định các kịch bản yêu cầu lọc phía client và đánh giá tác động hiệu năng của chúng. Xử lý phân trang (Handling pagination) Đánh giá chiến lược phân trang hiện tại của ứng dụng và điều chỉnh cho phù hợp với khả năng của DynamoDB. Trong khi các ứng dụng cơ sở dữ liệu quan hệ thường hiển thị tổng số trang cho người dùng, DynamoDB được tối ưu cho phân trang theo khóa và tiến tới trước (forward-only), sử dụng LastEvaluatedKey.\nVì việc triển khai các tính năng như tổng số bản ghi cần duyệt toàn bộ bảng (full table scans), hãy cân nhắc các giải pháp thay thế như điều hướng theo con trỏ (cursor-based) hoặc các mẫu “load more\u0026quot;. Đối với các ứng dụng cần ngữ cảnh kích thước tập kết quả, hãy cân nhắc triển khai các bộ đếm (counters) thay vì tính tổng thời gian thực. Khi thiết kế phân trang trong lớp truy cập dữ liệu cho DynamoDB, hiểu hành vi phân trang cốt lõi của nó. DynamoDB có thể không trả tất cả các item khớp trong một cuộc gọi API do hai ràng buộc chính: tham số \u0026ldquo;Limit\u0026rdquo; và kích thước đọc tối đa 1 MB.\nPhân tích tác động của lọc: Đánh giá các bộ lọc truy vấn và tính phân phối (cardinality) của dữ liệu. Tối ưu hóa tham số Limit: Hướng tới giá trị limit phù hợp gần với kích thước trang mong muốn trong khi tính đến tác động của bộ lọc. Giám sát hiệu năng: Theo dõi số cuộc gọi API trên mỗi yêu cầu trang và thời gian phản hồi trung bình. Xử lý các trường hợp biên (Handling edge cases) Khi di chuyển lớp truy cập dữ liệu sang DynamoDB, hãy xác định và giải quyết các trường hợp biên liên quan tới các thao tác dữ liệu ở quy mô lớn:\nCác thao tác khối lượng lớn có thể dự đoán được: Xem xét kịch bản một người dùng có hàng triệu người theo dõi đăng nội dung. Các mẫu thiết kế như write sharding hoặc batch processing có thể giúp quản lý những kịch bản này. Các sự kiện tăng đột biến không mong đợi: Ví dụ, khi một bài đăng bất ngờ nhận được lượng tương tác lớn. Những kịch bản này đòi hỏi các chiến lược như scaling động, caching và mô hình bất đồng bộ. Xử lý các phép tổng hợp và dữ liệu phi chuẩn hóa (Handling aggregations and de-normalized data) Quản lý các phép tổng hợp (Managing aggregations) Các cơ sở dữ liệu thường dùng JOIN và GROUP BY cho các phép tổng hợp thời gian thực. Các mẫu truy cập của DynamoDB hỗ trợ các cách tiếp cận khác như duy trì các thực thể aggregation để lưu các giá trị được tiền tính toán.\nXử lý dữ liệu phi chuẩn hóa (Handling de-normalized data) DynamoDB thường yêu cầu phi chuẩn hóa dữ liệu. Ví dụ, chúng tôi lưu trạng thái người dùng trực tiếp trên các thực thể bài đăng để cho phép lọc hiệu quả. Cách tiếp cận này đánh đổi tăng số thao tác ghi để cải thiện hiệu năng đọc.\nQuản lý cập nhật (Managing updates) Cập nhật đồng bộ (Synchronous updates): Cho các tính năng quan trọng cần tính nhất quán ngay lập tức (ví dụ: dùng giao dịch). Cập nhật bất đồng bộ (Asynchronous updates): Sử dụng Amazon DynamoDB Streams và AWS Lambda cho các cập nhật không cần tính nhất quán ngay lập tức. Xử lý phân tích (Analytical processing) Đối với các truy vấn phân tích phức tạp, hãy cân nhắc các dịch vụ bổ trợ: Amazon Redshift, Zero-ETL integration, Amazon Athena, hoặc Amazon SageMaker Lakehouse.\nKết luận Trong bài viết này, chúng tôi đã khám phá các chiến lược để hiện đại hóa lớp truy cập dữ liệu của ứng dụng cho DynamoDB. Việc chuyển đổi từ các mẫu dựa trên SQL sang cách tiếp cận điều khiển bằng API của DynamoDB đem lại cơ hội tối ưu hóa cách ứng dụng tương tác với dữ liệu của nó. Sự hợp tác chặt chẽ giữa các nhóm cơ sở dữ liệu và ứng dụng giúp tạo ra các giải pháp cân bằng giữa hiệu năng, tối ưu chi phí và khả năng mở rộng.\nVề các tác giả Ramana Kiran Mannava: Chuyên gia Tư vấn Cấp cao tại AWS Professional Services, chuyên sâu về .NET và AWS. Akber Rizwan Shaik: Chuyên gia Tư vấn Cấp cao tại AWS Professional Services. Mahesh Kumar Vemula: Chuyên gia Tư vấn Cấp cao tại AWS Professional Services, đam mê Serverless. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tại trang này, bạn sẽ cần giới thiệu về nhật ký công việc của mình. Bạn đã hoàn thành nó như thế nào? Bạn mất bao nhiêu tuần để hoàn thành chương trình? Bạn đã làm những gì trong những tuần đó?\nThông thường và theo tiêu chuẩn, một nhật ký công việc được thực hiện trong khoảng 3 tháng (suốt thời gian thực tập) với nội dung hàng tuần như sau:\nTuần 1: Làm quen với môi trường làm việc và các kiến thức AWS nền tảng thông qua việc thiết lập tài khoản, hoàn thành các bài lab cốt lõi về VPC và EC2, đồng thời xây dựng trang tài liệu Hugo.\nTuần 2: Nâng cao chuyên môn về mạng và lưu trữ bằng cách cấu hình AWS Transit Gateway, host website tĩnh trên S3 và triển khai các chiến lược sao lưu, khôi phục dữ liệu.\nTuần 3: Tập trung củng cố bảo mật thông qua IAM, KMS và AWS Organizations, đồng thời nâng cao năng lực vận hành với Amazon FSx và tự động hóa bằng Lambda.\nTuần 4: Tìm hiểu các dịch vụ cơ sở dữ liệu AWS và thực hiện thành công việc chuyển đổi cơ sở dữ liệu MSSQL tùy chỉnh sang MySQL bằng Schema Conversion Tool, song song với việc xây dựng đề xuất workshop cho nhóm.\nTuần 5: Thúc đẩy đề xuất workshop thông qua việc tinh chỉnh kiến trúc và thuật toán Lambda, đồng thời làm chủ các quy trình luân chuyển và phân tích dữ liệu sử dụng Amazon Kinesis, Glue và Athena.\nTuần 6: Hoàn thiện đề xuất và kiến trúc workshop bằng cách tích hợp Amazon GuardDuty và EventBridge, đồng thời triển khai tài liệu cập nhật lên GitHub Pages.\nTuần 7: Xây dựng nguyên mẫu quy trình ứng phó sự cố tự động bằng cách tích hợp GuardDuty với EventBridge để gửi thông báo và khắc phục, đồng thời nâng cấp kiến trúc hệ thống.\nTuần 8: Dành thời gian củng cố kiến thức cốt lõi về AWS cho kỳ thi giữa kỳ, đồng thời tinh chỉnh kiến trúc dự án với AWS Step Functions và logic cô lập EC2.\nTuần 9: Hoàn thiện kiến trúc bằng cách áp dụng AWS Step Functions để điều phối và triển khai quy trình ETL serverless để xử lý log CloudTrail cho dashboard tùy chỉnh.\nTuần 10: Kiểm chứng logic phản hồi tự động thông qua việc triển khai quy trình AWS Step Functions, gỡ lỗi bộ phân tích Lambda với các phát hiện thực tế từ GuardDuty và thực thi các kiểm soát bảo mật đặc quyền tối thiểu.\nTuần 11: Tối ưu hóa độ tin cậy của kiến trúc bằng cách tích hợp Amazon SQS và chuẩn bị cho quá trình chuyển đổi sang Infrastructure as Code với AWS CDK, đồng thời củng cố kiến thức bảo mật biên thông qua AWS WAF và CloudFront.\nTuần 12: Chuyển đổi sang Infrastructure as Code bằng việc khởi tạo môi trường AWS CDK và nâng cấp quy trình ứng phó sự cố với khả năng thu thập dữ liệu điều tra tự động.\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.1-week1/","title":"Nhật ký công việc Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Kết nối với các thành viên và mentor của FCJ. Tìm hiểu môi trường làm việc văn phòng. Cài đặt Linux, học cách sử dụng Linux đúng cách. Học các kiến thức cơ bản về AWS, Console và CLI. Hoàn thành module 1 và 2. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Đọc nội quy thực tập\n- Tạo tài khoản AWS - Tìm hiểu AWS là gì - Hoàn thành Module 1 Lab 1 (Học cách tạo tài khoản AWS và quản lý nhóm người dùng) - Hoàn thành Module 1 Lab 7 (Học cách tạo ngân sách sử dụng dịch vụ) - Lab 7-3 (Usage Budget) không thực hiện được, lỗi ở dropdown usage type, không hiển thị gì - Hoàn thành Module 1 Lab 9 (Học về Dịch vụ hỗ trợ AWS, các loại hình, lợi ích và cách yêu cầu hỗ trợ) 08/09/2025 08/09/2025 Tạo tài khoản AWS mới MFA cho tài khoản AWS Tạo nhóm Admin và người dùng Admin Hỗ trợ xác thực tài khoản Khám phá và cấu hình AWS Management Console Tạo Support Case và quản lý case trong AWS T3 - Bắt đầu học lý thuyết Module 2:\n+ Học về VPC (Amazon Virtual Private Cloud)\n+ Học về Subnet, Route table, Security Group\n+ Học về ENI và EIP\n+ Học về VPC Peering và Transit Gateway + Học về Elastic Load Balancing\n+ Học về EC2\n- Thiết lập trang web cho báo cáo workshop - Cài đặt Hugo - Viết thành công nhật ký công việc bằng markdown và Hugo 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ T4 - CN - Hoàn thành các bài lab của Module 2\n- Lab 3: + Học về các tài nguyên cần thiết để tạo và chạy EC2 instance + Cấu hình và chạy thành công các EC2 instance + Kết nối và ping thành công đến các EC2 instance + Tạo NAT Gateway để cho phép kết nối EC2 private - Lab 10: + Học cách tạo và sử dụng keypair để bảo mật + Học cách cấu hình security group để quản lý kết nối + Kết nối và sử dụng thành công RDP qua EC2 + Thiết lập hybrid DNS với Route 53 Resolver (Đang thực hiện, template CloudFormation không tạo security group để tiếp tục bài lab) - Lab 19: + Tạo thành công kết nối VPC Peering + Học cách cấu hình Network ACL + Bật Cross-Peer DNS để phân giải tên miền private - Tải và sử dụng MobaXTerm để kết nối đến EC2 instance - Tải và sử dụng Putty để cấu hình keypair 10/09/2025 12/09/2025 Lab 3 Lab 10 Lab 19 Thành tựu Tuần 1: Đã tạo và bảo mật tài khoản AWS, bao gồm thiết lập ngân sách và tìm hiểu các dịch vụ hỗ trợ. Hoàn thành lý thuyết và các bài lab thực hành về VPC, Subnet, Security Group và Route Table. Triển khai và kết nối thành công các EC2 instance, cấu hình NAT Gateway, và quản lý các kết nối chính sử dụng VPC Peering và AWS Transit Gateway. Có kinh nghiệm thực tế với S3 Bucket (hosting website tĩnh, versioning, replication), AWS Backup, và Storage Gateway. Thiết lập tài liệu: Đã cài đặt Hugo và cấu hình trang web để viết nhật ký công việc bằng markdown. Thành thạo công cụ: Học cách sử dụng MobaXTerm và PuTTY để kết nối và quản lý EC2 instance. Sửa thành công template CloudFormation bị lỗi thời trong bài lab Transit Gateway và học cách quản lý chi phí qua cảnh báo ngân sách. Hoàn thành Module 1 và Module 2, và đã bắt đầu tốt Module 3. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.1-create-iam-role-and-policy-for-lambda/","title":"Cài đặt IAM Role và Policy cho Lambda","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt IAM Role và Policy cho Lambda.\nTạo IAM Role cho Lambda Mở IAM Console\nĐiều hướng tới https://console.aws.amazon.com/iam/ Hoặc: AWS Management Console → Services → IAM Create Role:\nChọn tùy chọn Role trên menu bên trái. Sau đó nhấn Create role. Chọn trusted entity:\nTrusted entity type: AWS Service Use case: Lambda Nhấn \u0026ldquo;Next\u0026rdquo; Đính kèm permissions policies:\nTrong hộp tìm kiếm, nhập AWSLambdaBasicExecutionRole Đánh dấu ô bên cạnh \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên, xem lại, và tạo:\nRole name: Nhập dashboard-query-role Description: Nhập Execution role for Lambda function Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nSau khi tạo, bạn sẽ ở trang chi tiết role Nhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Nhấn \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Tạo inline policy:\nNhấn vào tab \u0026ldquo;JSON\u0026rdquo; Dán policy sau: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AthenaActions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;athena:StartQueryExecution\u0026#34;, \u0026#34;athena:GetQueryExecution\u0026#34;, \u0026#34;athena:GetQueryResults\u0026#34;, \u0026#34;athena:StopQueryExecution\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;GlueCatalogRead\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:GetDatabase\u0026#34;, \u0026#34;glue:GetDatabases\u0026#34;, \u0026#34;glue:GetTable\u0026#34;, \u0026#34;glue:GetTables\u0026#34;, \u0026#34;glue:GetPartitions\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3SourceAndResultAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::vel-athena-results\u0026#34;, \u0026#34;arn:aws:s3:::vel-athena-results/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty/*\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted/*\u0026#34; ] } ] } Nhấn \u0026ldquo;Next\u0026rdquo;\nTên Policy:\nPolicy name: Nhập lambda-query-policy Nhấn \u0026ldquo;Create policy\u0026rdquo; Xác minh tạo role:\nBạn sẽ thấy role với cả managed và inline policies được đính kèm "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.7-dashboard-setup/5.7.1-setup-s3/","title":"Cài đặt S3 Bucket cho Dashboard","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một S3 để chứa các file web và folder. Quan trọng: Thay thế ACCOUNT_ID bằng AWS Account ID của bạn và REGION bằng region mục tiêu (ví dụ: us-east-1) trong tất cả tên bucket.\nTên Bucket static-dashboard-bucket-ACCOUNT_ID-REGION - Lưu trữ các file web và folder đã build\nHướng dẫn tạo Bucket Mở Amazon S3 Console\nĐiều hướng tới https://console.aws.amazon.com/s3/ Hoặc: AWS Management Console → Services → S3 Nhấn vào \u0026ldquo;Create bucket\u0026rdquo;\nCài đặt tạo Bucket:\nGiữ các cài đặt như mặc định: Bucket name: Nhập static-dashboard-bucket-ACCOUNT_ID-REGION Ví dụ: static-dashboard-bucket-123456789012-us-east-1 Ownership: ACLs disabled Block Public Access: Block all public access Bucket versioning: Disable Tags (Tùy chọn): Thêm nếu bạn muốn Encryption: SSE-S3 Bucket key: Enable Nhấn Create bucket Xác minh tạo bucket:\nBạn sẽ thấy một thông báo thành công Bucket sẽ xuất hiện trong danh sách S3 bucket của bạn Tải lên files và folder:\nTruy cập Github để lấy nội dung web và tải lên S3 "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.1-cloudtrail-etl/","title":"Mã CloudTrail ETL","tags":[],"description":"","content":" import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.5-processing-setup/5.5.1-create-kinesis-data-firehose/","title":"Tạo Kinesis Data Firehose","tags":[],"description":"","content":"Tạo Kinesis Data Firehose Delivery Streams Tạo cloudtrail-firehose-stream Mở Kinesis Console → Delivery streams → Create delivery stream\nCấu hình:\nSource: Direct PUT Destination: Amazon S3 Stream name: cloudtrail-firehose-stream S3 bucket: processed-cloudtrail-logs-ACCOUNT_ID-REGION Prefix: processed-cloudtrail/date=!{timestamp:yyyy-MM-dd}/ Error prefix: processed-cloudtrail/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ Buffer size: 10 MB Buffer interval: 300 seconds Compression: GZIP IAM role: CloudTrailFirehoseRole Create delivery stream\nTạo vpc-dns-firehose-stream Stream name: vpc-dns-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: vpc-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: vpc-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Cài đặt buffer/compression giống như trên) Tạo vpc-flow-firehose-stream Stream name: vpc-flow-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: eni-flow-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: eni-flow-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Cài đặt buffer/compression giống như trên) "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.1-create-lambda-excecution-roles/","title":"Tạo Lambda Execution Roles","tags":[],"description":"","content":"Tạo CloudTrailETLLambdaServiceRole Mở IAM Console:\nĐiều hướng đến https://console.aws.amazon.com/iam/ Hoặc: AWS Management Console → Tìm kiếm \u0026ldquo;IAM\u0026rdquo; → Nhấn \u0026ldquo;IAM\u0026rdquo; Điều hướng đến Roles:\nỞ thanh bên trái, nhấn \u0026ldquo;Roles\u0026rdquo; Nhấn \u0026ldquo;Create role\u0026rdquo;\nChọn trusted entity:\nTrusted entity type: Chọn \u0026ldquo;AWS service\u0026rdquo; Use case: Chọn \u0026ldquo;Lambda\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Thêm permissions:\nTrong hộp tìm kiếm, nhập AWSLambdaBasicExecutionRole Đánh dấu vào ô bên cạnh \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên, xem lại, và tạo:\nRole name: Nhập CloudTrailETLLambdaServiceRole Description: Nhập Execution role for CloudTrail ETL Lambda function Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nSau khi tạo, bạn sẽ ở trang chi tiết role Nhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Nhấn \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Tạo inline policy:\nNhấn vào tab \u0026ldquo;JSON\u0026rdquo; Dán policy sau (thay thế ACCOUNT_ID và REGION): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/cloudtrail-firehose-stream\u0026#34; } ] } Nhấn \u0026ldquo;Next\u0026rdquo;\nTên Policy:\nPolicy name: Nhập CloudTrailETLPolicy Nhấn \u0026ldquo;Create policy\u0026rdquo; Xác minh tạo role:\nBạn sẽ thấy role với cả managed và inline policies được đính kèm Tạo các Lambda Roles còn lại Làm theo quy trình tương tự cho mỗi role dưới đây (các bước 3-11):\nGuardDutyETLLambdaServiceRole\nRole name: GuardDutyETLLambdaServiceRole Description: Execution role for GuardDuty ETL Lambda function Managed policy: AWSLambdaBasicExecutionRole Inline policy name: GuardDutyETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:kms:REGION:ACCOUNT_ID:key/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:CreatePartition\u0026#34;, \u0026#34;glue:GetPartition\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:catalog\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:database/security_logs\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:table/security_logs/processed_guardduty\u0026#34; ] } ] } CloudWatchETLLambdaServiceRole\nRole name: CloudWatchETLLambdaServiceRole Description: Execution role for VPC DNS logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-dns-firehose-stream\u0026#34; } ] } CloudWatchENIETLLambdaServiceRole\nRole name: CloudWatchENIETLLambdaServiceRole Description: Execution role for VPC Flow logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchENIETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-flow-firehose-stream\u0026#34; } ] } CloudWatchExportLambdaServiceRole\nRole name: CloudWatchExportLambdaServiceRole Description: Execution role for CloudWatch log export Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchExportPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateExportTask\u0026#34;, \u0026#34;logs:DescribeExportTasks\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34;, \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } ParseFindingsLambdaServiceRole\nRole name: ParseFindingsLambdaServiceRole Description: Execution role for parsing GuardDuty findings Managed policy: AWSLambdaBasicExecutionRole Không cần inline policy IsolateEC2LambdaServiceRole\nRole name: IsolateEC2LambdaServiceRole Description: Execution role for isolating compromised EC2 instances Managed policy: AWSLambdaBasicExecutionRole Inline policy name: IsolateEC2Policy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:DescribeInstances\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } QuarantineIAMLambdaServiceRole\nRole name: QuarantineIAMLambdaServiceRole Description: Execution role for quarantining compromised IAM users Managed policy: AWSLambdaBasicExecutionRole Inline policy name: QuarantineIAMPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:AttachUserPolicy\u0026#34;, \u0026#34;iam:ListAttachedUserPolicies\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::ACCOUNT_ID:user/*\u0026#34;, \u0026#34;arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy\u0026#34; ] } ] } AlertDispatchLambdaServiceRole\nRole name: AlertDispatchLambdaServiceRole Description: Execution role for dispatching alerts via SNS/SES/Slack Managed policy: AWSLambdaBasicExecutionRole Inline policy name: AlertDispatchPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:REGION:ACCOUNT_ID:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ses:SendEmail\u0026#34;, \u0026#34;ses:SendRawEmail\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.3-foundation-setup/5.3.1-set-up-s3-buckets/","title":"Thiết lập S3 buckets","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo 5 S3 buckets phục vụ làm nền tảng cho hệ thống Phản hồi Sự cố Tự động (Auto Incident Response system).\nQuan trọng: Thay thế ACCOUNT_ID bằng AWS Account ID của bạn và REGION bằng region mục tiêu của bạn (ví dụ: us-east-1) trong tất cả các tên bucket.\nTên Bucket incident-response-log-list-bucket-ACCOUNT_ID-REGION - Bucket thu thập log chính processed-cloudtrail-logs-ACCOUNT_ID-REGION - Lưu trữ CloudTrail logs đã xử lý athena-query-results-ACCOUNT_ID-REGION - Lưu trữ kết quả truy vấn Athena processed-cloudwatch-logs-ACCOUNT_ID-REGION - Lưu trữ CloudWatch logs đã xử lý processed-guardduty-findings-ACCOUNT_ID-REGION - Lưu trữ GuardDuty findings đã xử lý Hướng dẫn tạo Bucket Mở Amazon S3 Console Truy cập https://console.aws.amazon.com/s3/ Hoặc: AWS Management Console → Services → S3 Nhấn vào \u0026ldquo;Create bucket\u0026rdquo; Cấu hình chung: Bucket name: Nhập incident-response-log-list-bucket-ACCOUNT_ID-REGION Ví dụ: incident-response-log-list-bucket-123456789012-us-east-1 AWS Region: Chọn region mục tiêu của bạn (ví dụ: US East (N. Virginia) us-east-1) Object Ownership:\nGiữ mặc định: ACLs disabled (recommended) Cài đặt Block Public Access cho bucket này:\nChọn \u0026ldquo;Block all public access\u0026rdquo; Đảm bảo tất cả 4 tùy chọn phụ đều được chọn: ✓ Block public access to buckets and objects granted through new access control lists (ACLs) ✓ Block public access to buckets and objects granted through any access control lists (ACLs) ✓ Block public access to buckets and objects granted through new public bucket or access point policies ✓ Block public and cross-account access to buckets and objects through any public bucket or access point policies Bucket Versioning:\nChọn \u0026ldquo;Enable\u0026rdquo; Tags (tùy chọn):\nThêm tags nếu muốn Ví dụ: Key=Purpose, Value=IncidentResponse Mã hóa mặc định (Default encryption):\nEncryption type: Chọn \u0026ldquo;Server-side encryption with Amazon S3 managed keys (SSE-S3)\u0026rdquo; Bucket Key: Giữ mặc định (Enabled) Cài đặt nâng cao (Advanced settings):\nGiữ nguyên tất cả mặc định Nhấn \u0026ldquo;Create bucket\u0026rdquo;\nXác minh tạo bucket:\nBạn sẽ thấy thông báo thành công Bucket sẽ xuất hiện trong danh sách S3 buckets của bạn Lặp lại các bước 2-10 cho 4 buckets còn lại:\nprocessed-cloudtrail-logs-ACCOUNT_ID-REGION athena-query-results-ACCOUNT_ID-REGION processed-cloudwatch-logs-ACCOUNT_ID-REGION processed-guardduty-findings-ACCOUNT_ID-REGION Xác minh tất cả 5 buckets đã được tạo:\nĐiều hướng đến S3 Console Bạn sẽ thấy tất cả 5 buckets được liệt kê "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan","tags":[],"description":"","content":"Các thành phần hệ thống Phản hồi sự cố và Điều tra số tự động (Auto Incident Response and Forensics) là một kiến trúc sử dụng các dịch vụ tự động hóa để thu thập, xử lý và tự động phản hồi các phát hiện bảo mật, giảm thiểu thời gian cần thiết cho sự can thiệp của con người và hỗ trợ nhân viên bảo mật trong việc trực quan hóa và phân tích log. Hệ thống này được xây dựng dựa trên AWS Security Services (CloudTrail, GuardDuty, VPC Flow Logs, CloudWatch) đưa dữ liệu vào một Data Lake tập trung (S3/Glue/Athena) để phân tích. Tự động hóa cốt lõi được điều khiển bởi AWS EventBridge rules kích hoạt AWS Step Functions workflows, sau đó thực thi AWS Lambda functions để thực hiện các hành động cách ly và cảnh báo. Tổng quan về Workshop Trong workshop này, bạn sẽ triển khai một hệ thống đa giai đoạn để đạt được tự động hóa bảo mật từ đầu đến cuối. Bao gồm:\nThiết lập nền tảng (Foundation Setup): Tạo các S3 buckets và IAM roles chuyên dụng để hỗ trợ tất cả các dịch vụ. Thiết lập giám sát (Monitoring Setup): Kích hoạt và cấu hình các log bảo mật chính (CloudTrail, GuardDuty, VPC Flow Logs) để chuyển dữ liệu đến điểm thu thập log trung tâm. Thiết lập xử lý (Processing Setup): Triển khai Kinesis Firehose, Lambda ETLs, và Glue/Athena tables để chuyển đổi log thô thành một security data lake dễ dàng truy vấn. Thiết lập tự động hóa (Automation Setup): Tạo Isolation Security Group, SNS Topic, Incident Response Lambda Functions, và Step Functions State Machine thực thi các hành động cách ly tự động khi GuardDuty phát hiện các vấn đề. Thiết lập Dashboard (Dashboard Setup): Lưu trữ một giao diện web tĩnh dựa trên S3 an toàn được tăng tốc bởi CloudFront và bảo vệ bởi Cognito để cung cấp cho các nhà phân tích khả năng trực quan hóa thời gian thực của dữ liệu điều tra (forensic data) và khả năng truy vấn trực tiếp qua API Gateway. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"\nHệ thống Ứng phó Sự cố và Điều tra Số Tự động trên AWS Liên kết Proposal: Proposal Doc 1. Tóm tắt Điều hành Nhóm của chúng tôi đang xây dựng một giải pháp ứng phó sự cố và điều tra số tự động như một phần của chương trình thực tập AWS First Cloud Journey. Ý tưởng rất đơn giản—khi một vấn đề bảo mật xảy ra trong AWS, chúng tôi muốn hệ thống phản ứng tự động mà không cần chờ đợi sự can thiệp thủ công.\nChúng tôi đang tạo ra một nền tảng tự động phát hiện các phát hiện bảo mật từ GuardDuty, cô lập các tài nguyên bị ảnh hưởng, thu thập bằng chứng pháp y thông qua việc thu thập dữ liệu toàn diện, và cung cấp các phân tích và bảng điều khiển để các đội bảo mật có thể điều tra những gì đã xảy ra. Mọi thứ được xây dựng bằng Infrastructure-as-Code với AWS CDK, vì vậy khách hàng có thể dễ dàng triển khai nó vào tài khoản AWS của riêng họ.\n2. Báo cáo Vấn đề Vấn đề là gì? Tần suất và sự tinh vi ngày càng tăng của các mối đe dọa mạng đặt ra những rủi ro đáng kể cho các tổ chức dựa vào cơ sở hạ tầng đám mây. Quy trình ứng phó sự cố thủ công thường chậm chạp, không nhất quán và dễ mắc lỗi của con người, có thể dẫn đến thời gian ngừng hoạt động hệ thống kéo dài, vi phạm dữ liệu và tổn thất tài chính. Dự án nhằm giải quyết những thách thức này bằng cách phát triển một hệ thống ứng phó sự cố tự động, đáng tin cậy và có khả năng mở rộng.\nGiải pháp Các trường hợp sử dụng chính bao gồm phát hiện việc sử dụng trái phép thông tin xác thực AWS, xác định các EC2 instance bị xâm nhập, và đảm bảo dữ liệu pháp y được thu thập, xử lý và lưu trữ đúng cách để điều tra. Kiến trúc của chúng tôi tích hợp VPC Flow Logs, CloudTrail, CloudWatch và GuardDuty để phát hiện các mối đe dọa, trong khi Step Functions điều phối quy trình ứng phó tự động bao gồm cô lập EC2, tách khỏi ASG, tạo Snapshot và cách ly IAM. Tất cả bằng chứng được thu thập và xử lý thông qua Lambda ETL tùy chỉnh và Data Firehose, sử dụng Athena để phân tích pháp y. Hệ thống cũng bao gồm alert dispatching, notification bằng email và Slack, và cho chúng ta cái dashboard để analyze và điều tra chuyện đã xảy ra.\nLợi ích và Tỷ suất Lợi nhuận (ROI) Phát hiện mối đe dọa nhanh chóng: Phản ứng tự động giúp giảm thiểu khoảng thời gian dễ bị tổn thương. Thu thập bằng chứng toàn diện: Tự động hóa việc thu thập dữ liệu pháp y, tạo điều kiện cho các cuộc điều tra nhanh hơn. Hiệu quả về chi phí: Tận dụng các dịch vụ serverless của AWS giúp giảm thiểu chi phí cơ sở hạ tầng. Cải thiện tư thế bảo mật: Thông qua giám sát liên tục và cảnh báo thời gian thực. Thông tin chi tiết hữu ích: Các bảng điều khiển và phân tích trao quyền cho các đội bảo mật. Khả năng mở rộng: Thích ứng với các tổ chức có quy mô và khối lượng sự cố khác nhau. 3. Kiến trúc Giải pháp Giải pháp của chúng tôi sử dụng một kiến trúc đa giai đoạn toàn diện cho việc ứng phó sự cố và điều tra số tự động:\nCác Dịch vụ AWS Được Sử dụng Amazon GuardDuty: Liên tục theo dõi các mối đe dọa bảo mật và hoạt động đáng ngờ. AWS Step Functions: Điều phối quy trình ứng phó sự cố. AWS Lambda: Chạy mã tự động hóa để cô lập và xử lý dữ liệu. Amazon EventBridge: Định tuyến các phát hiện từ GuardDuty đến Step Functions. Amazon S3: Lưu trữ bằng chứng pháp y và lưu trữ bảng điều khiển tĩnh. Amazon Athena: Cho phép thực hiện các truy vấn SQL trên các tập dữ liệu pháp y. Amazon API Gateway: Tạo điều kiện giao tiếp giữa bảng điều khiển và backend. Amazon Cognito: Bảo mật quyền truy cập cho người dùng bảng điều khiển. Amazon CloudFront: Tăng tốc độ phân phối bảng điều khiển trên toàn cầu. Amazon SNS \u0026amp; SES: Xử lý thông báo qua tin nhắn và email. AWS CloudTrail: Ghi nhật ký tất cả các hành động để kiểm toán. Amazon CloudWatch: Giám sát và bảng điều khiển. Amazon EC2: Các instance tùy chọn để phân tích. AWS KMS: Quản lý khóa để mã hóa. Amazon Kinesis Data Firehose: Truyền dữ liệu đến S3. Thiết kế Thành phần Lớp Thu thập Dữ liệu \u0026amp; Phát hiện: Thu thập các sự kiện từ VPC Flow Logs, CloudTrail, CloudWatch, EC2 và GuardDuty. Lớp Xử lý Sự kiện: Alert Dispatch, EventBridge định tuyến các phát hiện đến Step Functions; các sự kiện được phân loại theo loại. Điều phối Ứng phó Tự động (Orchestration): Step Functions xử lý phân tích, ra quyết định, cô lập EC2, bảo vệ chấm dứt, tách ASG, tạo snapshot và cách ly IAM. Lớp Xử lý Dữ liệu \u0026amp; Phân tích: ETL pipeline với Lambda và Data Firehose xử lý nhật ký thô vào S3; Athena truy vấn dữ liệu. Lớp Bảng điều khiển \u0026amp; Phân tích: Bảng điều khiển React lưu trữ trên S3 với xác thực Cognito, sử dụng dữ liệu qua API Gateway và Athena. 4. Triển khai Kỹ thuật Các Giai đoạn Triển khai Chúng tôi sử dụng Agile Scrum với các sprint 1 tuần trong vòng 6 tuần:\nSprint 1: Nền tảng \u0026amp; Thiết lập (VPC, Security Groups, Đào tạo). Sprint 2: Điều phối Cốt lõi (Step Functions, Lambda, tích hợp GuardDuty). Sprint 3: Dữ liệu \u0026amp; Phân tích (S3, Athena, ETL pipeline). Sprint 4: Bảng điều khiển \u0026amp; UI (Trang web tĩnh, API Gateway, CloudFront). Sprint 5: Kiểm thử \u0026amp; Tối ưu hóa (Cognito, Kiểm thử hiệu suất, Mô phỏng). Sprint 6: Tài liệu \u0026amp; Bàn giao (Hướng dẫn, Demo, Hoàn thiện). Yêu cầu Kỹ thuật Frontend \u0026amp; Bảng điều khiển: HTML/CSS/JS tùy chỉnh được lưu trữ trên S3, phục vụ qua CloudFront. Backend \u0026amp; Xử lý: Python 3.12 cho Lambda, Step Functions để điều phối. Dữ liệu \u0026amp; Lưu trữ: S3 cho bằng chứng, Athena để truy vấn, Firehose để truyền dữ liệu. Cơ sở hạ tầng: Tất cả được định nghĩa trong AWS CDK (Python). Bảo mật: GuardDuty để phát hiện, IAM cho quyền hạn tối thiểu, KMS để mã hóa. 5. Thời gian biểu \u0026amp; Cột mốc Dòng thời gian Dự án Dòng thời gian Dự án\nTuần 6-7 (Nền tảng \u0026amp; Thiết lập) Hoạt động: Đào tạo nhóm về GuardDuty/Step Functions, đánh giá thiết kế kiến trúc, thiết lập VPC và bảo mật. Sản phẩm bàn giao: Tài liệu kiến trúc v1, hoàn thành đào tạo nhóm, kho lưu trữ GitHub được thiết lập. Tuần 7-9 (Điều phối Cốt lõi) Hoạt động: Phát triển quy trình Step Functions, lập trình hàm Lambda cho tất cả các hành động ứng phó, tích hợp EventBridge, thiết lập SNS/SES, kiểm thử tích hợp. Sản phẩm bàn giao: Định nghĩa máy trạng thái Step Functions, hơn 7 hàm Lambda có tài liệu, tích hợp GuardDuty, hệ thống thông báo, API Gateway. Tuần 10 (Dữ liệu \u0026amp; Phân tích) Hoạt động: Thiết lập lưu trữ pháp y S3, tạo bảng Athena, phát triển đường ống ETL, thư viện truy vấn SQL. Sản phẩm bàn giao: Hơn 15 truy vấn Athena được ghi lại, sách hướng dẫn phân tích pháp y, lưu trữ dữ liệu đã xử lý. Tuần 11 (Bảng điều khiển \u0026amp; UI) Hoạt động: Phát triển bảng điều khiển tĩnh, xác thực Cognito, thiết lập API Gateway, cấu hình CloudFront CDN, tích hợp bảng điều khiển. Sản phẩm bàn giao: Bảng điều khiển lưu trữ trên S3, hệ thống xác thực, giao diện truy vấn, tích hợp kết quả thời gian thực. Tuần 12 (Kiểm thử, Xác thực \u0026amp; Tối ưu hóa) Hoạt động: Kiểm thử thủ công, quét bảo mật bao gồm các kịch bản sự cố mô phỏng (hơn 5 quy trình), kiểm thử hiệu suất, mô phỏng tấn công. Tối ưu hóa dữ liệu với truy vấn Athena và Data Firehose. Sản phẩm bàn giao: Kết quả quét bảo mật, video mô phỏng sự cố, tối ưu hóa dữ liệu. Tuần 13 (Tài liệu \u0026amp; Bàn giao) Hoạt động: Hướng dẫn triển khai, tài liệu API, các phiên chuyển giao kiến thức, demo cuối cùng, dọn dẹp GitHub. Sản phẩm bàn giao: Kho lưu trữ GitHub hoàn chỉnh (công khai), hướng dẫn triển khai, buổi trình diễn workshop trực tiếp. 6. Ước tính Ngân sách Bạn có thể tìm thấy ước tính ngân sách chi tiết trên AWS Pricing Calculator.\nChi phí Cơ sở hạ tầng Chi phí triển khai hàng tháng điển hình (Bậc miễn phí / Quy mô nhỏ): ~$5.01\nGuardDuty: ~$1.80/tháng S3: ~$1.07/tháng KMS: ~$1.12/tháng CloudTrail: ~$0.55/tháng Athena: ~$0.29/tháng Amazon Simple Email Service (SES): ~$0.09/tháng Amazon API Gateway: ~$0.05/tháng Amazon Data firehose: ~$0.04/tháng Lambda, Step Functions, SNS: Thường nằm trong giới hạn Bậc miễn phí cho mức sử dụng thông thường. Lưu ý: Chi phí giả định mức sử dụng thông thường từ 20-150 sự cố mỗi tháng.\n7. Đánh giá Rủi ro Ma trận Rủi ro Tắc nghẽn Hiệu suất: Khối lượng dữ liệu lớn làm chậm các truy vấn. Vi phạm Bảo mật: Xâm phạm chính dữ liệu pháp y. Vượt quá Chi phí: Ghi nhật ký không kiểm soát hoặc vòng lặp vô hạn. Chiến lược Giảm thiểu Hiệu suất: Giám sát Athena/Firehose; tối ưu hóa truy vấn; điều chỉnh tài nguyên động. Bảo mật: Mã hóa (KMS), vai trò IAM nghiêm ngặt, ghi nhật ký kiểm toán. Chi phí: Cảnh báo ngân sách AWS, phát hiện bất thường chi phí, giới hạn tự động mở rộng. Khôi phục sau Thảm họa: Sao lưu, quy trình chuyển đổi dự phòng và các biện pháp dự phòng. 8. Kết quả Dự kiến Cải tiến Kỹ thuật Ứng phó Tự động: Cô lập không chạm (zero-touch) các tài nguyên bị xâm nhập. Tốc độ: Giảm thời gian điều tra từ hàng giờ xuống còn vài phút. Độ tin cậy: Thu thập bằng chứng nhất quán, có thể lặp lại mà không có lỗi của con người. Giá trị Dài hạn Kiến trúc Có thể Mở rộng: Nền tảng cho tự động hóa bảo mật trong tương lai. Kiến thức: Năng lực của nhóm về bảo mật AWS nâng cao và các khái niệm serverless. Tài sản Có thể Tái sử dụng: Một giải pháp có thể triển khai cho các khách hàng hoặc nhóm AWS khác. Trạng thái: Sẵn sàng cho Xem xét \u0026amp; Phê duyệt Mã Dự án: AWS-FCJ-IR-FORENSICS-2025\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 2","tags":[],"description":"","content":"Báo cáo Tóm tắt: “AWS Cloud Mastery Series #1 - AI/ML/GenAI trên AWS” Mục tiêu Sự kiện Giới thiệu về AI/ML/GenAI trên nền tảng AWS Diễn giả Lam Tuan Kiet – Sr DevOps Engineer, FPT Software Danh Hoang Hieu Nghi - AI Engineer, Renova Cloud Dinh Le Hoang Anh - Thực tập sinh Cloud Engineer, First Cloud AI Journey Van Hoang Kha - Community Builder Điểm nhấn chính Khám phá Generative AI với Amazon Bedrock: - Các Mô hình Nền tảng (Foundation Models): Khác biệt so với mô hình truyền thống ở chỗ nó có thể thích ứng cho nhiều tác vụ, cung cấp nhiều mô hình được quản lý hoàn toàn từ các công ty AI hàng đầu như: OpenAI, Claude, Anthropic, v.v. - Kỹ thuật Prompt (Prompt Engineering): Xây dựng và tinh chỉnh các hướng dẫn\nZero-Shot Prompting: Một câu lệnh (prompt) không có bối cảnh hoặc ví dụ trước đó. Few-shot Prompting: Một câu lệnh đi kèm với một vài bối cảnh và ví dụ. Chain of Thought: Một câu lệnh bao gồm các quy trình suy nghĩ và các bước để dẫn đến câu trả lời thực tế. - Retrieval Augmented Generation (RAG): Truy xuất thông tin liên quan từ một nguồn dữ liệu R: Retrieval (Truy xuất) - Lấy thông tin liên quan từ cơ sở tri thức hoặc nguồn dữ liệu. A: Augmented (Tăng cường) - Thêm thông tin đã truy xuất làm bối cảnh bổ sung vào câu lệnh của người dùng trước khi đưa vào mô hình. G: Generation (Tạo sinh) - Phản hồi từ mô hình dựa trên câu lệnh đã được tăng cường. Trường hợp sử dụng: Cải thiện chất lượng nội dung, chatbot theo ngữ cảnh và trả lời câu hỏi, tìm kiếm cá nhân hóa và tóm tắt dữ liệu thời gian thực. - Amazon Titan Embedding: Mô hình hạng nhẹ, vượt trội trong việc chuyển đổi văn bản thành các biểu diễn số (embeddings) cho các tác vụ truy xuất có độ chính xác cao, hỗ trợ hơn 100 ngôn ngữ.\n- Các dịch vụ AI được huấn luyện trước (Pretrained AI Services):\nAmazon Rekognition: Phân tích hình ảnh và video. Amazon Translate: Phát hiện và dịch văn bản. Amazon Textract: Trích xuất văn bản và bố cục từ tài liệu. Amazon Transcribe: Chuyển đổi giọng nói thành văn bản. Amazon Polly: Chuyển đổi văn bản thành giọng nói. Amazon Comprehend: Trích xuất thông tin chi tiết và mối quan hệ từ văn bản. Amazon Kendra: Dịch vụ tìm kiếm thông minh. Amazon Lookout: Phát hiện bất thường trong các chỉ số kinh doanh, thiết bị và hình ảnh. Amazon Personalize: Tùy chỉnh các đề xuất cho người dùng. - Demo: AMZPhoto: Nhận diện khuôn mặt từ hình ảnh sử dụng AI.\n- Amazon Bedrock AgentCore: Một nền tảng tác nhân (agentic) toàn diện được thiết kế để giải quyết các thách thức khi đưa các tác nhân (agents) vào môi trường thực tế (production):\nThực thi và mở rộng mã nguồn của agent một cách an toàn. Kết hợp bộ nhớ (ghi nhớ các tương tác trong quá khứ và học hỏi). Triển khai kiểm soát danh tính và quyền truy cập cho các agent và công cụ. Cung cấp khả năng sử dụng công cụ cho các quy trình làm việc phức tạp. Khám phá và kết nối với các công cụ và tài nguyên tùy chỉnh. Hiểu và kiểm toán mọi tương tác (khả năng quan sát - observability). + Các Dịch vụ Nền tảng: Các dịch vụ này được phân loại để chạy các agent một cách an toàn ở quy mô lớn. + Tăng cường với công cụ \u0026amp; bộ nhớ: Bao gồm Bộ nhớ (Memory), Cổng kết nối (Gateway), Công cụ trình duyệt (Browser tool), và Trình thông dịch mã (Code Interpreter).\n+ Triển khai an toàn ở quy mô lớn: Bao gồm Runtime và Định danh (Identity).\n+ Thu thập thông tin vận hành: Bao gồm Khả năng quan sát (Observability).\n+ Kích hoạt Agent ở quy mô lớn (Kiến trúc): Kết nối với AgentCore Gateway (qua MCP), Bộ nhớ, Định danh, Khả năng quan sát, Trình duyệt và Trình thông dịch mã.\n+ Các Framework để xây dựng Agent: CrewAI, Google ADK, LangGraph/LangChain, LlamaIndex, OpenAI Agents SDK, và Strands Agents SDK.\nBài học rút ra (Key Takeaways) Bedrock là trung tâm GenAI: Amazon Bedrock cung cấp các Mô hình Nền tảng được quản lý hoàn toàn từ các công ty hàng đầu cho nhiều tác vụ khác nhau.\nTùy chỉnh qua Prompt và Dữ liệu: Nhiều cách để đặt câu lệnh (Zero-Shot, Few-shot, CoT) và tận dụng RAG để thêm thông tin giúp mô hình phản hồi tốt hơn.\nEmbeddings hỗ trợ Tìm kiếm: Amazon Titan Embedding là mô hình hạng nhẹ quan trọng để dịch văn bản sang số, giúp đạt độ chính xác cao trong các tác vụ truy xuất (như RAG).\nCác mô hình Pretrained: AWS cung cấp nhiều dịch vụ AI sẵn sàng sử dụng cho các nhu cầu phổ biến, như Rekognition cho hình ảnh và Textract cho tài liệu.\nAgentCore giải quyết vấn đề Production: Amazon Bedrock AgentCore là nền tảng toàn diện mới giúp xử lý các phần khó khăn khi chạy AI Agents ở quy mô lớn (như Bộ nhớ, Định danh và Khả năng quan sát).\nỨng dụng vào công việc Rất hữu ích cho các dự án sau này của nhóm, có thể bao gồm việc sử dụng nhiều hơn các Mô hình Nền tảng AI trong kiến trúc của chúng tôi. Trải nghiệm Sự kiện Các diễn giả nói rất lưu loát và cung cấp nhiều thông tin bổ ích. Hỏi đáp (Q\u0026amp;A): Thành viên trong nhóm đã đặt một câu hỏi hơi ngoài lề nhưng quan trọng đối với dự án của chúng tôi. Hỏi: Dịch vụ SNS trong kiến trúc của chúng tôi được dùng để xử lý các phát hiện từ GuardDuty (GuardDuty Findings) đã gặp tình trạng hơn 1000 cảnh báo xuất hiện cùng lúc, làm thế nào để giải quyết vấn đề này? Đáp: Thêm SQS vào để xếp hàng các sự kiện và đảm bảo không bỏ sót bất kỳ cảnh báo nào. Lọt vào top 10 trong bài Quiz Kahoot cuối sự kiện và được chụp ảnh cùng các diễn giả. Đã tạo một nhóm không chính thức: \u0026ldquo;Mèo Cam Đeo Khăn\u0026rdquo;, một sự hợp tác chung giữa nhóm \u0026ldquo;The Ballers\u0026rdquo; của tôi và \u0026ldquo;Vinhomies\u0026rdquo;. Một số hình ảnh sự kiện "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.2-week2/","title":"Nhật ký công việc Tuần 2","tags":[],"description":"","content":" Mục tiêu Tuần 2: Hiểu và cấu hình AWS Transit Gateway. Tìm hiểu về các dịch vụ lưu trữ AWS (EBS, EFS, S3). Thảo luận về ý tưởng workshop. Thực hành các chiến lược sao lưu và khôi phục dữ liệu. Lưu trữ website tĩnh sử dụng S3 và cấu hình CloudFront. Hoàn thành Module 3. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Lab 20:\n- Tạo thành công AWS Transit Gateway để cho phép kết nối giữa các VPC thông qua một hub chung - Sửa file template, thay đổi loại EC2 instance thành t3.micro vì tài khoản vẫn đang sử dụng gói miễn phí (free tier) 15/09/2025 15/09/2025 T3 - Đã xác minh các kế hoạch chi phí và ngân sách hoạt động đúng dự kiến, nhận thông báo qua email.\nBắt đầu học lý thuyết Module 3 Học về EBS, tính năng Instance store và kiểm tra User Data/Meta Data - Tìm hiểu về Amazon Lightsail Tìm hiểu về Elastic File System (EFS) và FSx - Tìm hiểu về MGN - Hoàn thành các bài lab của Module 3 (Phần 1) - Lab 13: Tạo thành công Backup Plan và Vault cho dữ liệu trong S3 Bucket + Thiết lập thành công thông báo cho các sự kiện Backup + Khôi phục bản backup thành công\n- Hoàn thành các bài lab của Module 3 (Phần 2) - Lab 24: + Đã tạo Storage Gateway + Hoàn thành việc chia sẻ file thành công - Hoàn thành các bài lab của Module 3 (Phần 3) - Lab 57: + Lưu trữ thành công website tĩnh bằng S3 Bucket + Cấu hình thành công các access modifier + Cấu hình tăng tốc Website tĩnh với CloudFront không hoạt động, bỏ qua bước này + Tạo thành công các phiên bản (version) cho bucket + Di chuyển các object giữa các bucket + Sao chép (Replicate) bucket sang các region khác. 16/09/2025 20/09/2025 Lab 13 Lab 24 Lab 57 Thành tựu Tuần 2: Sửa thành công template CloudFormation bị lỗi thời trong bài lab Transit Gateway. Tạo thành công AWS Transit Gateway để kết nối giữa các VPC thông qua một hub chung. Rút ra bài học về việc dọn dẹp tài nguyên và xác minh cảnh báo chi phí/ngân sách (bị trừ $12 credit). Có kinh nghiệm thực tế với S3 Bucket (hosting website tĩnh, versioning, replication). Tạo thành công Backup Plan và Vault sử dụng AWS Backup, bao gồm cả kiểm thử khôi phục. Cấu hình Storage Gateway và hoàn thành nhiệm vụ chia sẻ file. Hoàn thành lý thuyết và bài lab của Module 3. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"GIỚI THIỆU AWS TRUST CENTER Tác giả: Chris Betz Ngày: 14 tháng 2 năm 2025 Danh mục: Announcements, Featured, Security, Identity \u0026amp; Compliance\nTại Amazon Web Services (AWS), việc giành được niềm tin không chỉ là một mục tiêu – đó là một trong những Nguyên tắc Lãnh đạo cốt lõi (Leadership Principles) định hướng cho mọi quyết định mà chúng tôi đưa ra. Là Giám đốc An ninh Thông tin (CISO) của AWS, tôi đã chứng kiến tận mắt cam kết này định hình nên văn hóa, dịch vụ, và cách chúng tôi tương tác hàng ngày với khách hàng.\nKhách hàng chọn AWS thay vì các nhà cung cấp khác bởi vì họ tin tưởng rằng chúng tôi sẽ cung cấp hạ tầng và dịch vụ an toàn nhất, đồng thời minh bạch hoàn toàn về cách dữ liệu được bảo vệ. Để giúp việc tìm kiếm thông tin đó trở nên dễ dàng hơn, chúng tôi ra mắt AWS Trust Center, một nguồn tài nguyên trực tuyến mới chia sẻ cách chúng tôi tiếp cận vấn đề bảo mật tài sản của bạn trên nền tảng đám mây.\nAWS Trust Center là cửa sổ thể hiện các quy trình bảo mật, chương trình tuân thủ và biện pháp bảo vệ dữ liệu của chúng tôi - chứng minh cách chúng tôi làm việc mỗi ngày để xứng đáng với niềm tin của bạn.\nXây dựng trên nền tảng của sự tin cậy Bảo mật luôn là ưu tiên hàng đầu của chúng tôi từ ngày đầu tiên. Khi ra mắt AWS vào năm 2006, chúng tôi đã thiết kế hạ tầng trở thành môi trường điện toán đám mây an toàn nhất có thể. Chúng tôi biết rằng mình không thể chỉ cung cấp mức độ bảo mật tương đương với hạ tầng tại chỗ (on-premises); để giành được niềm tin của khách hàng, chúng tôi phải vượt qua và làm thay đổi các tiêu chuẩn bảo mật nghiêm ngặt nhất của các tổ chức hàng đầu thế giới.\nChúng tôi liên tục củng cố bảo mật trong từng quyết định hàng ngày. Với Trust Center, chúng tôi giúp bạn hiểu rõ hơn về cách chúng tôi bảo vệ khối lượng công việc, dữ liệu, và hỗ trợ bạn đạt được các mục tiêu tuân thủ. Trust Center phản ánh niềm tin của chúng tôi rằng việc cung cấp thông tin dễ tiếp cận hơn sẽ giúp xây dựng và duy trì niềm tin. Dù bạn đang tìm hiểu về kiểm soát trung tâm dữ liệu, kiểm tra chứng nhận tuân thủ, hay xem lại mô hình trách nhiệm chia sẻ (shared responsibility model), bạn đều có thể tìm thấy tất cả thông tin bảo mật và tuân thủ cần thiết tại một địa điểm duy nhất.\nMột nguồn thông tin duy nhất cho bảo mật và tuân thủ Trong Trust Center, bạn sẽ tìm thấy thông tin về cách chúng tôi tiếp cận bảo mật ở mọi cấp độ từ trung tâm dữ liệu vật lý, hạ tầng đám mây, cho đến danh mục dịch vụ AWS. Chúng tôi cung cấp tài liệu về các dịch vụ và công cụ bảo mật, giúp bạn hiểu được cách chúng tôi bảo mật đám mây và cách chúng tôi hỗ trợ bạn bảo mật khối lượng công việc của mình trong đó.\nBạn cũng sẽ tìm thấy thông tin về các chương trình tuân thủ, bao gồm chứng nhận và báo cáo đánh giá (attestations) mà chúng tôi duy trì trên toàn cầu. Điều này đặc biệt hữu ích cho các nhóm làm việc trong ngành được quản lý chặt chẽ, những người cần chứng minh tính tuân thủ với kiểm toán viên và cơ quan quản lý.\nTrust Center còn nhấn mạnh thông tin về thực hành bảo vệ và quyền riêng tư dữ liệu. Khách hàng có thể tìm hiểu cách chúng tôi bảo vệ dữ liệu và quản lý mã hóa. Bên cạnh đó, chúng tôi hiểu rằng khách hàng quan tâm đến việc ai có thể truy cập dữ liệu của họ và trong hoàn cảnh nào. Chúng tôi đã tổng hợp thông tin chi tiết về cơ chế kiểm soát quyền truy cập của nhân viên vận hành (operator access controls), được thiết kế dựa trên nguyên tắc đặc quyền tối thiểu (least privilege).\nBạn sẽ biết thêm về:\nThiết kế không truy cập (zero-access) đối với các dịch vụ cốt lõi như AWS Key Management Service (AWS KMS) và Amazon Elastic Compute Cloud (Amazon EC2). Forward Access Sessions (FAS) - phương thức mã hóa để thực thi ủy quyền của khách hàng. Hệ thống giám sát toàn cầu của chúng tôi. Trust Center cũng cung cấp một vị trí trung tâm để bạn tìm thấy thông tin về trạng thái dịch vụ và các sự kiện bảo mật, giúp bạn duy trì hiệu quả vận hành cao. Bạn có thể cập nhật các bản tin bảo mật, kiểm tra tình trạng dịch vụ theo thời gian thực, và nếu cần báo cáo mối quan ngại bảo mật hoặc tiến hành đánh giá bảo mật, các quy trình đó cũng được trình bày rõ ràng và dễ tìm hơn bao giờ hết. Các tài nguyên được sắp xếp logic và dễ truy cập, với liên kết trực tiếp đến các thỏa thuận, tài liệu và nguồn thông tin giúp bạn đưa ra quyết định chính xác về tư thế bảo mật trên đám mây của mình.\nTrao quyền cho khách hàng thúc đẩy đổi mới an toàn Điều khiến tôi phấn khích nhất về Trust Center chính là khả năng loại bỏ rào cản cho khách hàng. Với thông tin bảo mật chi tiết, liên kết dễ dàng đến tài liệu tuân thủ, và dữ liệu vận hành sẵn có, bạn có thể hành động nhanh hơn và đổi mới với sự tự tin.\nKhi chúng tôi tiếp tục đổi mới và mở rộng các dịch vụ AWS, chúng tôi cam kết nâng cấp Trust Center với những thông tin bảo mật mới nhất. Đây là một tài nguyên sống (living resource) sẽ phát triển song song với đám mây và dịch vụ của chúng tôi.\nDuy trì niềm tin của bạn không chỉ là những gì chúng tôi đã xây dựng hôm nay, mà còn là việc chứng minh – qua cam kết và hành động – rằng chúng tôi xứng đáng trở thành đối tác bảo mật đáng tin cậy của bạn. Đó chính là cam kết của chúng tôi dành cho bạn, và cũng là điều mà AWS Trust Center đại diện.\nKhám phá AWS Trust Center Chúng tôi mời bạn khám phá AWS Trust Center ngay hôm nay, và mong muốn tiếp tục giành được niềm tin của bạn mỗi ngày.\nNếu bạn có phản hồi về bài viết này, vui lòng để lại bình luận trong phần Comments bên dưới. Nếu bạn có câu hỏi liên quan, hãy liên hệ với AWS Support. Về tác giả Chris Betz là Giám đốc An ninh Thông tin (CISO) tại AWS. Ông phụ trách giám sát các nhóm bảo mật và lãnh đạo việc phát triển cũng như triển khai các chính sách bảo mật với mục tiêu quản lý rủi ro và điều chỉnh tư thế bảo mật của công ty phù hợp với các mục tiêu kinh doanh. Chris gia nhập Amazon vào tháng 8 năm 2023 sau khi đảm nhiệm các vị trí CISO và vai trò lãnh đạo bảo mật tại nhiều công ty hàng đầu. Ông hiện sinh sống cùng gia đình tại Bắc Virginia.\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/","title":"Cài đặt IAM Roles và Policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo IAM role và Policy cho Lambda. Sau đó bạn sẽ tạo Lambda Function để thực thi truy vấn.\nNội dung Tạo Lambda Execution Roles và Policy Tạo Lambda Function "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.2-create-lambda-function/","title":"Cài đặt Lambda","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một Lambda sử dụng Python để thực thi truy vấn dùng dịch vụ Athena.\nTạo Lambda Function Mở Lambda Console\nĐiều hướng tới https://console.aws.amazon.com/lambda/ Hoặc: AWS Management Console → Services → Lambda Tạo Function:\nNhấn Create Function Trong mục cài đặt tạo mới, sử dụng cài đặt sau: Chọn Author from scratch Name: dashboard-query Runtime: Python 3.12 Architecture: x86_64 Change default execution role: Use an existing role Chọn dashboard-query-role Nhấn Create Thêm mã nguồn (code):\nTrong code editor copy và paste đoạn mã bên dưới sau đó nhấn Deploy: import boto3 import time import os import json athena = boto3.client(\u0026#39;athena\u0026#39;) RESOURCE_MAP = { \u0026#39;/logs/cloudtrail\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_cloudtrail\u0026#39; }, \u0026#39;/logs/guardduty\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_guardduty\u0026#39; }, \u0026#39;/logs/vpc\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;vpc_logs\u0026#39; }, \u0026#39;/logs/eni_logs\u0026#39;:{ \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;eni_flow_logs\u0026#39; } } OUTPUT_BUCKET_NAME = os.environ.get(\u0026#34;ATHENA_OUTPUT_BUCKET\u0026#34;) REGION = os.environ.get(\u0026#34;REGION\u0026#34;) OUTPUT_BUCKET = f\u0026#39;s3://{OUTPUT_BUCKET_NAME}/\u0026#39; def lambda_handler(event, context): print(\u0026#34;Received event:\u0026#34;, json.dumps(event)) resource_path = event.get(\u0026#39;resource\u0026#39;) config = RESOURCE_MAP.get(resource_path) if not config: return api_response(400, {\u0026#39;error\u0026#39;: f\u0026#39;Unknown resource path: {resource_path}\u0026#39;}) database_name = config[\u0026#39;db\u0026#39;] table_name = config[\u0026#39;table\u0026#39;] query_params = event.get(\u0026#39;queryStringParameters\u0026#39;, {}) or {} if config[\u0026#39;table\u0026#39;] == \u0026#39;processed_cloudtrail\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by eventtime desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;processed_guardduty\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by date desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;vpc_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;eni_flow_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp_str desc\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Querying DB: {database_name}, Table: {table_name}, Output: {OUTPUT_BUCKET}\u0026#34;) try: response = athena.start_query_execution( QueryString=query_string, QueryExecutionContext={\u0026#39;Database\u0026#39;: database_name}, ResultConfiguration={\u0026#39;OutputLocation\u0026#39;: OUTPUT_BUCKET} ) query_execution_id = response[\u0026#39;QueryExecutionId\u0026#39;] status = \u0026#39;RUNNING\u0026#39; while status in [\u0026#39;RUNNING\u0026#39;, \u0026#39;QUEUED\u0026#39;]: response = athena.get_query_execution(QueryExecutionId=query_execution_id) status = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;][\u0026#39;State\u0026#39;] if status in [\u0026#39;FAILED\u0026#39;, \u0026#39;CANCELLED\u0026#39;]: reason = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;].get(\u0026#39;StateChangeReason\u0026#39;, \u0026#39;Unknown\u0026#39;) return api_response(500, {\u0026#39;error\u0026#39;: f\u0026#39;Query Failed: {reason}\u0026#39;}) time.sleep(1) results = athena.get_query_results(QueryExecutionId=query_execution_id) return api_response(200, results) except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return api_response(500, {\u0026#39;error\u0026#39;: str(e)}) def api_response(code, body): return { \u0026#34;statusCode\u0026#34;: code, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET, OPTIONS\u0026#34; }, \u0026#34;body\u0026#34;: json.dumps(body) } "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.10-cleanup/5.10.2-cdk-cleanup/","title":"Dọn dẹp CDK","tags":[],"description":"","content":"Clean up (CDK) Hướng dẫn này đảm bảo bạn hủy bỏ (decommission) chính xác tất cả các tài nguyên được cung cấp bởi AWS CDK stack và dọn dẹp dữ liệu được tạo thủ công để tránh các khoản phí phát sinh.\nGiai đoạn 1: Dọn dẹp dữ liệu thủ công (Trước khi CDK Destroy) CDK tự động xóa hầu hết các tài nguyên nhưng không xóa nội dung trong S3 buckets. Bạn phải làm trống nội dung của các buckets này trước khi chạy lệnh cdk destroy.\nTên Resource Mục đích Hành động yêu cầu incident-response-log-list-bucket Nguồn Log Chính Làm trống nội dung processed-cloudwatch-logs ETL Destination Làm trống nội dung processed-guardduty-findings ETL Destination Làm trống nội dung processed-cloudtrail-logs ETL Destination Làm trống nội dung athena-query-results Kết quả truy vấn Athena Làm trống nội dung aws-incident-response-automation-dashboard React Dashboard S3 Bucket Làm trống nội dung Hướng dẫn làm trống Buckets:\nMở Amazon S3 Console trong trình duyệt của bạn. Đối với mỗi buckets được liệt kê ở trên (tìm tên dựa trên AWS Account ID và Region của bạn): Nhấn vào tên bucket. Điều hướng đến tab \u0026ldquo;Objects\u0026rdquo;. Nhấn nút \u0026ldquo;Empty\u0026rdquo;. Làm theo các lời nhắc để xác nhận xóa vĩnh viễn tất cả các objects. Giai đoạn 2: CDK Stack Destruction Bước này sử dụng CDK CLI để phá hủy tất cả các tài nguyên được cung cấp bởi CloudFormation stack.\nĐảm bảo môi trường ảo (Virtual Environment) đang hoạt động\nNếu bạn đã tắt môi trường Python, hãy kích hoạt lại nó (ví dụ: source .venv/bin/activate). Điều hướng đến Project Root\nĐảm bảo bạn đang ở thư mục chính nơi chứa file cdk.json. Thực thi lệnh Destroy\nChạy lệnh để phá hủy tất cả các stacks đã triển khai. Khi được nhắc, gõ y để chấp nhận việc xóa. $ cdk destroy --all Giai đoạn 3: Dọn dẹp sau khi phá hủy Bước này giải quyết việc dọn dẹp thủ công các tài nguyên còn sót lại.\nXóa các S3 Buckets còn lại\nLệnh cdk destroy sẽ xóa các S3 buckets trống. Nếu còn sót lại bucket nào (do kiểm tra cuối cùng hoặc bảo vệ dịch vụ), hãy xóa chúng ngay bây giờ qua S3 Console. Vô hiệu hóa Amazon GuardDuty\nVào GuardDuty Console → Settings → General. Xác minh dịch vụ đã bị vô hiệu hóa để đảm bảo ngừng tính phí. Xóa Cognito User và Pool\nVào Cognito Console → User pools. Xóa test user bạn đã tạo. Xóa User Pool đã tạo cho dashboard. Xóa SES Identity\nVào Amazon SES Console → Verified Identities. Xóa sender email identity (sender_email) bạn đã xác minh. Hủy kích hoạt môi trường ảo\nHủy kích hoạt môi trường ảo Python: $ deactivate "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.2-prerequiste/","title":"Điều kiện tiên quyết","tags":[],"description":"","content":"Các yêu cầu về Truy cập và Thông tin Trước khi tiến hành thiết lập Hệ thống Phản hồi Sự cố và Điều tra số AWS Tự động (Automated AWS Incident Response and Forensics System), hãy đảm bảo bạn đã thu thập đủ các thông tin và quyền truy cập cần thiết dưới đây.\n🔑 Truy cập \u0026amp; Định danh Tài khoản AWS với Quyền Quản trị (Administrative Access) Bạn cần toàn quyền quản trị để tạo tài nguyên trên nhiều dịch vụ AWS. Truy cập vào AWS Management Console. AWS Account ID của bạn Định dạng: số có 12 chữ số (ví dụ: 123456789012). Placeholder: Thay thế ACCOUNT_ID trong toàn bộ hướng dẫn. AWS Region Mục tiêu Chọn region nơi bạn sẽ triển khai hệ thống (ví dụ: us-east-1). Placeholder: Thay thế REGION trong toàn bộ hướng dẫn. VPC ID Một VPC có ít nhất một subnet được yêu cầu cho VPC Flow Logs. Placeholder: Thay thế YOUR_VPC_ID trong hướng dẫn. Địa chỉ Email đã xác thực Amazon SES Cần thiết để gửi và nhận thông báo qua email. Xác thực địa chỉ này trong SES Console. Placeholder: Thay thế YOUR_VERIFIED_EMAIL@example.com. Slack Webhook URL (Tùy chọn) Nếu bạn muốn nhận thông báo qua Slack, hãy lấy webhook URL từ Slack workspace của bạn. Placeholder: Thay thế YOUR_SLACK_WEBHOOK_URL. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.2-guardduty-etl/","title":"Mã GuardDuty ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime from urllib.parse import unquote_plus s3_client = boto3.client(\u0026#39;s3\u0026#39;) DATABASE_NAME = os.environ.get(\u0026#34;DATABASE_NAME\u0026#34;, \u0026#34;security_logs\u0026#34;) TABLE_NAME_GUARDDUTY = os.environ.get(\u0026#34;TABLE_NAME_GUARDDUTY\u0026#34;, \u0026#34;processed_guardduty\u0026#34;) S3_LOCATION_GUARDDUTY = os.environ.get(\u0026#34;S3_LOCATION_GUARDDUTY\u0026#34;, \u0026#34;s3://vel-processed-guardduty/processed-guardduty/\u0026#34;) DESTINATION_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;, \u0026#34;vel-processed-guardduty\u0026#34;) def promote_network_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) net_conn_action = action.get(\u0026#39;networkConnectionAction\u0026#39;, {}) if net_conn_action: remote_ip = net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;) or \\ net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV6\u0026#39;) return { \u0026#39;remote_ip\u0026#39;: remote_ip, \u0026#39;remote_port\u0026#39;: net_conn_action.get(\u0026#39;remotePortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), \u0026#39;connection_direction\u0026#39;: net_conn_action.get(\u0026#39;connectionDirection\u0026#39;), \u0026#39;protocol\u0026#39;: net_conn_action.get(\u0026#39;protocol\u0026#39;), } dns_action = action.get(\u0026#39;dnsRequestAction\u0026#39;, {}) if dns_action: return {\u0026#39;dns_domain\u0026#39;: dns_action.get(\u0026#39;domain\u0026#39;), \u0026#39;dns_protocol\u0026#39;: dns_action.get(\u0026#39;protocol\u0026#39;)} port_probe_action = action.get(\u0026#39;portProbeAction\u0026#39;, {}) if port_probe_action and port_probe_action.get(\u0026#39;portProbeDetails\u0026#39;): detail = port_probe_action[\u0026#39;portProbeDetails\u0026#39;][0] return { \u0026#39;scanned_ip\u0026#39;: detail.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), \u0026#39;scanned_port\u0026#39;: detail.get(\u0026#39;localPortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), } return {} def promote_api_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) aws_api_action = action.get(\u0026#39;awsApiCallAction\u0026#39;, {}) if aws_api_action: return { \u0026#39;aws_api_service\u0026#39;: aws_api_action.get(\u0026#39;serviceName\u0026#39;), \u0026#39;aws_api_name\u0026#39;: aws_api_action.get(\u0026#39;api\u0026#39;), \u0026#39;aws_api_caller_type\u0026#39;: aws_api_action.get(\u0026#39;callerType\u0026#39;), \u0026#39;aws_api_error\u0026#39;: aws_api_action.get(\u0026#39;errorCode\u0026#39;), \u0026#39;aws_api_remote_ip\u0026#39;: aws_api_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), } return {} def promote_resource_details(finding_resource): if not finding_resource: return {} instance_details = finding_resource.get(\u0026#39;instanceDetails\u0026#39;, {}) if instance_details: return { \u0026#39;target_resource_arn\u0026#39;: instance_details.get(\u0026#39;arn\u0026#39;), \u0026#39;instance_id\u0026#39;: instance_details.get(\u0026#39;instanceId\u0026#39;), \u0026#39;resource_region\u0026#39;: instance_details.get(\u0026#39;awsRegion\u0026#39;), \u0026#39;instance_type\u0026#39;: instance_details.get(\u0026#39;instanceType\u0026#39;), \u0026#39;image_id\u0026#39;: instance_details.get(\u0026#39;imageId\u0026#39;), \u0026#39;instance_tags\u0026#39;: instance_details.get(\u0026#39;tags\u0026#39;) } access_key_details = finding_resource.get(\u0026#39;accessKeyDetails\u0026#39;, {}) if access_key_details: return { \u0026#39;access_key_id\u0026#39;: access_key_details.get(\u0026#39;accessKeyId\u0026#39;), \u0026#39;principal_id\u0026#39;: access_key_details.get(\u0026#39;principalId\u0026#39;), \u0026#39;user_name\u0026#39;: access_key_details.get(\u0026#39;userName\u0026#39;), } s3_details = finding_resource.get(\u0026#39;s3BucketDetails\u0026#39;, []) if s3_details: return { \u0026#39;target_resource_arn\u0026#39;: s3_details[0].get(\u0026#39;arn\u0026#39;), \u0026#39;s3_bucket_name\u0026#39;: s3_details[0].get(\u0026#39;name\u0026#39;), } return {} def process_guardduty_log(bucket, key): response = s3_client.get_object(Bucket=bucket, Key=key) if key.endswith(\u0026#39;.gz\u0026#39;): content = gzip.decompress(response[\u0026#39;Body\u0026#39;].read()).decode(\u0026#39;utf-8\u0026#39;) else: content = response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;) processed_findings = [] for line in content.splitlines(): if not line: continue try: finding = json.loads(line) except json.JSONDecodeError: print(f\u0026#34;Skipping malformed JSON line in {key}\u0026#34;); continue finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;UNKNOWN\u0026#39;) finding_service = finding.get(\u0026#39;service\u0026#39;, {}) network_fields = promote_network_details(finding_service) api_fields = promote_api_details(finding_service) resource_fields = promote_resource_details(finding.get(\u0026#39;resource\u0026#39;, {})) created_at_str = finding.get(\u0026#39;createdAt\u0026#39;) event_last_seen_str = finding_service.get(\u0026#39;eventLastSeen\u0026#39;) dt_obj = datetime.now() if event_last_seen_str: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass elif created_at_str: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass processed_record = { \u0026#39;finding_id\u0026#39;: finding.get(\u0026#39;id\u0026#39;), \u0026#39;finding_type\u0026#39;: finding_type, \u0026#39;title\u0026#39;: finding.get(\u0026#39;title\u0026#39;), \u0026#39;severity\u0026#39;: finding.get(\u0026#39;severity\u0026#39;), \u0026#39;account_id\u0026#39;: finding.get(\u0026#39;accountId\u0026#39;), \u0026#39;region\u0026#39;: finding.get(\u0026#39;region\u0026#39;), \u0026#39;created_at\u0026#39;: created_at_str, \u0026#39;event_last_seen\u0026#39;: event_last_seen_str, **network_fields, **api_fields, **resource_fields, \u0026#39;date\u0026#39;: dt_obj.strftime(\u0026#39;%Y-%m-%d\u0026#39;), \u0026#39;service_raw\u0026#39;: json.dumps(finding_service), \u0026#39;resource_raw\u0026#39;: json.dumps(finding.get(\u0026#39;resource\u0026#39;, {})), \u0026#39;metadata_raw\u0026#39;: json.dumps(finding.get(\u0026#39;metadata\u0026#39;, {})), } processed_findings.append(processed_record) return processed_findings def save_processed_data(processed_events, source_key): if not processed_events: return first_event = processed_events[0] date_str = first_event.get(\u0026#39;date\u0026#39;, datetime.now().strftime(\u0026#39;%Y-%m-%d\u0026#39;)) original_filename = source_key.split(\u0026#39;/\u0026#39;)[-1].replace(\u0026#39;.gz\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;.json\u0026#39;, \u0026#39;\u0026#39;) output_key = f\u0026#34;processed-guardduty/date={date_str}/{original_filename}_processed.jsonl.gz\u0026#34; json_lines = \u0026#34;\u0026#34; for event in processed_events: event_to_dump = event.copy() json_lines += json.dumps(event_to_dump) + \u0026#34;\\n\u0026#34; compressed_data = gzip.compress(json_lines.encode(\u0026#39;utf-8\u0026#39;)) s3_client.put_object( Bucket=DESTINATION_BUCKET, Key=output_key, Body=compressed_data, ContentType=\u0026#39;application/jsonl\u0026#39;, ContentEncoding=\u0026#39;gzip\u0026#39; ) print(f\u0026#34;Saved processed data to: s3://{DESTINATION_BUCKET}/{output_key}\u0026#34;) def lambda_handler(event, context): for record in event[\u0026#39;Records\u0026#39;]: bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = unquote_plus(record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;]) print(f\u0026#34;Processing GuardDuty finding file: s3://{bucket}/{key}\u0026#34;) try: processed_findings = process_guardduty_log(bucket, key) save_processed_data(processed_findings, key) print(f\u0026#34;Successfully processed {len(processed_findings)} findings from {key}\u0026#34;) except Exception as e: print(f\u0026#34;Error processing {key}: {str(e)}\u0026#34;) raise e return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;GuardDuty findings processed successfully\u0026#39;) } "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.5-processing-setup/5.5.2-create-aws-glue-database-and-tables/","title":"Tạo AWS Glue Database và Tables","tags":[],"description":"","content":"Tạo AWS Glue Database và Tables Tạo Database Mở Glue Console → Databases → Add database\nDatabase name: security_logs\nCreate database\nTạo Tables (Sử dụng Athena DDL) Mở Athena Console\nĐặt vị trí lưu kết quả truy vấn (query result location): s3://athena-query-results-ACCOUNT_ID-REGION/\nChọn database: security_logs\nTạo bảng processed_cloudtrail Chạy DDL này trong Athena (thay thế ACCOUNT_ID và REGION):\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_cloudtrail ( `eventtime` string, `eventname` string, `eventsource` string, `awsregion` string, `sourceipaddress` string, `useragent` string, `useridentity` struct\u0026lt; type:string, invokedby:string, principalid:string, arn:string, accountid:string, accesskeyid:string, username:string, sessioncontext:struct\u0026lt; attributes:map\u0026lt;string,string\u0026gt;, sessionissuer:struct\u0026lt; type:string, principalid:string, arn:string, accountid:string, username:string \u0026gt; \u0026gt;, inscopeof:struct\u0026lt; issuertype:string, credentialsissuedto:string \u0026gt; \u0026gt;, `requestparameters` string, `responseelements` string, `resources` array\u0026lt;struct\u0026lt;arn:string,type:string\u0026gt;\u0026gt;, `recipientaccountid` string, `serviceeventdetails` string, `errorcode` string, `errormessage` string, `hour` string, `usertype` string, `username` string, `isconsolelogin` boolean, `isfailedlogin` boolean, `isrootuser` boolean, `isassumedrole` boolean, `ishighriskevent` boolean, `isprivilegedaction` boolean, `isdataaccess` boolean, `target_bucket` string, `target_key` string, `target_username` string, `target_rolename` string, `target_policyname` string, `new_access_key` string, `new_instance_id` string, `target_group_id` string, `identity_principalid` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Tạo bảng processed_guardduty Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_guardduty ( `finding_id` string, `finding_type` string, `title` string, `severity` double, `account_id` string, `region` string, `created_at` string, `event_last_seen` string, `remote_ip` string, `remote_port` int, `connection_direction` string, `protocol` string, `dns_domain` string, `dns_protocol` string, `scanned_ip` string, `scanned_port` int, `aws_api_service` string, `aws_api_name` string, `aws_api_caller_type` string, `aws_api_error` string, `aws_api_remote_ip` string, `target_resource_arn` string, `instance_id` string, `instance_type` string, `image_id` string, `instance_tags` string, `resource_region` string, `access_key_id` string, `principal_id` string, `user_name` string, `s3_bucket_name` string, `service_raw` string, `resource_raw` string, `metadata_raw` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/\u0026#39; TBLPROPERTIES ( \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39;, \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/date=${date}/\u0026#39; ); Tạo bảng vpc_logs Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.vpc_logs ( `version` string, `account_id` string, `region` string, `vpc_id` string, `query_timestamp` string, `query_name` string, `query_type` string, `query_class` string, `rcode` string, `answers` string, `srcaddr` string, `srcport` int, `transport` string, `srcids_instance` string, `timestamp` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;ignore.malformed.json\u0026#39; = \u0026#39;true\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Tạo bảng eni_flow_logs Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.eni_flow_logs ( `version` int, `account_id` string, `interface_id` string, `srcaddr` string, `dstaddr` string, `srcport` int, `dstport` int, `protocol` int, `packets` bigint, `bytes` bigint, `start_time` bigint, `end_time` bigint, `action` string, `log_status` string, `timestamp_str` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.2-create-service-roles/","title":"Tạo Service Roles","tags":[],"description":"","content":"Tạo Firehose Roles Tạo CloudTrailFirehoseRole Mở IAM Console → Roles → Create role\nChọn trusted entity:\nTrusted entity type: AWS service Use case: Chọn \u0026ldquo;Kinesis\u0026rdquo; → \u0026ldquo;Kinesis Firehose\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Thêm permissions:\nBỏ qua việc thêm managed policies (chúng ta sẽ thêm inline policy) Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên và tạo:\nRole name: CloudTrailFirehoseRole Description: Allows Firehose to write CloudTrail logs to S3 Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nPolicy name: FirehosePolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Tạo CloudWatchFirehoseRole Role name: CloudWatchFirehoseRole Description: Allows Firehose to write CloudWatch logs to S3 Trusted entity: Kinesis Firehose Inline policy name: FirehosePolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Tạo Step Functions Role Tạo StepFunctionsRole Tạo role:\nTrusted entity: Step Functions Role name: StepFunctionsRole Description: Execution role for Incident Response Step Functions Thêm HAI inline policies:\nPolicy 1: LambdaInvokePolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-parse-findings-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-quarantine-iam-lambda\u0026#34; ] } ] } Policy 2: EC2AutoScalingPolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;autoscaling:DescribeAutoScalingInstances\u0026#34;, \u0026#34;autoscaling:DetachInstances\u0026#34;, \u0026#34;autoscaling:UpdateAutoScalingGroup\u0026#34;, \u0026#34;ec2:CreateSnapshot\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:DescribeVolumes\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo EventBridge Role Tạo IncidentResponseStepFunctionsEventRole Role name: IncidentResponseStepFunctionsEventRole Description: Allows EventBridge to trigger Step Functions Trusted entity: EventBridge Inline policy name: StartStepFunctionsPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;states:StartExecution\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:REGION:ACCOUNT_ID:stateMachine:IncidentResponseStepFunctions\u0026#34; } ] } Tạo VPC Flow Logs Role Tạo FlowLogsIAMRole Tạo role:\nTrusted entity: EC2 (will edit trust policy - sẽ chỉnh sửa trust policy sau) Role name: FlowLogsIAMRole Chỉnh sửa trust relationship thành:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;vpc-flow-logs.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } Thêm inline policy: Policy name: FlowLogsPolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo Glue Role Tạo GlueCloudWatchRole Role name: GlueCloudWatchRole Description: Allows Glue to access S3 and CloudWatch Logs Trusted entity: Glue Managed policies (đính kèm 3 policies): AWSGlueServiceRole CloudWatchLogsReadOnlyAccess AmazonS3FullAccess Không cần inline policies "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.3-foundation-setup/5.3.2-set-up-s3-buckets-policies/","title":"Thiết lập S3 buckets policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ cấu hình bucket policy cho bucket log chính để cho phép CloudTrail, GuardDuty, và CloudWatch Logs ghi log.\nCấu hình Bucket Policy Điều hướng đến bucket log chính: Trong S3 Console, nhấn vào incident-response-log-list-bucket-ACCOUNT_ID-REGION Mở tab Permissions:\nNhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Cuộn đến Bucket policy:\nCuộn xuống phần \u0026ldquo;Bucket policy\u0026rdquo; Nhấn \u0026ldquo;Edit\u0026rdquo; Dán bucket policy: Copy JSON policy sau Quan trọng: Thay thế ACCOUNT_ID và REGION bằng giá trị thực tế của bạn trong policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyGetBucketLocation\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsGetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailAclCheck\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailWrite\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/AWSLogs/ACCOUNT_ID/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34;, \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } } ] } Nhấn \u0026ldquo;Save changes\u0026rdquo;\nXác minh policy đã lưu: Bạn sẽ thấy policy hiển thị trong phần Bucket policy\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/4-eventparticipated/4.3-event3/","title":"Sự kiện 3","tags":[],"description":"","content":"Báo cáo Tóm tắt: “AWS Cloud Mastery Series #2 - DevOps trên AWS” Mục tiêu Sự kiện Giới thiệu các dịch vụ AWS DevOps – Quy trình CI/CD Giới thiệu Cơ sở hạ tầng dưới dạng mã (IaC) và các công cụ liên quan Giới thiệu các Dịch vụ Container trên AWS Đảm bảo khả năng Giám sát (Monitoring) và Quan sát (Observability) sử dụng các dịch vụ AWS Diễn giả Truong Quang Tinh – AWS Community Builder, Kỹ sư Nền tảng (Platform Engineer) - TymeX Bao Huynh – AWS Community Builder Nguyen Khanh Phuc Thinh – AWS Community Builder Tran Dai Vi – AWS Community Builder Huynh Hoang Long – AWS Community Builder Pham Hoang Quy – AWS Community Builder Nghiem Le – AWS Community Builder Dinh Le Hoang Anh - Thực tập sinh Cloud Engineer, First Cloud AI Journey Điểm nhấn Chính Tư duy DevOps (DevOps Mindset) - Văn hóa: Hợp tác, Tự động hóa, Học tập liên tục và Đo lường - Các vai trò DevOps: Kỹ sư DevOps, Kỹ sư Cloud, Kỹ sư Nền tảng, Kỹ sư độ tin cậy trang web (SRE) - Chỉ số thành công: + Đảm bảo sức khỏe của việc triển khai (deployment health) + Cải thiện sự linh hoạt (agility) + Tính ổn định của hệ thống + Tối ưu hóa trải nghiệm khách hàng + Chứng minh hiệu quả đầu tư công nghệ\nNÊN (DO) KHÔNG NÊN (DON\u0026rsquo;T) Bắt đầu từ những điều cơ bản Kẹt trong vòng lặp hướng dẫn (Tutorial Hell) Học bằng cách xây dựng dự án thực tế Sao chép và dán một cách mù quáng Tài liệu hóa mọi thứ So sánh tiến độ của bạn với người khác Thành thạo từng thứ một Bỏ cuộc sau những thất bại Nâng cao kỹ năng mềm - Tích hợp liên tục (CI): Các thành viên trong nhóm tích hợp công việc của họ thường xuyên, hướng tới Chuyển giao liên tục (CD) và Triển khai liên tục.\nCơ sở hạ tầng dưới dạng mã (IaC) - Lợi ích: Tự động hóa, Khả năng mở rộng, Khả năng tái tạo và Hợp tác tốt hơn\nAWS CloudFormation Công cụ IaC tích hợp sẵn của AWS, sử dụng các mẫu (templates) viết bằng YAML hoặc JSON, có thể xây dựng mọi cơ sở hạ tầng AWS một cách tự động.\n- Stack: Một tập hợp các Tài nguyên AWS được định nghĩa trong một mẫu, có thể được CloudFormation sử dụng để tạo, cập nhật hoặc xóa các tài nguyên đó.\n- CloudFormation Template: Một tệp YAML/JSON định nghĩa Cơ sở hạ tầng AWS, hoạt động như một bản thiết kế để triển khai và định cấu hình tài nguyên.\n- Cách thức hoạt động: Tạo mẫu -\u0026gt; Lưu trữ trong S3 Bucket hoặc bộ nhớ cục bộ -\u0026gt; Sử dụng CloudFormation để tạo Stack dựa trên mẫu -\u0026gt; CloudFormation xây dựng tài nguyên.\n- Phát hiện sai lệch (Drift Detection): Phát hiện các thay đổi trong cơ sở hạ tầng thực tế so với Stack =\u0026gt; Cập nhật Stack hoặc hoàn tác thay đổi, hữu ích cho việc kiểm soát phiên bản.\nAWS Cloud Development Kit (CDK) Khung phát triển phần mềm nguồn mở, hỗ trợ IaC bằng các ngôn ngữ lập trình thực (Python, Java, C#.Net, Type/JavaScript và Go).\n- Construct: Các khối xây dựng, bao gồm các thành phần đại diện cho Tài nguyên AWS và Cấu hình của chúng, có 3 cấp độ construct:\nL1 Construct: Tài nguyên cấp thấp ánh xạ trực tiếp đến một tài nguyên AWS CloudFormation đơn lẻ. L2 Construct: Cung cấp mức độ trừu tượng cao hơn thông qua API dựa trên ý định trực quan, đóng gói các phương pháp hay nhất (best practices) và mặc định bảo mật. L3 Construct: Các mẫu kiến trúc hoàn chỉnh với nhiều tài nguyên, được triển khai theo định hướng sẵn (opinionated) và triển khai nhanh chóng. AWS Amplify Nền tảng AWS giúp dễ dàng xây dựng, triển khai và mở rộng các ứng dụng web và di động, sử dụng CloudFormation bên dưới: Các Stack được triển khai để xây dựng cơ sở hạ tầng theo chương trình.\nTerraform Công cụ IaC, bắt đầu bằng việc định nghĩa cơ sở hạ tầng trong mã Terraform, lên kế hoạch (plan) và sau đó áp dụng (apply) cơ sở hạ tầng trên nhiều nền tảng đám mây như Azure, AWS, Google Cloud, v.v.\n- Điểm mạnh: Hỗ trợ đa đám mây (Multi-Cloud), Theo dõi trạng thái (State tracking) với cùng một cấu hình.\nCách chọn công cụ IaC? - Tiêu chí:\nKế hoạch sử dụng một Đám mây hay nhiều Đám mây? Vai trò là Developer hay Ops? Hệ sinh thái và Đám mây đó có hỗ trợ công cụ không? Dịch vụ Container trên AWS Dockerfile Dockerfile định nghĩa cách xây dựng một container image, mô tả môi trường, các phụ thuộc, các bước xây dựng và cấu hình runtime cuối cùng, đảm bảo ứng dụng chạy nhất quán trên mọi hệ thống hỗ trợ Docker.\n- Images: Một bản thiết kế đóng gói của ứng dụng, được xây dựng từ Dockerfile sử dụng hệ thống tệp phân lớp, dùng để tạo các container nhất quán trên các môi trường.\n- Quy trình: Dockerfile xây dựng Docker Image, image này có thể được dùng để chạy Container và đẩy lên ECR/Docker Hub.\nAmazon ECR Một container registry được quản lý hoàn toàn giúp dễ dàng lưu trữ, quản lý và chia sẻ bảo mật các Docker container image. Đây là registry container riêng tư, bảo mật và có khả năng mở rộng của chính AWS.\n- Tính năng:\nQuét Image (Image Scanning) Thẻ bất biến (Immutable Tags) Chính sách vòng đời (Lifecycle Policies) Mã hóa \u0026amp; IAM - Điều phối (Orchestration): Điều phối nhiều quy trình container: khởi động lại container, tự động mở rộng khi tải cao, phân phối lưu lượng hiệu quả, quản lý vị trí đặt và chạy container.\nKubernetes Mã nguồn mở, tự động hóa việc triển khai, mở rộng, phục hồi và cân bằng tải. - Thành phần:\nMaster Node: Control Plane, quản lý các worker node và pod. Worker Node: Chạy khối lượng công việc ứng dụng bên trong các pod. Pod: Đơn vị triển khai nhỏ nhất, có thể chứa một hoặc nhiều container. Service So sánh ECS và EKS\nTính năng Amazon ECS (Elastic Container Service) Amazon EKS (Elastic Kubernetes Service) Công nghệ cốt lõi Điều phối container gốc của AWS (AWS-native) Dựa trên Kubernetes (tiêu chuẩn nguồn mở) Độ phức tạp Đơn giản hơn, dễ vận hành hơn Linh hoạt cao nhưng phức tạp hơn Kiến thức yêu cầu Không cần kiến thức Kubernetes Yêu cầu kiến thức Kubernetes (pods, deployments, v.v.) Tích hợp AWS Tích hợp sâu với AWS (ALB, IAM, CloudWatch, v.v.) Tích hợp Kubernetes tiêu chuẩn Trường hợp sử dụng/Lợi ích Tuyệt vời cho triển khai nhanh \u0026amp; chi phí vận hành thấp Đa cụm (Multi-cluster), khả năng di động đa đám mây Hệ sinh thái/Cộng đồng Công cụ gốc AWS và cộng đồng Hệ sinh thái lớn hơn \u0026amp; công cụ cộng đồng Tóm tắt ECS = dễ hơn, chạy nhanh hơn, chi phí vận hành thấp hơn EKS = linh hoạt hơn, kiểm soát nhiều hơn, phức tạp hơn App Runner Phù hợp để triển khai nhanh các ứng dụng web và REST API, lý tưởng cho khối lượng công việc sản xuất từ nhỏ đến trung bình.\nGiám sát \u0026amp; Khả năng quan sát (Monitoring \u0026amp; Observability) CloudWatch Giám sát các Tài nguyên AWS và Ứng dụng chạy trên AWS trong thời gian thực Cung cấp khả năng quan sát Cảnh báo và phản hồi tự động Dashboard giúp tối ưu hóa vận hành và chi phí - CloudWatch metrics: Dữ liệu về hiệu suất của hệ thống trên AWS hoặc on-premise với CloudWatch Agent, tích hợp tốt với EventBridge, Auto Scaling và quy trình DevOps.\nAWS X-Ray - Truy vết phân tán (Distributed Tracing): Theo dõi các yêu cầu từ đầu đến cuối, vẽ bản đồ và đường đi giữa các dịch vụ đã truy cập, thêm SDK vào mã để theo dõi ID.\n- Performance Insight: Phân tích nguyên nhân gốc rễ cho độ trễ và lỗi, suy ra thông tin chi tiết từ các dấu vết (traces) và cung cấp Giám sát Người dùng Thực (Real User Monitoring).\nTrải nghiệm Sự kiện Sự kiện này rất quan trọng đối với dự án của chúng tôi vì nó giải quyết kế hoạch thêm IaC sử dụng CDK, thay vì sử dụng ClickOps, để tăng khả năng bảo trì và tái tạo. Ngoài ra, một số thông tin chi tiết về CloudWatch cũng giúp ích rất nhiều cho tính năng giám sát dữ liệu của chúng tôi.\nCác diễn giả đã trả lời câu hỏi của nhóm:\nHỏi: Dự án của chúng tôi cho đến nay hoàn toàn được xây dựng bằng ClickOps (thao tác thủ công trên console), và chúng tôi đang định sử dụng CDK. Có công cụ nào có thể quét và chuyển đổi cơ sở hạ tầng hiện có thành CDK hoặc CloudFormation thay vì phải tái tạo lại cơ sở hạ tầng từ đầu bằng IaC không?\nĐáp: Rất tiếc là không, chưa có công cụ nào có thể hỗ trợ vấn đề đó, nhóm của bạn sẽ phải xây dựng lại cơ sở hạ tầng từ đầu. Nếu tình cờ bạn tìm thấy một công cụ có thể hỗ trợ, hãy chia sẻ với chúng tôi nhé.\nHỏi: Chúng tôi nhận thấy AWS X-Ray dùng với CloudWatch tương tự như CloudTrail trong phương pháp theo dõi, bạn có thể giải thích thêm về điểm khác biệt giữa chúng không?\nĐáp: X-Ray được sử dụng cho CloudWatch và dùng để theo dõi các tài nguyên và dịch vụ mà hệ thống đã tương tác, trong khi CloudTrail thường được sử dụng để theo dõi hành động của người dùng (user) AWS.\nHỏi: Dự án của chúng tôi được xây dựng xoay quanh GuardDuty Findings, bạn có kinh nghiệm nào về cách kích hoạt Findings một cách đáng tin cậy cho các kịch bản demo không?\nĐáp: Theo kinh nghiệm của tôi, GuardDuty Findings có thể được kích hoạt bởi các hoạt động quét cổng (port scanning), nhưng tôi chắc chắn còn có những cách khác.\nĐáp: GuardDuty có thể được cấu hình để có một danh sách mối đe dọa (threat list) chứa các quy tắc tùy chỉnh để kích hoạt các finding khi có hoạt động liên quan đến các tên miền hoặc IP độc hại đã được cấu hình.\nSự kiện này cũng là lần đầu tiên một số diễn giả trình bày về một chủ đề:\nCác phần về DevOps và IaC được trình bày rất tốt. Phần Giám sát \u0026amp; Khả năng quan sát chưa thực sự xuất sắc và chúng tôi có thể nhận thấy sự lo lắng của diễn giả nhưng vẫn mang lại những giá trị tuyệt vời. Một số hình ảnh sự kiện "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.3-week3/","title":"Nhật ký công việc Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Hoàn thành Module 5. Hỗ trợ đồng đội với các bài lab trước đó. Làm lại các bài lab trước đây bị chặn do giới hạn Free Tier. Thảo luận ý tưởng dự án. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Lab 25 không thể hoàn thành vì tài khoản vẫn ở gói Free Tier.\n- Đã nâng cấp tài khoản lên gói trả phí.\n- Thử lại Lab 25:\n+ Template được cung cấp sử dụng Lambda runtime nodejs12.x đã cũ, nên đã cập nhật lên nodejs20.x.\n+ Thiết lập hệ thống file FSx.\n+ Endpoint mặc định của S3 để kiểm thử chỉ truy cập được ở vùng US, nên câu lệnh cần đổi thành: Read-S3Object -BucketName nasanex -KeyPrefix /AVHRR -Folder Z:/nasanex/AVHRR -Region us-west-2.\n+ Tạo file share.\n+ Cấu hình cả HDD và SSD FSx.\n+ Cập nhật phiên bản công cụ đã cũ ở phần 25.4.\n+ Thực hiện benchmark ổ đĩa thành công với các tham số khác nhau.\n+ Sử dụng CloudWatch để giám sát hiệu năng — thông lượng (throughput) đạt tối đa 400 MB, kích hoạt cảnh báo.\n+ Tìm hiểu về tính năng deduplication (chống trùng lặp) của FSx:\n• Lịch mặc định chạy vào thứ Bảy hàng tuần.\n• Lần chạy dedup đầu tiên không tối ưu được gì do cài đặt fileAge mặc định -\u0026gt; chỉnh fileAge về 0 -\u0026gt; ~50% file được tối ưu.\n+ Tạo shadow copy để backup.\n+ Học cách quản lý và buộc đóng (force-close) các file đang mở.\n+ Cấu hình hạn mức người dùng (user quotas) để giới hạn dung lượng lưu trữ.\n+ Bật tính năng Continuously Available (CA) file shares để nhiều người dùng có thể truy cập cùng lúc.\n+ Mở rộng throughput và dung lượng lưu trữ từ AWS Console.\n- Ôn tập Mô hình Trách nhiệm Chia sẻ: cả AWS và khách hàng đều chia sẻ trách nhiệm bảo mật.\n- Module 5-2: Best practice là tạo một IAM user quản trị thay vì dựa vào tài khoản root.\n- IAM Principal: Một thực thể được phép truy cập tài nguyên AWS.\n- IAM Policy: Có thể dựa trên danh tính hoặc tài nguyên.\n- IAM Role: Tập hợp các quyền hạn cho user/service, và có thể dùng cho truy cập xuyên tài khoản (cross-account).\n- Môn học ở trường:\n+ ENW493c: Hoàn thành khóa học Understanding Research Methods. 22/09/2025 22/09/2025 Lab25 T3 - Module 5:\n- Amazon Cognito: Dịch vụ xác thực và quản lý người dùng với hai thành phần chính:\n+ User Pools: Lưu thông tin người dùng và hỗ trợ các nhà cung cấp danh tính bên thứ ba.\n+ Identity Pools: Ánh xạ người dùng tới các quyền hạn và thông tin xác thực tạm thời.\n- AWS Organizations: Quản lý tập trung nhiều tài khoản AWS sử dụng OU và Service Control Policies (SCP).\n- AWS Identity Center (SSO): Quản lý truy cập ứng dụng và tài khoản AWS thông qua các bộ quyền (permission sets).\n- AWS KMS: Tạo và quản lý khóa mã hóa (CMK), dùng để tạo và mã hóa/giải mã các data key.\n- AWS Security Hub: Đánh giá tình trạng bảo mật dựa trên các best practice của AWS.\n- Tiếp tục Lab 14:\n+ Thiết lập IAM role và S3 bucket.\n+ Ubuntu 25.04 thất bại do kernel không hỗ trợ -\u0026gt; thử Ubuntu 24.04 -\u0026gt; vẫn không hỗ trợ -\u0026gt; cài đặt thành công Ubuntu 22.04.\n+ Import máy ảo (VM) vào AWS.\n+ Kết nối tới EC2 instance được tạo từ AMI bằng username/password của VM. 23/09/2025 23/09/2025 Lab 14 T4 Tiếp tục với lab 14:\n+ Tạo export bucket, cấu hình quyền hạn + Export thành công instance sang định dạng .OVA để sử dụng - Lab 18: Bật Security Hub và cấu hình AWS Config để ghi lại dữ liệu phân tích (Có thể mất nhiều thời gian để tính điểm) 24/09/2025 24/09/2025 Lab 14 T5 - Lab 22:\n+ Xây dựng Lambda function để tự động start/stop EC2 instance sử dụng lịch trình và tag.\n+ Gửi thông báo đến Slack.\n- Lab 28:\n+ Tạo IAM policy và role để chỉ cho phép truy cập từ vùng Singapore.\n+ Chặn truy cập EC2 từ bên ngoài vùng được cho phép.\n+ Chặn tạo EC2 instance nếu không có tag hợp lệ.\n- Lab 30: Hạn chế IAM user để họ chỉ có thể truy cập EC2 ở một vùng cụ thể.\n- Cập nhật Lab 18: Quét Security Hub hoàn tất — điểm số: 85%, có 1 lỗi nghiêm trọng (một IAM user vẫn có quyền admin).\n- Lab 33:\n+ Thiết lập KMS.\n+ Cấu hình CloudTrail để gửi log đến S3.\n+ Truy vấn log bằng Athena.\n+ Xác minh rằng KMS từ chối truy cập đối với người dùng không được phép một cách chính xác. 25/09/2025 25/09/2025 Lab 22 Lab 28 Lab 30 Lab 18 Lab 33 T6 - Lab 44: Cấu hình điều kiện cho role, hạn chế truy cập theo IP, Thời gian và các yếu tố khác\n- Lab 48:\n+ Sử dụng IAM access key để upload file lên S3 qua EC2 Instance + Upload file lên S3 qua EC2 Instance không dùng access key mà sử dụng IAM Roles - Lab 12: + Tạo AWS Organization + Tạo tài khoản và di chuyển chúng vào các unit (OU) + Mời các tài khoản vào tổ chức + Chuyển đổi role cho các tài khoản trong tổ chức + Thiết lập policy cho các tài khoản trong tổ chức + Cài đặt Python để tiếp tục bài lab 26/09/2025 26/09/2025 Lab 44 Lab 48 Lab 12 Thành tựu Tuần 3 Đã nâng cấp tài khoản AWS và hoàn thành các bài lab trước đây bị chặn do giới hạn Free Tier. Giải quyết nhiều vấn đề tương thích (ví dụ: Lambda runtime cũ, kernel không hỗ trợ). Hoàn thành thiết lập Amazon FSx nâng cao trong Lab 25: Deduplication, shadow copy, user quota, mở rộng, giám sát CloudWatch. Hoàn thành lý thuyết Module 5: IAM, Cognito, Organizations, Identity Center, KMS. Áp dụng bảo mật IAM thực tế: Hạn chế vùng (Lab 28 \u0026amp; 30) Điều kiện IAM theo IP/thời gian (Lab 44) Upload S3 an toàn dùng IAM Role (Lab 48) Bật Security Hub \u0026amp; AWS Config (Lab 18) → Đạt điểm đánh giá bảo mật 85%. Xây dựng tự động hóa Lambda để lập lịch cho EC2 tích hợp với Slack (Lab 22). Import thành công VM, tạo AMI, và export EC2 ra file .OVA (Lab 14). Thiết lập AWS Organization với các OU, SCP, chuyển đổi role, và quản lý user/group (Lab 12). Hoàn thành các bài lab Microsoft Workloads: Quản lý AD Khắc phục sự cố EC2 qua sửa chữa volume Gán license với Microsoft AD Cấu hình CloudTrail, lưu log vào S3, và dùng Athena để phân tích log (Lab 33), với KMS thực thi kiểm soát truy cập. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/3-blogstranslated/","title":"Blog đã dịch","tags":[],"description":"","content":"This section will list and introduce the blogs you have translated.\nBlog 1 - Giới thiệu AWS Trust Center Blog này giới thiệu về AWS Trust Center, một nguồn tài nguyên trực tuyến thống nhất giúp khách hàng dễ dàng tiếp cận thông tin về bảo mật, tuân thủ và quyền riêng tư của AWS. Bài viết giải thích cách Trust Center hỗ trợ người dùng tìm hiểu về các biện pháp kiểm soát trung tâm dữ liệu, xem báo cáo đánh giá tuân thủ, và hiểu rõ cơ chế kiểm soát truy cập, từ đó xây dựng niềm tin vững chắc vào sự minh bạch của nền tảng đám mây.\nBlog 2 - Cách Derive mở rộng nền tảng giao dịch phi tập trung độ trễ thấp Bài viết này chia sẻ câu chuyện thành công của Derive trong việc xây dựng nền tảng giao dịch phi tập trung lai (hybrid DEX) với độ trễ cực thấp và khả năng xử lý hàng tỷ đô la khối lượng giao dịch. Bạn sẽ khám phá kiến trúc sử dụng AWS Graviton trên Amazon EKS kết hợp với Amazon Aurora để tối ưu hóa hiệu năng tính toán, quản lý rủi ro và xử lý khớp lệnh tốc độ cao, đồng thời tìm hiểu về mô hình kết hợp giữa hiệu quả tập trung và bảo mật phi tập trung.\nBlog 3 - SQL to NoSQL: Hiện đại hóa lớp truy cập dữ liệu với Amazon DynamoDB Đây là phần cuối trong loạt bài về di chuyển từ SQL sang NoSQL, tập trung vào việc thiết kế lớp truy cập dữ liệu hiệu quả cho Amazon DynamoDB. Blog hướng dẫn chi tiết về cách xử lý các mô hình truy cập phức tạp như thiết kế lớp trừu tượng API, xử lý bộ lọc (filtering), thực hiện phân trang (pagination), quản lý các trường hợp biên và thực hiện các phép tổng hợp dữ liệu (aggregations) để tối ưu hóa hiệu suất ứng dụng.\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"CÁCH DERIVE MỞ RỘNG NỀN TẢNG GIAO DỊCH PHI TẬP TRUNG ĐỘ TRỄ THẤP BẰNG AWS GRAVITON, AMAZON EKS VÀ AMAZON AURORA Tác giả: Daniel Wirjo, Christoph Niemann, Dillon Lin, và Joshua Kim Ngày: 04/06/2025 Chuyên mục: Amazon Aurora, Amazon Elastic Kubernetes Service, Blockchain, Customer Solutions, Graviton, Intermediate (200)\nĐây là bài viết cộng tác của Joshua Kim, Trưởng nhóm Kỹ thuật tại Derive, và Dillon Lin, Trưởng nhóm Phát triển tại Derive, phối hợp cùng AWS.\nThị trường phái sinh được dự báo sẽ tăng trưởng mạnh mẽ trong thập kỷ tới, được thúc đẩy bởi sự gia tăng tham gia của các tổ chức, đổi mới công nghệ và xu hướng chuyển dịch sang mô hình on-chain, tokenization và tài chính phi tập trung (DeFi). Khi thị trường toàn cầu đối mặt với nhiều biến động, phái sinh đang trở thành công cụ thiết yếu để quản lý rủi ro và tận dụng cơ hội. Sự hội tụ giữa các công cụ tài chính truyền thống và công nghệ blockchain này được kỳ vọng sẽ định hình lại toàn cảnh thị trường phái sinh, mang đến những cơ hội tăng trưởng và đổi mới mới trong ngành.\nTrong bài viết này, chúng tôi chia sẻ cách Derive đã mở rộng thành công nền tảng giao dịch phi tập trung lai (hybrid decentralized trading platform) của họ - đạt được hàng tỷ đô la khối lượng giao dịch và độ trễ cực thấp, bằng cách sử dụng cơ sở hạ tầng tính toán và cơ sở dữ liệu mạnh mẽ, kết hợp AWS Graviton trên Amazon Elastic Kubernetes Service (Amazon EKS) và Amazon Aurora. Chúng tôi cũng khám phá mô hình sàn giao dịch lai của Derive và vai trò quan trọng mà AWS đã đóng góp trong quá trình tăng trưởng và mở rộng quy mô của họ.\nTổng quan: Mô hình sàn giao dịch lai độc đáo của Derive Derive là một giao thức DeFi tạo ra các sản phẩm phái sinh on-chain có thể lập trình và tùy chỉnh, bao gồm options (quyền chọn), perpetuals (hợp đồng vĩnh viễn) và các sản phẩm cấu trúc khác.\nNền tảng này vận hành theo mô hình lai (hybrid model) – kết hợp hiệu quả của việc khớp lệnh tập trung với tính bảo mật và minh bạch của việc thanh toán phi tập trung và quản lý ký quỹ trên Derive chain, được xây dựng trên OP Stack, một blockchain Ethereum Layer 2 mã nguồn mở. Cách tiếp cận này cho phép Derive mang đến trải nghiệm giao dịch liền mạch tương tự như các sàn tập trung (CEX), đồng thời vẫn đảm bảo người dùng kiểm soát tài sản của mình.\nĐiều này được hỗ trợ bởi hệ thống ký quỹ dựa trên đấu giá mở, giúp tăng tính minh bạch và giảm rủi ro thường thấy trong các hệ thống tập trung truyền thống nơi tài sản dự trữ do một bên trung tâm quản lý.\nMặc dù Derive cung cấp các sản phẩm giao dịch tiêu chuẩn như perpetuals và spot trading, nhưng trọng tâm cốt lõi của họ là phục vụ các nhà giao dịch chuyên nghiệp và tổ chức. Giải pháp của Derive cung cấp thanh khoản on-chain cho các quyền chọn phi tập trung (decentralized options), thông qua order book và hệ thống Request-for-Quote (RFQ) mạnh mẽ - cho phép thực hiện các chiến lược giao dịch nâng cao và tối ưu hóa việc khám phá giá (price discovery) trong thị trường phi tập trung.\nVới sự tăng trưởng nhanh chóng của cơ sở người dùng và khối lượng giao dịch, Derive cần đảm bảo rằng hạ tầng của họ có thể xử lý nhu cầu ngày càng tăng mà không ảnh hưởng đến hiệu suất, ngay cả khi đội ngũ kỹ thuật tinh gọn và trong những giai đoạn biến động thị trường cao.\nTổng quan giải pháp Sơ đồ sau minh họa kiến trúc tổng thể cho nền tảng có hiệu suất cao và độ trễ thấp của Derive.\nKiến trúc tổng thể bao gồm nhiều thành phần chính, được trình bày chi tiết bên dưới.\nTính toán hiệu năng cao\nKiến trúc của Derive bao gồm hệ thống tính toán hiệu năng cao (high-performance compute) chạy trên Graviton nodes, được triển khai theo kiến trúc microservices trong Amazon EKS. Điều này mang lại độ trễ thấp và khả năng mở rộng cao, giúp xử lý giao dịch nhanh chóng.\nCác microservice được thiết kế theo mô-đun và có thể mở rộng ngang (horizontally scalable), giúp hệ thống xử lý khối lượng giao dịch lớn một cách hiệu quả, với các dịch vụ chuyên biệt cho những chức năng cốt lõi sau:\nCore matching engine: Được xây dựng bằng Rust để đạt độ trễ thấp; chịu trách nhiệm xử lý lệnh, khớp giao dịch và quản lý trạng thái. Risk management: Các microservice chuyên dụng đảm nhận tính toán rủi ro tiêu chuẩn và danh mục đầu tư, đảm bảo tuân thủ và bảo vệ nền tảng lẫn người dùng. Emitters: Các dịch vụ như Orderbook Emitter và Ticker Emitter phát sóng các thay đổi trạng thái và cập nhật giá đến hệ thống và người dùng bên ngoài. Additional microservices: Kiến trúc có thể mở rộng, hỗ trợ việc bổ sung các microservice mới khi cần cho sự phát triển trong tương lai. Cơ sở dữ liệu\nCác microservice giao dịch dữ liệu trên PostgreSQL trong Amazon Aurora, tận dụng khả năng mở rộng và độ tin cậy cao của hệ thống này.\n“Trong ngày ra mắt, chúng tôi có hơn 50.000 người dùng chỉ trong một ngày, thực hiện hơn 50 triệu yêu cầu API khi giao dịch. Amazon Aurora đã đóng vai trò then chốt trong việc giúp chúng tôi nhanh chóng mở rộng cơ sở dữ liệu để xử lý lượng yêu cầu đọc khổng lồ.” — Josh Kim, Trưởng nhóm Kỹ thuật tại Derive.\nTổng hợp và thanh toán blockchain\nMô hình sàn giao dịch lai của Derive yêu cầu một thành phần quản lý việc tổng hợp (aggregation rollup) và thanh toán (settlement) giao dịch, kết nối với các microservice để hoàn tất giao dịch.\nĐể thực hiện thanh toán, Derive xây dựng blockchain Layer 2 dựa trên Ethereum, dùng OP Stack mã nguồn mở làm giải pháp mở rộng quy mô. Cách tiếp cận này mang lại tốc độ xử lý cao, chi phí thấp và kế thừa bảo mật từ Ethereum, cân bằng giữa tốc độ và an toàn.\nKim giải thích: \u0026ldquo;Các sàn lai thêm một tầng phức tạp mới cho giao dịch độ trễ thấp, vì chúng yêu cầu tự quản lý tài sản (self-custody) thông qua chữ ký lệnh mật mã và xác thực rủi ro on-chain theo thời gian thực, ngay cả khi việc khớp lệnh diễn ra off-chain. Một ví dụ điển hình là nhà giao dịch tần suất cao bị thanh lý on-chain trong khi đang gửi hàng nghìn lệnh đến sàn Derive. Engine khớp lệnh cần có khả năng truy cập nhanh vào trạng thái giao thức on-chain và xử lý song song một số khối lượng công việc nhất định.\u0026rdquo;\nKiến trúc hướng sự kiện (Event-driven architecture)\nCác yêu cầu của người dùng được xử lý thông qua các endpoint WebSocket và REST API, đảm bảo bảo mật và hiệu quả khi quản lý lệnh và dữ liệu thị trường. Hệ thống hàng đợi dựa trên Valkey điều phối việc xếp hàng và xử lý lệnh đến, đồng thời cơ chế giới hạn tốc độ (rate limiter) đảm bảo công bằng và ngăn chặn lạm dụng.\nĐể phát dữ liệu thị trường theo thời gian thực và cập nhật lệnh với độ trễ tối thiểu, cơ chế publish/subscribe dựa trên Valkey giúp truyền tải sự kiện đến tất cả các client được kết nối một cách hiệu quả. Kiến trúc còn bao gồm event streaming để theo dõi và ghi lại thay đổi trạng thái phục vụ các microservice hạ tầng. Cách tiếp cận hướng sự kiện này sử dụng NATS, được triển khai trên Amazon EKS, giúp đảm bảo tính mở rộng và độ tin cậy cho toàn bộ nền tảng.\nKim cho biết: \u0026ldquo;Ngoài việc xây dựng engine bằng Rust hiệu năng cao, chúng tôi còn phát triển nhiều thành phần nội bộ đặc thù – một trong số đó là hệ thống hàng đợi tùy chỉnh để định tuyến lệnh trong phạm vi độ trễ cực thấp. Đội ngũ AWS đã hỗ trợ tuyệt vời qua nhiều phiên brainstorm kỹ thuật trực tiếp với các chuyên gia nội bộ, giúp cải thiện tốc độ thực thi đáng kể. Ngay sau khi ra mắt, sàn giao dịch đã xử lý khối lượng 3,7 tỷ đô la và giao dịch gần 1 triệu lệnh on-chain chỉ trong một tháng.\u0026rdquo;\nBảo mật\nBên cạnh lớp bảo mật vốn có của việc thanh toán phi tập trung, Derive còn sử dụng các dịch vụ bảo mật của AWS như AWS Control Tower (Quản trị đám mây tập trung), AWS IAM Identity Center (Quản lý danh tính đơn giản hóa), AWS Key Management Service (AWS KMS – Mã hóa an toàn), Amazon GuardDuty (Phát hiện mối đe dọa thông minh). Nhờ đó, Derive có thể đáp ứng các yêu cầu bảo mật nghiêm ngặt và tiêu chuẩn cao mà các nhà đầu tư tổ chức kỳ vọng.\nHợp tác với AWS Derive đã hợp tác với AWS ngay từ khi khởi đầu, tham gia chương trình AWS Activate dành cho startup. Sau khi nhận đầu tư từ Coinbase Ventures và Framework Ventures (đều là nhà cung cấp AWS Activate), Derive đã có thể truy cập tín dụng AWS hỗ trợ cho phát triển sản phẩm.\nDominic Romanowski, Đồng sáng lập Derive, chia sẻ: “Đội ngũ AWS Startups đóng vai trò cực kỳ quan trọng trong hành trình của chúng tôi - mang lại nguồn tài trợ, công cụ và chuyên môn giúp chúng tôi đổi mới trong không gian DeFi. Bằng cách tận dụng sức mạnh của hạ tầng AWS, chúng tôi không chỉ tối ưu chi phí, mà còn đảm bảo nền tảng mở rộng liền mạch để đáp ứng nhu cầu ngày càng tăng, đồng thời giữ vững bảo mật. Điều đó giúp chúng tôi tập trung vào điều quan trọng nhất: xây dựng nền tảng giao dịch hiệu năng cao cho cả khách hàng tổ chức và bán lẻ.”\nDerive cũng làm việc chặt chẽ với các chuyên gia chuyên môn của AWS trong nhiều lĩnh vực, bao gồm tính toán, cơ sở dữ liệu và Web3, để giải quyết các thách thức kỹ thuật độc đáo và tăng tốc phát triển. Romanowski nói thêm: \u0026ldquo;Thật yên tâm khi biết rằng chúng tôi có thể gọi và nhận tư vấn chuyên sâu bất cứ khi nào cần.\u0026rdquo;.\nLộ trình tiếp theo Nhìn về phía trước, Derive cam kết liên tục nâng cao năng lực và giảm độ trễ. Trong lộ trình sắp tới, Derive tập trung vào hai sáng kiến chính:\nKhả năng phát lại và kiểm toán toàn diện (replay \u0026amp; audit): Cho phép người dùng phát lại chính xác các lệnh và giao dịch, phục vụ khách hàng tổ chức cần dữ liệu lịch sử chi tiết để debug thuật toán và đảm bảo công bằng. Tích hợp sâu hơn với Ethereum Virtual Machine (EVM): Biến Derive thành một phần mở rộng tự nhiên của node EVM. Cách tiếp cận này giúp giảm sai lệch giữa số dư trên sàn và trạng thái on-chain, đơn giản hóa cấu trúc dữ liệu thị trường, tài khoản và giao dịch, và trong tương lai cho phép người dùng tích hợp liền mạch các thành phần của Derive với các giao thức khác.\nDillon Lin, Trưởng nhóm Phát triển tại Derive, cho biết: “Chúng tôi tin rằng những phát triển này sẽ đưa Derive trở thành người dẫn đầu trong giao dịch blockchain-native, đồng thời mở đường cho những đổi mới rộng hơn trong ngành.”.\nKết luận Bằng việc sử dụng các dịch vụ AWS, Derive có thể tập trung vào đổi mới và mở rộng danh mục sản phẩm trong tokenization và phái sinh phi tập trung. Sự kết hợp này giúp Derive mở rộng quy mô thành công, mang lại môi trường giao dịch an toàn và hiệu quả, đáp ứng nhu cầu ngày càng phát triển của các tổ chức tài chính.\nLin khẳng định: “Khi chúng tôi tiếp tục đổi mới trong lĩnh vực DeFi và đáp ứng nhu cầu ngày càng tăng về phái sinh on-chain, sự hợp tác với AWS vẫn là yếu tố then chốt. Sự hỗ trợ của họ đóng vai trò cực kỳ quan trọng trong hành trình của chúng tôi, giúp mở rộng hiệu quả và cung cấp giải pháp phù hợp với nhu cầu của các nhà đầu tư tổ chức. Chúng tôi mong muốn tiếp tục hợp tác với AWS để mở rộng nền tảng hơn nữa.”\nTài nguyên tham khảo:\nTìm hiểu thêm về phái sinh phi tập trung tại Derive và Developer Hub của họ. Tìm hiểu thêm về Web3 trên AWS. Tìm hiểu thêm về AWS Startups tại startups.aws. Về tác giả Joshua Kim: Trưởng bộ phận Kỹ thuật tại Derive, lãnh đạo phát triển hạ tầng phái sinh. Từng làm việc tại Apple và sở hữu nhiều bằng sáng chế.\nDillon Lin: Trưởng bộ phận Phát triển tại Derive, phụ trách chiến lược go-to-market và phân phối cho người dùng bán lẻ và tổ chức.\nDaniel Wirjo: Kiến trúc sư Giải pháp tại AWS, hỗ trợ các startup và từng là CTO của một startup.\nChristoph Niemann: Kiến trúc sư Blockchain Cao cấp tại AWS, đam mê công nghệ Blockchain.\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.7-dashboard-setup/5.7.3-setup-api-gateway/","title":"Cài đặt API Gateway","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một API Gateway để định tuyến cuộc gọi api từ dashboard tới Lambda.\nTạo API Gateway Mở API Gateway Console\nĐiều hướng tới https://console.aws.amazon.com/apigateway/ Hoặc: AWS Management Console → Services → API Gateway Tạo API:\nNhấn Create API Chọn REST API và nhấn Build Sử dụng cài đặt này để tạo: Chọn New API Name: dashboard-api API endpoint type: Regional Security policy: SecurityPolicy_TLS13_1_3_2025_09 Endpoint access mode: Basic IP address type: IPv4 Tạo Resources:\nBật CORS cho root resource Nhấn Create resource và đặt tên là logs Sau đó nhấn vào tài nguyên /logs vừa tạo và nhấn Create Resource để tạo tài nguyên con của /logs Đặt tên là cloudtrail và bật CORS Lặp lại ba lần nữa cho eni_logs, guardduty và vpc Tạo methods:\nNhấn vào /cloudtrail vừa tạo và nhấn Create method\nTrong phần tạo method, sử dụng cài đặt này:\nMethod type: GET Intergration type: Lambda function Bật Lambda proxy intergration chọn Buffered Lambda function: chọn region của bạn, tìm kiếm dashboard-query và chọn nó Timout: 29000 Lặp lại ba lần nữa cho eni_logs, guardduty và vpc\nTriển khai API (Deploy API):\nNhấn Deploy API ở góc phải Trong phần deploy API, sử dụng cài đặt này: Stage: New stage Name: prod Nhấn Deploy "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.3-cloudwatch-etl/","title":"Mã CloudWatch ETL","tags":[],"description":"","content":"import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.3-create-iam-policy/","title":"Tạo IAM Policy","tags":[],"description":"","content":"Tạo IAM Quarantine Policy Tạo IrQuarantineIAMPolicy Điều hướng đến IAM Console → Policies → Create policy\nPolicy JSON:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Policy name: IrQuarantineIAMPolicy Description: Deny-all policy for quarantining compromised IAM users "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/","title":"Tạo IAM Roles và Policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo 17 IAM roles cùng với các policies liên quan cho Lambda functions, Firehose streams, Step Functions, và các dịch vụ khác.\nTổng quan về IAM Roles Lambda Execution Roles (9 roles):\nCloudTrailETLLambdaServiceRole GuardDutyETLLambdaServiceRole CloudWatchETLLambdaServiceRole CloudWatchENIETLLambdaServiceRole CloudWatchExportLambdaServiceRole ParseFindingsLambdaServiceRole IsolateEC2LambdaServiceRole QuarantineIAMLambdaServiceRole AlertDispatchLambdaServiceRole Service Roles (6 roles): 10. CloudTrailFirehoseRole 11. CloudWatchFirehoseRole 12. StepFunctionsRole 13. IncidentResponseStepFunctionsEventRole 14. FlowLogsIAMRole 15. GlueCloudWatchRole\nIAM Policy (1 policy): 16. IrQuarantineIAMPolicy\nNội dung Tạo Lambda Execution Roles Tạo Service Roles Tạo IAM Policy "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.5-processing-setup/5.5.3-create-lambda-function-etl-processing/","title":"Tạo Lambda Function - Xử lý ETL","tags":[],"description":"","content":"Tạo Lambda Functions - Xử lý ETL Trong phần này, bạn sẽ tạo 5 Lambda functions để xử lý logs và gửi chúng đến Kinesis Firehose hoặc S3.\nincident-response-cloudtrail-etl Runtime: Python 3.12 Handler: CloudTrailETL.lambda_handler Role: CloudTrailETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: FIREHOSE_STREAM_NAME=cloudtrail-firehose-stream Code: cloudtrail-etl incident-response-guardduty-etl Runtime: Python 3.12 Handler: guardduty_etl.lambda_handler Role: GuardDutyETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: DESTINATION_BUCKET, S3_LOCATION_GUARDDUTY, DATABASE_NAME, TABLE_NAME_GUARDDUTY Code: guardduty-etl cloudwatch-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_etl.lambda_handler Role: CloudWatchETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-dns-firehose-stream Code: cloudwatch-etl cloudwatch-eni-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_eni_etl.lambda_handler Role: CloudWatchENIETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-flow-firehose-stream Code: cloudwatch-eni-etl cloudwatch-export-lambda Runtime: Python 3.12 Handler: cloudwatch_autoexport.lambda_handler Role: CloudWatchExportLambdaServiceRole Env: DESTINATION_BUCKET=incident-response-log-list-bucket-ACCOUNT_ID-REGION Code: cloudwatch-autoexport Cấu hình CloudWatch Logs Subscription Filter Cấu hình Subscription Filter Mở CloudWatch Console.\nỞ ngăn điều hướng bên trái, chọn Log Management.\nNhấn vào centralized log group: /aws/incident-response/centralized-logs.\nTạo Subscription Filter:\nNhấn vào tab \u0026ldquo;Subscription filters\u0026rdquo;. Nhấn \u0026ldquo;Create Lambda subscription filter\u0026rdquo;. Cấu hình Destination:\nDestination Lambda function: Chọn function cloudwatch-export-lambda. Log format: Chọn \u0026ldquo;Other\u0026rdquo;. (Điều này đảm bảo dữ liệu log thô được chuyển đi hiệu quả để Lambda xử lý). Cấu hình Log Format và Filter:\nSubscription filter name: Nhập tên mô tả, ví dụ, VPC-Log-Export-Filter. Filter pattern: Để trống trường này blank. (Đảm bảo tất cả logs trong group đều được xử lý). Nhấn \u0026ldquo;Start streaming\u0026rdquo;.\nCấu hình S3 Event Notifications S3 Console → incident-response-log-list-bucket-ACCOUNT_ID-REGION → Properties → Event notifications\nTạo 4 notifications với Event types/Object creation/✅All object create events:\nCloudTrailETLTrigger: Prefix AWSLogs/ACCOUNT_ID/CloudTrail/ → Lambda incident-response-cloudtrail-etl VPCDNSLogsTrigger: Prefix exportedlogs/vpc-dns-logs/ → Lambda cloudwatch-etl-lambda VPCFlowLogsTrigger: Prefix exportedlogs/vpc-flow-logs/ → Lambda cloudwatch-eni-etl-lambda GuardDutyFindingsTrigger: Prefix AWSLogs/ACCOUNT_ID/GuardDuty/ → Lambda incident-response-guardduty-etl "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.3-foundation-setup/","title":"Thiết lập nền tảng","tags":[],"description":"","content":"Giai đoạn Thiết lập nền tảng ban đầu này xây dựng các điều kiện tiên quyết cốt lõi cho Hệ thống Phản hồi Sự cố Tự động, tập trung vào việc triển khai lưu trữ chuyên dụng và ủy quyền bảo mật thiết yếu. Điều này bắt buộc phải tạo năm Amazon S3 buckets an toàn để thu thập và xử lý log tập trung, áp dụng Bucket Policy cần thiết để phân phối log an toàn, và định nghĩa 17 IAM roles cùng chính sách cách ly (quarantine policy) để thực thi quyền truy cập đặc quyền tối thiểu (least-privilege access) trên tất cả các dịch vụ AWS được tích hợp.\nNội dung Thiết lập Amazon S3 Bucket Cấu hình S3 Bucket Policy cho Primary Log Bucket Tạo IAM Roles và Policies "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/4-eventparticipated/4.4-event4/","title":"Sự kiện 4","tags":[],"description":"","content":"Báo cáo tóm tắt: “AWS Cloud Mastery Series #3: AWS Well-Architected – Security Pillar Workshop” Mục tiêu sự kiện Giới thiệu về AWS Cloud Club Trụ cột 1: Quản lý Danh tính \u0026amp; Truy cập (IAM) Trụ cột 2: Phát hiện \u0026amp; Giám sát liên tục Trụ cột 3: Bảo vệ Cơ sở hạ tầng Trụ cột 4: Bảo vệ Dữ liệu Trụ cột 5: Ứng phó sự cố Diễn giả Lê Vũ Xuân An - Chủ nhiệm AWS Cloud Club HCMUTE\nTrần Đức Anh - Chủ nhiệm AWS Cloud Club SGU\nTrần Đoàn Công Lý - Chủ nhiệm AWS Cloud Club PTIT\nDanh Hoàng Hiếu Nghi - Chủ nhiệm AWS Cloud Club HUFLIT\nHuỳnh Hoàng Long - AWS Community Builders\nĐinh Lê Hoàng Anh - AWS Community Builders\nNguyễn Tuấn Thịnh - Thực tập sinh Kỹ sư Cloud\nNguyễn Đỗ Thành Đạt - Thực tập sinh Kỹ sư Cloud\nVăn Hoàng Kha - Kỹ sư Bảo mật Cloud, AWS Community Builder\nThịnh Lâm - Thành viên FCJ\nViệt Nguyễn - Thành viên FCJ\nMendel Grabski (Long) - Cựu Trưởng bộ phận Bảo mật \u0026amp; DevOps, Kiến trúc sư Giải pháp Bảo mật Cloud\nTình Trương - Kỹ sư Nền tảng tại TymeX, AWS Community Builder\nCác điểm nổi bật chính AWS Cloud Club Giới thiệu về AWS Cloud Club:\nGiúp khám phá và phát triển kỹ năng điện toán đám mây Phát triển khả năng lãnh đạo kỹ thuật Xây dựng các kết nối có ý nghĩa trên toàn cầu Cung cấp trải nghiệm thực tế với AWS, sự cố vấn từ các chuyên gia AWS và hỗ trợ sự nghiệp lâu dài. Các AWS Cloud Club thuộc FCJA:\nAWS Cloud Club HCMUTE AWS Cloud Club SGU AWS Cloud Club PTIT AWS Cloud Club HUFLIT Lợi ích: Xây dựng Kỹ năng, Cộng đồng và Cơ hội.\nQuản lý Danh tính \u0026amp; Truy cập (IAM) IAM là một dịch vụ AWS thiết yếu, chịu trách nhiệm kiểm soát truy cập an toàn. IAM quản lý Người dùng (Users), Nhóm (Groups), Vai trò (Roles) và Quyền hạn (Permissions), đảm bảo cả việc xác thực (authentication) và ủy quyền (authorization).\nCác thực hành tốt nhất (Best Practices) bao gồm:\nNguyên tắc đặc quyền tối thiểu (Least Privilege Principle).\nXóa access keys của tài khoản root sau khi tạo.\nTránh dùng \u0026ldquo;*\u0026rdquo; trong Actions/Resources.\nSử dụng Đăng nhập một lần (SSO) để tích hợp đa tài khoản và quản lý truy cập tập trung.\nService Control Policies (SCPs): Các chính sách cấp Tổ chức đặt ra quyền hạn tối đa khả dụng cho tất cả các tài khoản trong một Tổ chức. SCP chỉ lọc quyền; chúng không bao giờ cấp quyền.\nPermission Boundaries: Thiết lập quyền hạn tối đa mà một identity-based policy có thể cấp cho một User/Role cụ thể trong tài khoản.\nMFA (Xác thực đa yếu tố):\nTOTP (Time-based One-Time Password) FIDO2 (Fast Identity Online 2) Bí mật chia sẻ (Shared secret) Mật mã khóa công khai (Public-key cryptography) Yêu cầu nhập thủ công mã 6 chữ số Yêu cầu chạm đơn giản hoặc quét sinh trắc học Miễn phí Chi phí thay đổi tùy loại Sao lưu và khôi phục linh hoạt Sao lưu nghiêm ngặt và không thể khôi phục Xoay vòng thông tin xác thực (Credential Rotation) với AWS Secrets Manager:\nCredential Updater sử dụng các hàm của Secrets Manager theo chu kỳ: Tạo Secret, Thiết lập Secret (ví dụ: mỗi 7 ngày), Kiểm tra Secret, và Hoàn tất Secret. Các sự kiện xoay vòng có thể được gửi đến EventBridge Schedule để kiểm soát thời gian. Cuối cùng là loại bỏ Secret cũ. Phát hiện và Giám sát liên tục Khả năng hiển thị bảo mật đa lớp:\nManagement Events:** Các lệnh gọi API và hành động trên console trên tất cả các tài khoản của tổ chức. Data Events:** Truy cập đối tượng S3 và thực thi Lambda ở quy mô lớn. Network Activity Events:** Tích hợp VPC Flow Logs để giám sát cấp độ mạng. Organization Coverage:** Ghi log thống nhất trên tất cả các tài khoản thành viên và các region. Cảnh báo \u0026amp; Tự động hóa với EventBridge\nSự kiện thời gian thực: Các sự kiện CloudTrail chuyển đến EventBridge để xử lý ngay lập tức. Đây là nền tảng của Kiến trúc hướng sự kiện (EDA), cho phép hệ thống phản ứng với các thay đổi khi chúng xảy ra.\nCảnh báo tự động: Phát hiện các hoạt động đáng ngờ trên tất cả các tài khoản của tổ chức.\nĐịnh tuyến sự kiện chéo tài khoản: Xử lý sự kiện tập trung và phản hồi tự động. EventBridge làm cho việc này trở nên liền mạch, định tuyến sự kiện dựa trên các quy tắc đến các đích trên các tài khoản hoặc region khác nhau.\nTích hợp \u0026amp; Quy trình làm việc: Tích hợp Lambda, SNS, SQS cho các quy trình bảo mật tự động.\nPhát hiện dưới dạng mã (Detection-as-Code):\nCloudTrail Lake Queries: Tạo và sử dụng các quy tắc phát hiện dựa trên SQL để săn tìm mối đe dọa nâng cao.\nLogic được kiểm soát phiên bản: Các quy tắc và logic phát hiện được theo dõi và quản lý thông qua kho lưu trữ mã (code repositories).\nTriển khai tự động: Các trails và quy tắc phát hiện được triển khai tự động trên tất cả các tài khoản liên quan của tổ chức, đảm bảo phạm vi bảo mật đồng nhất.\nCơ sở hạ tầng dưới dạng mã (IaC): Sử dụng các công cụ IaC để thiết lập và cấu hình tự động việc ghi log và event trails của tổ chức.\nGuard Duty GuardDuty là giải pháp Phát hiện Mối đe dọa Thông minh, Luôn bật (Always-On).\nCách GuardDuty hoạt động – Dựa vào phân tích liên tục Ba Trụ cột Phát hiện:\nNguồn dữ liệu Những gì nó giám sát Ví dụ thực tế CloudTrail Events Hành động IAM, thay đổi quyền, gọi API Kẻ tấn công tắt logging để xóa dấu vết. VPC Flow Logs Lưu lượng mạng đến/đi từ tài nguyên của bạn EC2 gửi dữ liệu đến máy chủ điều khiển botnet (C2). DNS Logs Các truy vấn DNS từ hạ tầng của bạn Các truy vấn nhiễm mã độc đến các trang đào tiền ảo. Các gói bảo vệ nâng cao: GuardDuty cung cấp các tiện ích phát hiện chuyên biệt để bảo vệ toàn diện:\nS3 Protection: Phát hiện các mẫu truy cập S3 bất thường và quét mã độc trong các đối tượng S3 tại thời điểm tải lên.\nEKS Protection: Giám sát nhật ký kiểm toán Kubernetes để phát hiện truy cập trái phép và liên kết các phát hiện với S3 để lập bản đồ đường đi tấn công đầy đủ.\nMalware Protection: Tự động quét các volume EBS của các instance EC2 khi nghi ngờ bị xâm nhập.\nRDS Protection: Phân tích nhật ký hoạt động đăng nhập vào cơ sở dữ liệu (Aurora/RDS) và phát hiện các cuộc tấn công brute-force (nhiều lần đăng nhập thất bại từ một IP duy nhất).\nLambda Protection: Giám sát nhật ký mạng từ các lệnh gọi hàm Lambda và phát hiện nếu một hàm bị xâm nhập gửi dữ liệu đến các IP độc hại.\nRuntime Monitoring – Sâu bên trong hệ điều hành: Đạt được bằng cách sử dụng GuardDuty Agent cài đặt trên EC2/EKS/ECS Fargate. Nó giám sát các tiến trình đang chạy, mẫu truy cập tệp, lệnh gọi hệ thống và các nỗ lực leo thang đặc quyền hoặc reverse shells.\nCác tiêu chuẩn tuân thủ:\nAWS Foundational Security Best Practices: Được phát triển bởi AWS và bao gồm một loạt các dịch vụ AWS.\nCIS AWS Foundations Benchmark: Được phát triển bởi AWS và các chuyên gia trong ngành, tập trung vào Danh tính (IAM), Ghi log \u0026amp; Giám sát, và Mạng.\nThực thi tuân thủ với Detection-as-Code\nCông cụ IaC: AWS CloudFormation được sử dụng để triển khai các cấu hình.\nCông cụ tuân thủ: AWS CloudFormation đẩy các kiểm tra cấu hình lên AWS Security Hub CSPM.\nÁp dụng Tiêu chuẩn tuân thủ: Security Hub thực hiện kiểm tra dựa trên các tiêu chuẩn đã liệt kê (AWS Foundational Security Best Practices, CIS AWS Foundations Benchmark, PCI DSS, NIST).\nTài nguyên bao gồm: Amazon S3, Amazon EC2 và Amazon RDS.\nKiểm soát An ninh Mạng Các véc-tơ tấn công: Các mối đe dọa được phân loại thành Tấn công đầu vào - Ingress (DDoS, SQL injection), Tấn công đầu ra - Egress (trích xuất dữ liệu, DNS tunneling), và Tấn công nội bộ - Inside (di chuyển ngang).\nSecurity Groups (SG): Hoạt động như một tường lửa có trạng thái (Stateful) ở cấp độ instance/giao diện mạng. Chúng chỉ hỗ trợ quy tắc cho phép (allow rules) và mặc định từ chối tất cả (implicit deny all).\nNetwork ACLs (NACLs): Hoạt động ở cấp độ subnet. Chúng là phi trạng thái (stateless) và sử dụng các quy tắc được đánh số để CHO PHÉP (ALLOW) hoặc TỪ CHỐI (DENY) lưu lượng truy cập một cách rõ ràng.\nAWS TGW Security Group Referencing: Cho phép Transit Gateway (TGW) VPCs xác định các quy tắc Inbound chỉ sử dụng tham chiếu SG.\nRoute 53 Resolver: Định tuyến các truy vấn DNS đến Private DNS (private hosted zones), VPC DNS hoặc Public DNS.\nAWS Network Firewall:\nTrường hợp sử dụng: Lọc đầu ra (chặn tên miền xấu, giao thức độc hại), Phân đoạn môi trường (VPC tới VPC), và Ngăn chặn xâm nhập (quy tắc IDS/IPS).\nPhòng thủ chủ động: Có thể tự động chặn lưu lượng độc hại bằng cách sử dụng Amazon Threat Intelligence, nơi các phát hiện của GuardDuty được đánh dấu để chặn tự động.\nQuản trị \u0026amp; Bảo vệ Dữ liệu Mã hóa (KMS): Dữ liệu được mã hóa bằng Data Key, được bảo vệ bởi Master Key (CMK). Các chính sách KMS thực thi lớp bảo mật thứ hai với các Condition keys để xác định KHI NÀO việc mã hóa/giải mã được cho phép.\nQuản lý Chứng chỉ (ACM): Cung cấp chứng chỉ công khai miễn phí và tự động gia hạn chứng chỉ 60 ngày trước khi hết hạn. Xác thực DNS là phương pháp xác thực được khuyến nghị.\nSecrets Manager: Giải quyết vấn đề thông tin xác thực bị hardcode. Nó sử dụng logic Lambda 4 bước (createSecret, setSecret, testSecret, finishSecret) để tự động xoay vòng thông tin xác thực mà không gây gián đoạn (downtime).\nBảo mật Dịch vụ API (S3 \u0026amp; DynamoDB): S3 yêu cầu TLS 1.2+ và bucket policies với aws:SecureTransport để thực thi. DynamoDB được bảo mật mặc định với HTTPS bắt buộc.\nBảo mật Dịch vụ Cơ sở dữ liệu (RDS): Yêu cầu sự tin cậy phía máy khách vào AWS Root CA Bundle để xác minh danh tính máy chủ, và thực thi phía máy chủ (ví dụ: rds.force_ssl=1 cho PostgreSQL).\nỨng phó sự cố \u0026amp; Phòng ngừa Các phương pháp phòng ngừa tốt nhất: Các bước chính bao gồm sử dụng thông tin xác thực tạm thời, không bao giờ để lộ trực tiếp các S3 buckets, đặt các dịch vụ nhạy cảm sau các private subnets, quản lý mọi thứ thông qua Infrastructure as Code, và sử dụng quy trình thay đổi rủi ro cao với hai lớp kiểm soát (phê duyệt PR, triển khai pipeline).\nQuy trình Ứng phó sự cố: Một phương pháp tiếp cận có cấu trúc gồm 5 bước: Chuẩn bị, Phát hiện \u0026amp; Phân tích, Ngăn chặn (cô lập, thu hồi thông tin xác thực), Loại bỏ \u0026amp; Khôi phục, và Sau sự cố (bài học kinh nghiệm).\nTrải nghiệm sự kiện Sự kiện này cực kỳ hữu ích cho nhóm chúng tôi, phù hợp trực tiếp với dự án về Tự động Ứng phó Sự cố và Điều tra số (Forensics) của nhóm.\nHỏi: Dự án của nhóm em là một công cụ Tự động Ứng phó Sự cố và Điều tra số với GuardDuty là trọng tâm chính của việc phản hồi sự cố, nhưng qua thử nghiệm, bọn em thấy rằng GuardDuty có thể mất tới 5 phút để tạo ra một finding (phát hiện) khi sự cố xảy ra. Em muốn hỏi có giải pháp nào để giảm độ trễ này không ạ?\nĐáp: Việc GuardDuty mất 5 phút để tạo ra các phát hiện là điều bạn phải chấp nhận, vì đó là cách GuardDuty được cấu hình để hoạt động: GuardDuty phải đi qua một lượng lớn bộ dữ liệu bảo mật để xác định mối đe dọa chính xác và sau đó tạo ra finding. Tuy nhiên, nếu bạn muốn giảm độ trễ, một trong những cách để giải quyết là tích hợp các dịch vụ bảo mật của bên thứ 3 như: Open Clarity (Miễn phí) cho các phát hiện gần như thời gian thực và bạn cũng có thể phát hiện các bất thường và hành vi người dùng lạ với CloudTrail.\nÔng Mendel Grabski rất nhiệt tình đề nghị hỗ trợ khi chúng tôi hỏi về dự án của mình sau sự kiện.\nMột số hình ảnh sự kiện Ảnh chụp nhóm cùng Diễn giả Mendel Grabski và Diễn giả Văn Hoàng Kha\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/4-eventparticipated/","title":"Sự kiện đã tham gia","tags":[],"description":"","content":"Báo cáo tóm tắt: “Chuỗi làm chủ AWS Cloud #1 - AI/ML/GenAI trên AWS” Mục tiêu sự kiện Giới thiệu về AI/ML/GenAI trên AWS Diễn giả Lam Tuan Kiet – Kỹ sư DevOps cấp cao, FPT Software Danh Hoang Hieu Nghi - Kỹ sư AI, Renova Cloud Dinh Le Hoang Anh - Thực tập sinh Kỹ sư đám mây, First Cloud AI Journey Van Hoang Kha - Kỹ sư bảo mật đám mây, AWS Community Builder Những điểm nổi bật Khám phá Generative AI với Amazon Bedrock: - Các mô hình nền tảng (Foundation Models): Khác với Mô hình truyền thống ở chỗ nó có thể thích ứng với nhiều tác vụ, cung cấp nhiều mô hình được quản lý hoàn toàn từ các công ty AI hàng đầu như: OpenAI, Claude, Anthropic, v.v. - Kỹ thuật gợi ý (Prompt Engineering): Soạn thảo và tinh chỉnh các hướng dẫn + Zero-Shot Prompting: Lời nhắc không có ngữ cảnh hoặc ví dụ trước đó + Few-shot Prompting: Lời nhắc với một vài ngữ cảnh và ví dụ trước đó + Chuỗi suy nghĩ (Chain of Thought): Lời nhắc với các quy trình suy nghĩ và các bước để có câu trả lời thực tế - Retrieval Augmented Generation (RAG): Truy xuất thông tin liên quan từ nguồn dữ liệu + R: Truy xuất (Retrieval) - Truy xuất thông tin liên quan từ cơ sở tri thức hoặc nguồn dữ liệu + A: Tăng cường (Augmented) - Thêm thông tin được truy xuất dưới dạng ngữ cảnh bổ sung vào lời nhắc của người dùng trước khi đưa vào mô hình + G: Tạo sinh (Generation) - Phản hồi từ mô hình cho lời nhắc đã được tăng cường + Các trường hợp sử dụng: Cải thiện chất lượng nội dung, chatbot theo ngữ cảnh và trả lời câu hỏi, tìm kiếm được cá nhân hóa và tóm tắt dữ liệu thời gian thực\n- Amazon Titan Embedding: Mô hình hạng nhẹ vượt trội trong việc dịch văn bản thành các biểu diễn số (embeddings) cho các tác vụ truy xuất độ chính xác cao, hỗ trợ hơn 100 ngôn ngữ\n- Các dịch vụ AI được huấn luyện trước: + Amazon Rekognition: Phân tích hình ảnh và video + Amazon Translate: Phát hiện và dịch văn bản + Amazon Textract: Trích xuất văn bản và bố cục từ tài liệu + Amazon Transcribe: Chuyển đổi giọng nói thành văn bản + Amazon Polly: Chuyển đổi văn bản thành giọng nói + Amazon Comprehend: Trích xuất thông tin chi tiết và mối quan hệ từ văn bản + Amazon Kendra: Dịch vụ tìm kiếm thông minh + Amazon Lookout: Phát hiện bất thường trong các chỉ số kinh doanh, thiết bị và hình ảnh + Amazon Personalize: Tùy chỉnh các đề xuất cho người dùng\n- Demo: AMZPhoto: Nhận diện khuôn mặt từ hình ảnh sử dụng AI\n- Amazon Bedrock AgentCore: Một nền tảng tác nhân toàn diện được thiết kế để giải quyết các thách thức trong việc đưa các tác nhân vào môi trường production: + Thực thi và mở rộng mã tác nhân một cách an toàn. + Tích hợp bộ nhớ (ghi nhớ các tương tác trong quá khứ và học hỏi). + Triển khai kiểm soát danh tính và quyền truy cập cho các tác nhân và công cụ. + Cung cấp khả năng sử dụng công cụ tác nhân cho các quy trình làm việc phức tạp. + Khám phá và kết nối với các công cụ và tài nguyên tùy chỉnh. + Hiểu và kiểm toán mọi tương tác (khả năng quan sát). + Dịch vụ nền tảng: Các dịch vụ này được phân loại để chạy các tác nhân an toàn ở quy mô lớn.\n+ Nâng cao với các công cụ \u0026amp; bộ nhớ: Bao gồm Bộ nhớ, Cổng kết nối (Gateway), Công cụ trình duyệt và Trình thông dịch mã.\n+ Triển khai an toàn ở quy mô lớn: Bao gồm Runtime và Định danh.\n+ Thu thập thông tin chi tiết về vận hành: Bao gồm Khả năng quan sát (Observability).\n+ Kích hoạt tác nhân ở quy mô lớn (Kiến trúc): Kết nối với AgentCore Gateway (qua MCP), Bộ nhớ, Định danh, Khả năng quan sát, Trình duyệt và Trình thông dịch mã.\n+ Các Framework để xây dựng tác nhân: CrewAI, Google ADK, LangGraph/LangChain, LlamaIndex, OpenAI Agents SDK, và Strands Agents SDK.\nNhững điểm chính cần ghi nhớ Bedrock là trung tâm GenAI: Amazon Bedrock cung cấp các Mô hình nền tảng được quản lý hoàn toàn từ các công ty hàng đầu cho nhiều tác vụ khác nhau.\nTùy chỉnh qua Lời nhắc và Dữ liệu: Các cách khác nhau để gợi ý (Zero-Shot, Few-shot, CoT) và sử dụng RAG để thêm thông tin cho phản hồi mô hình tốt hơn.\nEmbeddings hỗ trợ tìm kiếm: Amazon Titan Embedding là một mô hình hạng nhẹ quan trọng để dịch văn bản thành số, giúp đạt được độ chính xác cao trong các tác vụ truy xuất (như RAG).\nCác mô hình được huấn luyện trước: AWS cung cấp nhiều dịch vụ AI sẵn sàng sử dụng cho các nhu cầu phổ biến, như Rekognition cho hình ảnh và Textract cho tài liệu.\nAgentCore giải quyết các vấn đề Production: Amazon Bedrock AgentCore là nền tảng toàn diện mới xử lý các phần khó khăn của việc chạy các Tác nhân AI ở quy mô lớn (như Bộ nhớ, Định danh và Khả năng quan sát).\nỨng dụng vào công việc Rất hữu ích trong các dự án sau này của nhóm chúng tôi, có thể bao gồm việc sử dụng nhiều hơn các Mô hình nền tảng AI trong kiến trúc. Trải nghiệm sự kiện Các diễn giả nói rất hay và cung cấp nhiều thông tin hữu ích Hỏi đáp: Thành viên trong nhóm đã đặt một câu hỏi ngoài lề nhưng rất quan trọng đối với dự án của chúng tôi + Hỏi: SNS trong kiến trúc của chúng tôi được sử dụng để xử lý các phát hiện của GuardDuty đã gặp phải tình huống hơn 1000 cảnh báo xuất hiện cùng một lúc, chúng tôi giải quyết vấn đề này như thế nào? + Đáp: Thêm SQS để xếp hàng các sự kiện và đảm bảo không có cảnh báo nào bị bỏ sót Lọt vào top 10 trong bài kiểm tra Kahoot cuối sự kiện và được chụp ảnh cùng các diễn giả Đã tạo một nhóm không chính thức: \u0026ldquo;Mèo Cam Đeo Khăn\u0026rdquo;, sự hợp tác giữa nhóm \u0026ldquo;The Ballers\u0026rdquo; của tôi và \u0026ldquo;Vinhomies\u0026rdquo; Một số hình ảnh sự kiện "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.4-week4/","title":"Nhật ký công việc Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Hoàn thành Module 6 Bắt đầu làm đề xuất (proposal) Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Module 6: Ôn tập khái niệm Cơ sở dữ liệu:\n+ Database (Cơ sở dữ liệu) + Session (Phiên) + Primary/Foreign Key (Khóa chính/Khóa ngoại) + Index (Chỉ mục) + Partitions (Phân vùng) + Execution/Query Plan (Kế hoạch thực thi/truy vấn) + Log \u0026amp; Buffer + RDBMS (Hệ quản trị cơ sở dữ liệu quan hệ) + NoSQL + OLTP (Xử lý giao dịch trực tuyến): Dùng cho thanh toán, giao dịch + OLAP (Xử lý phân tích trực tuyến): Phân tích dữ liệu, dự đoán xu hướng và mô hình - AWS RDS (Dịch vụ cơ sở dữ liệu quan hệ): Bao gồm Aurora, MySQL, Postgres SQL, MSSQL, Oracle, Maria + Sao lưu tự động + Tạo Read Replica + Read Replica có thể chuyển thành node chính (primary) + Tự động chuyển đổi dự phòng (Fail Over)/Multi AZ (Sao lưu trên nhiều AZ) + Thường được dùng cho OLTP + Mã hóa dữ liệu khi lưu trữ/khi truyền tải + Được bảo vệ bởi Security Group và NACL + Có thể thay đổi kích thước instance + Tự động mở rộng dung lượng lưu trữ - Amazon Aurora: Tối ưu hóa hạ tầng lưu trữ bên dưới, sử dụng MySQL và PostgreSQL + Backtrack: quay lại trạng thái trước đó + Clone (Tạo bản sao) + Global Database (Đa vùng) + Multi Master: Nhiều Master Database - Amazon Redshift: Dịch vụ kho dữ liệu (Data warehouse): Lõi PostgreSQL, tối ưu cho OLAP + Sử dụng kiến trúc MPP (Massively Parallel Processing): dữ liệu được phân vùng và lưu tại các compute node, một Leader node dùng để điều phối và biên dịch truy vấn + Lưu trữ dữ liệu dạng cột (columnar), hữu ích cho ứng dụng OLAP + Sử dụng SQL và các driver như JDBC và ODBC + Cung cấp các dịch vụ tối ưu chi phí (Transient Cluster/ Redshift spectrum) - Amazon ElastiCache: Tạo các Cluster Caching Engine (Redis/Memcached) + Phát hiện và thay thế các node bị lỗi + Đặt trước lớp CSDL để cache dữ liệu + Khuyến nghị dùng Redis cho các workload mới + Sử dụng ElastiCache yêu cầu logic caching trên ứng dụng, không khuyến khích dùng system caching mặc định - Xây dựng đề xuất cho workshop cùng đồng đội - Môn học ở trường: + KS57: Hoàn thành môn Quản trị dữ liệu và an toàn thông tin 29/09/2025 29/09/2025 Quản trị dữ liệu và an toàn thông tin T3 - Lab 43: Hướng dẫn bị lỗi, link không hoạt động, làm theo video\n+ Tải xuống Schema Conversion Tool + Tải MSSQL trên EC2 Instance + Không có script SQL, thử với Database MSSQL cơ bản tự tạo + Không có CloudFormation Stack, bỏ qua kết nối Oracle Database + Cài đặt MySQL trên EC2 Instance + Di chuyển Database MSSQL tự tạo sang MySQL Database sử dụng AWS Schema Conversion Tool + Tạo RDS tùy chỉnh để kiểm thử tác vụ di chuyển + Thử di chuyển từ máy local lên RDS + Thử dùng AWS Replication Agent: Không thành công do chỉ hỗ trợ Window/Linux server, không hỗ trợ OS cá nhân + Thử port forward PC để dùng làm endpoint + Port forwarding thất bại, không được ISP cho phép 30/09/2025 30/09/2025 Lab 43 Application Mirgation Service Guide T4 - Phát hiện credit của tài khoản AWS đã hết hạn khi làm lab 12\n- Viết support case (yêu cầu hỗ trợ) - Tạm dừng làm lab - Tập trung nghiên cứu về đề xuất của nhóm 01/10/2025 01/10/2025\n- Môn học ở trường: + ENW439c: Hoàn thành môn Research Methodologies Research Methodologies T5 - Tiếp tục làm lab nhờ sự trợ giúp của thành viên nhóm: Tạo IAM User với quyền admin để tôi đăng nhập và sử dụng tài khoản của họ\n- Dịch bài blog đầu tiên 02/10/2025 02/10/2025 Blog 1 T6 - Tham gia sự kiện AI-Driven Development Life Cycle: Reimagining Software Engineering\n- Dịch bài blog thứ hai và thứ ba 03/10/2025 04/10/2025 Blog 2 Blog 3 Thành tựu Tuần 4: Hoàn thành việc ôn tập toàn diện các khái niệm cốt lõi về cơ sở dữ liệu bao gồm RDBMS, khóa, chỉ mục, phân vùng, OLTP/OLAP và các dịch vụ cơ sở dữ liệu đặc thù của AWS. Nắm được kiến thức lý thuyết về các tính năng và trường hợp sử dụng cho AWS RDS, Amazon Aurora (ví dụ: Backtrack, Global Database), Amazon Redshift (Kho dữ liệu cho OLAP), và Amazon ElastiCache (caching với Redis/Memcached). Di chuyển Cơ sở dữ liệu: Đã thử nghiệm một bài lab di chuyển cơ sở dữ liệu phức tạp, thể hiện sự tháo vát thông qua việc: Tự tạo một Database MSSQL và cài đặt các dịch vụ cần thiết trên EC2 instance do hướng dẫn lab bị lỗi. Di chuyển thành công database MSSQL tự tạo sang MySQL sử dụng AWS Schema Conversion Tool (SCT). Phát hiện và xử lý vấn đề hết hạn credit AWS bằng cách tạo support case. Đảm bảo tiến độ làm lab bằng cách thiết lập IAM User với quyền admin trên tài khoản của thành viên trong nhóm. Xây dựng đề xuất cho workshop sắp tới cùng với các thành viên trong nhóm. Hoàn thành việc dịch 3 bài blog. Tham dự sự kiện AI-Driven Development Life Cycle: Reimagining Software Engineering. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.7-dashboard-setup/5.7.4-setup-cloudfront/","title":"Cài đặt Cloudfront","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một Cloudfront để cache, định tuyến và truy cập web.\nTạo Cloudfront Distribution Mở Cloudfront Console\nĐiều hướng tới https://console.aws.amazon.com/cloudfront/ Hoặc: AWS Management Console → Services → Cloudfront Tạo Distribution:\nNhấn nút Create distribution Trong phần tạo distribution, sử dụng cài đặt này: Chọn plan: Free plan Name: Static Dashboard Website CloudFront Origin type: Amazom S3 S3 Origin: Chọn static-dashboard-bucket Giữ phần còn lại như mặc định Bật security: Sử dụng cái này nếu bạn chọn free plan Xem lại và nhấn Create distribution Cài đặt chung (General setting):\nSau khi tạo xong, trên tab General của Cloudfront nhấn vào Edit Tại Default root object nhập index.html Description: Static Dashboard Distribution Nhấn Save change Tạo API Gateway origin:\nNhấn Origins trên các tab menu Sau đó nhấn Create origin Trong phần tạo origin, sử dụng cài đặt này: Origin domain: chọn dashboard-api Protocol: HTTPS only HTTPS port: 443 Minimum Origin SSL protocol: TLSv1.2 Origin path: /prod Nhấn Create origin Tạo behaviors cho API Gateway:\nNhấn Behaviors trên các tab menu Sau đó nhấn Create behavior Trong phần tạo behavior, sử dụng cài đặt này: Path pattern: /logs/* Origin và origin groups: chọn dashboard-api Để các cài đặt còn lại như mặc định Nhấn Create behavior Cập nhật S3 policy để hoạt động với Cloudfront:\nNhấn Origins trên các tab menu, chọn tên origin s3-static-dashboard Nhấn Edit Tại phần Origin access controll nhấn Go to S3 bucket permissions Kiểm tra xem quyền S3 của bạn có giống thế này không, nếu không hãy copy và paste nó vào quyền S3 của bạn (Thay đổi ACCOUNT_ID, ACCOUNT_REGION và CLOUDFRONT_ID thành của bạn): { \u0026#34;Version\u0026#34;: \u0026#34;2008-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;PolicyForCloudFrontPrivateContent\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontServicePrincipal\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::s3-static-dashboard-[ACCOUNT_ID]-[ACCOUNT_REGION]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnLike\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::[ACCOUNT_ID]:distribution/[CLOUDFRONT_ID]\u0026#34; } } } ] } Nhấn Save change Tạo error pages:\nNhấn Error pages trên các tab menu Nhấn Create custom error page Trong phần tạo custom error page, sử dụng cài đặt này: HTTP error code: 403: Forbident Error caching minimum TTL: 300 Customize error response: Yes Response page path: /index.html HTTP Response code: 200: OK Lặp lại bước này cho 404 code "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.4-cloudwatch-eni-etl/","title":"Mã CloudWatch ENI ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose = boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIGURATION # -------------------------------------------------- FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) # ----------------------------- UTILS ----------------------------- def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def safe_int(x): try: return int(x) except: return None def parse_flow_log_line(line): parts = line.strip().split(\u0026#39; \u0026#39;) if len(parts) \u0026lt; 14: return None try: start_timestamp = safe_int(parts[10]) time_str = None if start_timestamp: dt_object = datetime.fromtimestamp(start_timestamp) time_str = dt_object.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) record = { \u0026#34;version\u0026#34;: safe_int(parts[0]), # Cột 1: version (int) \u0026#34;account_id\u0026#34;: parts[1], # Cột 2: account_id (STRING) \u0026#34;interface_id\u0026#34;: parts[2], # Cột 3: eni-... \u0026#34;srcaddr\u0026#34;: parts[3], \u0026#34;dstaddr\u0026#34;: parts[4], \u0026#34;srcport\u0026#34;: safe_int(parts[5]), \u0026#34;dstport\u0026#34;: safe_int(parts[6]), \u0026#34;protocol\u0026#34;: safe_int(parts[7]), \u0026#34;packets\u0026#34;: safe_int(parts[8]), \u0026#34;bytes\u0026#34;: safe_int(parts[9]), \u0026#34;start_time\u0026#34;: start_timestamp, # Cột 11 \u0026#34;end_time\u0026#34;: safe_int(parts[11]), \u0026#34;action\u0026#34;: parts[12], \u0026#34;log_status\u0026#34;: parts[13], \u0026#34;timestamp_str\u0026#34;: time_str } return record except Exception as e: print(f\u0026#34;Error parsing line: {e}\u0026#34;) return None def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] # Duyệt qua các file S3 gửi về (Iterate through files sent from S3) for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] # Chỉ xử lý file .gz (Process .gz files only) if not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping non-gz: {key}\u0026#34;) continue print(f\u0026#34;Processing: {key}\u0026#34;) # Đọc nội dung (Read content) content = read_gz(bucket, key) if not content: continue # Parse từng dòng log (Parse each log line) for line in content.splitlines(): rec = parse_flow_log_line(line) if not rec: continue # Chuyển thành JSON string và thêm xuống dòng (\\n) (Convert to JSON string and add newline) json_row = json.dumps(rec) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Đẩy sang Firehose (Batching 500 dòng) (Push to Firehose - batching 500 lines) if firehose_records: total = len(firehose_records) print(f\u0026#34;Flushing {total} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed.\u0026#34;) except Exception as e: print(f\u0026#34;Firehose API Error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;count\u0026#34;: len(firehose_records)} "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.4-monitoring-setup/","title":"Thiết lập giám sát","tags":[],"description":"","content":"Giai đoạn Thiết lập giám sát này kích hoạt và cấu hình ba nguồn log cốt lõi để phát hiện mối đe dọa. Giai đoạn này bao gồm việc bật CloudTrail cho các sự kiện quản lý và dữ liệu toàn diện, kích hoạt GuardDuty để xuất các phát hiện bảo mật sang S3 bucket chính, và thiết lập VPC Flow Logs trên mạng của bạn để gửi tất cả metadata lưu lượng truy cập đến CloudWatch Log Group chuyên dụng. Điều này đảm bảo luồng dữ liệu log liên tục, tập trung luôn sẵn sàng cho việc xử lý và phản hồi tự động.\nTạo CloudWatch Log Group Mở CloudWatch Console → Log Management → Create log group Cấu hình:\nLog group name: /aws/incident-response/centralized-logs Retention: 90 ngày KMS key: None Nhấn \u0026ldquo;Create\u0026rdquo;\nBật AWS CloudTrail Mở CloudTrail Console → Trail → Create trail Thuộc tính Trail:\nTrail name: incident-responses-cloudtrail-ACCOUNT_ID-REGION Storage location: Sử dụng S3 bucket hiện có S3 bucket: Chọn incident-response-log-list-bucket-ACCOUNT_ID-REGION của bạn Log file SSE-KMS encryption: Disable (Tắt) Log file validation: Enabled (Bật) Nhấn next Chọn log events:\nEvents Chọn Management events, Data events Management events: Tất cả (Read + Write) Data events: S3 - Log tất cả events Nhấn next đến bước 4 và Create Trail Advanced event selectors: Loại trừ log buckets:\nNhấn vào Trail sau đó cuộn xuống Data Event và nhấn Edit Thiết lập như hình với định dạng dưới đây: -arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\n-arn:aws:s3:::athena-query-results-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/\nLưu thay đổi Bật Amazon GuardDuty Mở GuardDuty Console → Get Started → Enable GuardDuty\nCấu hình cài đặt:\nFinding export frequency: Update CWE và S3 mỗi 15 phút S3 export: incident-response-log-list-bucket-ACCOUNT_ID-REGION KMS encryption: Chọn hoặc tạo KMS key Bật VPC Flow Logs Mở VPC Console → Your VPCs → Chọn VPC của bạn\nActions → Create flow log\nCấu hình:\nFilter: All (Tất cả) Aggregation interval: 10 phút Destination: CloudWatch Logs Log group: /aws/incident-response/centralized-logs IAM role: FlowLogsIAMRole Log format: Default (Mặc định) Tạo flow log\nBật VPC DNS Query Logging Cấu hình Resolver Query Logging Mở Amazon Route 53 Console.\nỞ thanh điều hướng bên trái, chọn VPC Resolver -\u0026gt; Query logging.\nNhấn \u0026ldquo;Configure query logging\u0026rdquo;.\nCấu hình:\nName: Nhập tên mô tả, ví dụ: IR-DNS-Query-Log-Config. Destination for query logs: CloudWatch Logs log group Log group: Chọn \u0026ldquo;Existing log group\u0026rdquo; và chọn: /aws/incident-response/centralized-logs Nhấn \u0026ldquo;Configure query logging\u0026rdquo;.\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.5-week5/","title":"Nhật ký công việc Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5: Tiếp tục xây dựng và lập kế hoạch cho bản đề xuất (proposal) Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T5 - Đã tạo và nghiên cứu các phần việc của mình dựa trên sơ đồ kiến trúc workshop của nhóm 08/10/2025 08/10/2025 T6 - Lab 35:\n+ Thiết lập thành công luồng dữ liệu (data stream) sử dụng Kinesis + Gửi thành công dữ liệu mẫu đến S3 sử dụng Kinesis Data Generator với Amazon Cognito + Học cách sử dụng AWS Glue Crawler để ánh xạ dữ liệu vào S3 Bucket + Sử dụng Athena để truy vấn dữ liệu + Sử dụng AWS Glue Notebook để xây dựng tập dữ liệu dựa trên dữ liệu mẫu + Sử dụng Athena để phân tích dữ liệu và trực quan hóa bằng QuickSight - Cập nhật sơ đồ kiến trúc dựa trên những thay đổi trong đề xuất workshop - Bắt đầu nghiên cứu các thuật toán Lambda cho dự án của nhóm. 09/10/2025 09/10/2025 Lab 35 T7 - Lab 40:\n+ Thực hành thêm với AWS Glue và Athena, sử dụng để phân tích dữ liệu Chi phí Hàng tháng của AWS. 10/10/2025 10/10/2025 Lab 40 Thành tựu Tuần 5: Kiến trúc Workshop \u0026amp; Nghiên cứu:\nĐã tạo và nghiên cứu các thành phần cụ thể cho kiến trúc workshop của nhóm. Cập nhật sơ đồ kiến trúc để phản ánh những thay đổi mới nhất trong đề xuất. Bắt đầu nghiên cứu về các thuật toán AWS Lambda sẽ được triển khai trong dự án của nhóm. Luồng dữ liệu và Phân tích (Lab 35): Hoàn thành bài lab phức tạp về pipeline dữ liệu:\nThiết lập thành công luồng dữ liệu thời gian thực sử dụng Amazon Kinesis. Tạo và gửi dữ liệu mẫu đến S3 bằng Kinesis Data Generator và Amazon Cognito. Sử dụng AWS Glue Crawler để ánh xạ dữ liệu và Glue Notebook để xây dựng tập dữ liệu. Thực hiện truy vấn dữ liệu với Amazon Athena và trực quan hóa bằng Amazon QuickSight. Phân tích Chi phí (Lab 40): Thực hành phân tích nâng cao bằng cách sử dụng AWS Glue và Athena để phân tích dữ liệu Chi phí Hàng tháng của AWS.\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.7-dashboard-setup/5.7.5-setup-cognito/","title":"Cài đặt Cognito","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ tạo một Cognito user pool để đăng nhập dashboard.\nTạo Cognito User Pool Mở Amazon Cognito Console\nĐiều hướng tới https://console.aws.amazon.com/cognito/ Hoặc: AWS Management Console → Services → Cognito Tạo user pool:\nNhấn Create user pool Trong phần tạo user pool, sử dụng cài đặt này: Application type: Single-page application (SPA) Application name: dashboard-user-pool-client Options for sign-in identifiers: Email và Username Self-registration: Enable slef-registration Required attributes for sign-up: email Add a return URL: Vào Cloudfront, chọn cái bạn vừa tạo và copy Distribution domain name và dán vào đây (Ví dụ: https://d2bvvvpr6s4eyd.cloudfront.net) Nhấn Create user directory Sau khi tạo, cuộn xuống và nhấn Go to overview Cấu hình User pool App clients:\nChọn App clients trên menu bên trái Chọn dashboard-user-pool-client Trong phần App client information, nhấn Edit Thay đổi cài đặt như hình bên dưới: [Screenshot: Cognito Console Homepage]\nNhấn Save change Cấu hình Managed login pages:\nTrong phần Managed login pages configuration, nhấn Edit Nhấn Add sign-out URL tại phần Allowed sign-out URLs Copy URL trên callbacks URL và dán vào Allowed sign-out URLs Cuộn xuống OpenID Connect scopes thêm Profile vào scopes Nhấn Save change Tạo một user:\nTrên menu bên trái, chọn tùy chọn User Nhấn Create user Nhập thông tin người dùng của bạn Nhấn Create user "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.5-cloudwatch-autoexport/","title":"Mã CloudWatch Autoexport","tags":[],"description":"","content":" import json import base64 import gzip from io import BytesIO import boto3 import os import time s3 = boto3.client(\u0026#39;s3\u0026#39;) # --- CONFIGURATION (CẤU HÌNH) --- RAW_S3_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;) # The log group pattern constant is no longer used for filtering, but is kept for reference. # VPC_DNS_LOG_PATTERN = \u0026#39;/aws/route53/query/\u0026#39; def is_vpc_dns_log(log_message): try: json_body = json.loads(log_message.strip()) if \u0026#39;query_name\u0026#39; in json_body and \u0026#39;query_type\u0026#39; in json_body: return True return False except Exception: return False def lambda_handler(event, context): try: compressed_payload = base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]) f = BytesIO(compressed_payload) decompressed_data = gzip.GzipFile(fileobj=f).read() log_data = json.loads(decompressed_data.decode(\u0026#39;utf-8\u0026#39;)) log_lines = [] for log_event in log_data.get(\u0026#39;logEvents\u0026#39;, []): log_lines.append(log_event.get(\u0026#39;message\u0026#39;, \u0026#39;\u0026#39;)) if not log_lines: print(f\u0026#34;Batch skipped: No log events found in payload. Log Group: {log_data.get(\u0026#39;logGroup\u0026#39;)}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Log batch ignored (No events).\u0026#39;} is_dns_log = is_vpc_dns_log(log_lines[0]) if is_dns_log: key_prefix = \u0026#39;vpc-dns-logs\u0026#39; filename_prefix = \u0026#39;vpc-\u0026#39; # Add vpc- to the filename else: key_prefix = \u0026#39;vpc-flow-logs\u0026#39; filename_prefix = \u0026#39;eni-\u0026#39; # Keep filename blank for other logs output_content = \u0026#39;\\n\u0026#39;.join(log_lines) full_log_group_name = log_data.get(\u0026#39;logGroup\u0026#39;, \u0026#39;unknown-group\u0026#39;) log_group_name_safe = full_log_group_name.strip(\u0026#39;/\u0026#39;).replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) final_filename = f\u0026#34;{filename_prefix}{context.aws_request_id}.gz\u0026#34; s3_key = f\u0026#39;exportedlogs/{key_prefix}/{log_group_name_safe}/{final_filename}\u0026#39; buffer = BytesIO() with gzip.GzipFile(fileobj=buffer, mode=\u0026#39;w\u0026#39;) as gz: gz.write(output_content.encode(\u0026#39;utf-8\u0026#39;)) gzipped_data = buffer.getvalue() s3.put_object( Bucket=RAW_S3_BUCKET, Key=s3_key, Body=gzipped_data, ContentType=\u0026#39;application/x-gzip\u0026#39; ) num_logs = len(log_lines) print(f\u0026#34;Exported {num_logs} raw log lines to s3://{RAW_S3_BUCKET}/{s3_key}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#39;Logs exported. {num_logs} events processed. Key Prefix: {key_prefix}\u0026#39;} except Exception as e: print(f\u0026#34;Error in CW Export Lambda: {e}\u0026#34;) raise e "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.5-processing-setup/","title":"Thiết lập xử lý","tags":[],"description":"","content":"Giai đoạn Thiết lập xử lý này xây dựng đường ống dữ liệu (data pipeline) cốt lõi để cấu trúc log thô và chuẩn bị chúng cho việc phân tích truy vấn. Giai đoạn này bắt buộc triển khai ba luồng Kinesis Data Firehose để đệm và phân phối CloudTrail và VPC logs đến các S3 buckets đích. Đồng thời, bạn sẽ cấu hình AWS Glue Database và bốn bảng Athena thông qua DDL để làm cho dữ liệu có cấu trúc có thể truy vấn được. Pipeline này dựa vào năm Lambda functions ETL được kích hoạt bởi S3 Event Notifications để thực hiện chuyển đổi dữ liệu cần thiết khi log đến.\nNội dung Tạo Kinesis Data Firehose Delivery Streams Tạo AWS Glue Database và Tables Tạo Lambda Functions - Xử lý ETL "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Thiết lập hệ thống phản hồi sự cố tự động AWS Tổng quan Hướng dẫn này cung cấp quy trình từng bước hoàn chỉnh để triển khai hệ thống phản hồi sự cố và điều tra số (forensics) tự động của chúng tôi trên AWS. Hệ thống này tận dụng CloudTrail, GuardDuty, VPC Flow Logs, Kinesis Firehose, Glue, Athena, và Lambda functions được điều phối bởi AWS Step Functions để tự động phát hiện, phân tích và cách ly các tài nguyên bị xâm phạm như EC2 instances và IAM users. Khả năng điều tra log sâu hơn được bổ sung bằng cách thiết lập Security Dashboard lưu trữ trên S3 và truy cập qua CloudFront và Cognito, truy vấn log sử dụng API Gateway và Lambda.\nNội dung Tổng quan Điều kiện tiên quyết Giai đoạn 1: Thiết lập nền tảng Giai đoạn 2: Thiết lập giám sát Giai đoạn 3: Thiết lập xử lý Giai đoạn 4: Thiết lập tự động hóa Giai đoạn 5: Thiết lập Dashboard Kiểm tra Sử dụng CDK Dọn dẹp Phụ lục "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Amazon Web Services từ 9/2025 đến 12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia Phát triển Autonomous Incident Response với các tasks EventBridge (Trigger), AWS Lambda Functions, AWS Step Functions (Core Logic).\nBáo cáo Tổng kết Kỹ năng \u0026amp; Hạng mục đã thực hiện Trong quá trình triển khai dự án, tôi đã thực hiện các nội dung sau:\nOrchestration với AWS Step Functions:\nThiết lập tích hợp trực tiếp AWS SDK (Service Integration) để gọi API EC2 và Auto Scaling, loại bỏ sự phụ thuộc vào Lambda trung gian. Xử lý luồng dữ liệu (Data Flow) giữa các state: sử dụng ResultPath: null để bảo toàn dữ liệu và States.Array để xử lý mảng động. Cấu hình các logic điều hướng phức tạp: rẽ nhánh (Choice), vòng lặp (Map) và cơ chế tự động thử lại (Retry). Vận hành Auto Scaling Group (ASG):\nThực hiện quy trình tách (Detach) instance khỏi ASG sử dụng tham số ShouldDecrementDesiredCapacity để duy trì hoạt động ứng dụng. Xử lý các ràng buộc về dung lượng (Capacity Constraints), cụ thể là khắc phục lỗi logic MinSize bằng cách thêm bước UpdateASGConfiguration. Debugging \u0026amp; Troubleshooting:\nPhân tích nguyên nhân gốc (Root Cause Analysis) thông qua việc kiểm tra Input/Output của từng Step. Thực hiện kiểm thử cô lập (Isolation Testing) cho từng nhánh logic (ASG và Non-ASG) và sử dụng dữ liệu giả lập (Mock events). Xác định và xử lý các lỗi logic không báo lỗi hệ thống (Silent Failure) và các lỗi môi trường (sai Region, định dạng ID). Bảo mật \u0026amp; Quản lý Quyền hạn (IAM):\nÁp dụng nguyên tắc Least Privilege: Cấp quyền hạn chế qua Inline Policy cho từng hành động cụ thể (như DetachInstances, CreateSnapshot). Triển khai quy trình kỹ thuật Ứng phó sự cố theo trình tự: Phát hiện $\\rightarrow$ Cô lập (Security Group) $\\rightarrow$ Bảo vệ (Termination Protection) $\\rightarrow$ Thu thập bằng chứng (Snapshot). Tự động hóa (Automation):\nXây dựng hệ thống tự động hóa thay thế thao tác thủ công. Thiết kế workflow đảm bảo tính Idempotent (cho phép chạy lại nhiều lần mà không gây lỗi trùng lặp) và khả năng xử lý linh hoạt cho cả instance thuộc ASG và không thuộc ASG. Về tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ ☐ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ✅ ☐ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.6-week6/","title":"Nhật ký công việc Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6: Hoàn thành và nộp đề xuất (proposal) Phân công nhiệm vụ với các thành viên trong nhóm để bắt đầu thực hiện workshop Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Định dạng lại và chỉnh sửa nhật ký công việc (worklog), bổ sung thêm thông tin và tóm tắt\n- Triển khai thành công nhật ký công việc lên Github Page 13/10/2025 13/10/2025 T3 - Họp nhóm\n- Chỉnh sửa đề xuất workshop: Tập trung vào việc sử dụng GuardDuty để phát hiện xâm nhập thay vì dùng custom Lambda function do yêu cầu dataset lớn và thời gian phát triển dài. - Vẽ lại AWS Architecture: Thêm GuardDuty thay thế cho CloudWatch Alarm - Viết bản nháp cho đề xuất, phác thảo chức năng cơ bản và ước tính chi phí sơ bộ. 14/10/2025 14/10/2025 T4 - Họp nhóm\n- Chỉnh sửa đề xuất workshop: + Tích hợp sử dụng EventBridge + Tính toán lại chi phí bằng cách giảm loại EC2 instance và giờ hoạt động - Cập nhật AWS Architecture: Thêm icon EventBridge và các kết nối liên quan 15/10/2025 15/10/2025 T5 - Cập nhật AWS Architecture:\n+ Sắp xếp lại các icon để kết nối rõ ràng hơn. + Di chuyển SSM vào trong region group + Thêm public subnet group cho EC2 Instance - Cài đặt AmazonQ để phân tích đề xuất tốt hơn - Chỉnh sửa đề xuất workshop: Tính toán lại chi phí sử dụng AWS Pricing Calculator - Chuyển đổi bản nháp đề xuất sang mã markdown và triển khai thành công lên Github Pages - Tham gia hội thảo trực tuyến 𝗗𝗫\u0026lt;𝗶𝗻𝗔𝗰𝘁𝗶𝗼𝗻\u0026gt; 𝗧𝗮𝗹𝗸#𝟳: Reinventing DevSecOps with AWS Generative AI 16/10/2025 16/10/2025 T6 - Tổng hợp tài liệu ôn tập cho kỳ thi giữa kỳ 17/10/2025 17/10/2025 Thành tựu Tuần 6: Hoàn thiện Đề xuất:\nHoàn thành nhiều lần chỉnh sửa cho đề xuất workshop, chuyển đổi từ việc dùng custom Lambda function sang sử dụng GuardDuty để phát hiện xâm nhập. Tính toán lại và giảm thành công chi phí ước tính bằng cách tối ưu hóa loại EC2 instance và giờ hoạt động. Chuyển đổi sang markdown và triển khai bản nháp đề xuất lên GitHub Pages. Cập nhật Kiến trúc và Hệ thống:\nChỉnh sửa sơ đồ AWS Architecture, tích hợp GuardDuty, EventBridge, đồng thời tinh chỉnh lại cách sắp xếp icon và các nhóm subnet để đảm bảo tính rõ ràng và chính xác. Cập nhật nhật ký công việc và triển khai thành công nhật ký đã chỉnh sửa lên GitHub Pages. Cài đặt AmazonQ. Tham dự hội thảo trực tuyến \u0026lsquo;DX Talk#7: Reinventing DevSecOps with AWS Generative AI\u0026rsquo;.\nTổng hợp tài liệu ôn tập cho kỳ thi giữa kỳ.\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.6-parse-findings/","title":"Mã Parse Findings","tags":[],"description":"","content":" import json import logging logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): instance_ids = [] detail = event.get(\u0026#39;detail\u0026#39;, {}) region = event.get(\u0026#39;region\u0026#39;) or detail.get(\u0026#39;region\u0026#39;) or \u0026#39;ap-southeast-1\u0026#39; instance_id_primary = detail.get(\u0026#39;resource\u0026#39;, {}).get(\u0026#39;instanceDetails\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if instance_id_primary: instance_ids.append(instance_id_primary) # --- 2. Extract from the older/secondary \u0026#39;resources\u0026#39; array structure --- # --- 2. Trích xuất từ cấu trúc mảng \u0026#39;resources\u0026#39; cũ/phụ --- for r in detail.get(\u0026#34;resources\u0026#34;, []): if r.get(\u0026#34;type\u0026#34;) == \u0026#34;AwsEc2Instance\u0026#34;: id_from_details = r.get(\u0026#39;details\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if id_from_details: instance_ids.append(id_from_details) else: arn_id = r.get(\u0026#39;id\u0026#39;) if arn_id and arn_id.startswith(\u0026#39;arn:aws:ec2:\u0026#39;): instance_ids.append(arn_id.split(\u0026#39;/\u0026#39;)[-1]) unique_instance_ids = list(set([id for id in instance_ids if id])) return { \u0026#34;InstanceIds\u0026#34;: unique_instance_ids, \u0026#34;Region\u0026#34;: region } "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.6-automation-setup/","title":"Thiết lập tự động hóa","tags":[],"description":"","content":"Giai đoạn 4: Thiết lập tự động hóa Tạo Isolation Security Group EC2 Console → Security Groups → Create security group Name: IR-Isolation-SG Description: Denies all inbound and outbound traffic for compromised instances (Chặn tất cả lưu lượng đi và đến cho các instance bị xâm phạm) VPC: Chọn VPC của bạn Inbound rules: Không có (từ chối tất cả - deny all) Outbound rules: Xóa mặc định (từ chối tất cả - deny all) Tạo và ghi lại Security Group ID (ví dụ: sg-0078026b70389e7b3) Tạo SNS Topic SNS Console → Create topic Type: Standard, Name: IncidentResponseAlerts Access policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AWSEvents_IncidentResponseAlert_Target0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;SNS:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; } ] } Tạo Lambda Functions - Phản hồi sự cố (Incident Response) ir-parse-findings-lambda Handler: parse_findings.lambda_handler Role: ParseFindingsLambdaServiceRole Code: parse-findings ir-isolate-ec2-lambda Handler: isolate_ec2.lambda_handler Role: IsolateEC2LambdaServiceRole Env: ISOLATION_SG_ID=sg-XXXXXXX (từ bước 12) Code: isolate-ec2 ir-quarantine-iam-lambda Handler: quarantine_iam.lambda_handler Role: QuarantineIAMLambdaServiceRole Env: QUARANTINE_POLICY_ARN=arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy Code: quarantine-iam ir-alert-dispatch Handler: alert_dispatch.lambda_handler Role: AlertDispatchLambdaServiceRole Env: SENDER_EMAIL, RECIPIENT_EMAIL, SLACK_WEBHOOK_URL Add SNS trigger: Topic IncidentResponseAlerts Code: alert-dispatch Cập nhật SNS Topic Subscription SNS Console → IncidentResponseAlerts → Subscriptions Xác minh: Protocol=AWS Lambda, Endpoint=ir-alert-dispatch, Status=Confirmed Tạo Step Functions State Machine Step Functions Console → Create state machine Type: Standard, Name: IncidentResponseStepFunctions Definition: Step Functions Definition Role: StepFunctionsRole Create Tạo EventBridge Rule EventBridge Console → Rules → Create rule Name: IncidentResponseAlert Event pattern: { \u0026#34;source\u0026#34;: [\u0026#34;aws.guardduty\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;GuardDuty Finding\u0026#34;] } Targets (2): SNS topic: IncidentResponseAlerts Step Functions: IncidentResponseStepFunctions với role IncidentResponseStepFunctionsEventRole Cấu hình Athena Workgroup Athena Console → Workgroups → primary → Edit Query result location: s3://athena-query-results-ACCOUNT_ID-REGION/ Lưu (Save) "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.7-week7/","title":"Nhật ký công việc Tuần 7","tags":[],"description":"","content":"Mục tiêu Tuần 7: Thiết kế và tạo mẫu quy trình phản ứng sự cố tự động, tinh chỉnh kiến trúc dự án dựa trên phản hồi của mentor. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Nghiên cứu và thử nghiệm thuật toán cô lập EC2 bằng cách sử dụng Security Group (SG) không có quy tắc outbound/inbound nào 20/10/2025 21/10/2025 T4 - Họp nhóm:\n+ Ôn tập nhanh kiến thức dịch vụ AWS + Thảo luận về các thay đổi trong đề xuất - Cập nhật Kiến trúc AWS: Thêm AWS Detective - Chỉnh sửa đề xuất: + Thêm việc sử dụng AWS Detective + Thêm kế hoạch dùng CDK sau khi hoàn thành workshop - Khuyến nghị của Mentor: + Trực quan hóa dữ liệu nhưng không dùng QuickSight, thay vào đó làm dashboard tự code (Đang nghiên cứu) + Lưu các phát hiện của GuardDuty vào S3 bucket để phân tích (Đang nghiên cứu) - Cấu hình thành công EventBridge để kích hoạt khi có các phát hiện cụ thể từ GuardDuty và: + Gửi email SNS đến tất cả thành viên nhóm + Kích hoạt một script Lambda đơn giản - Hình thành ý tưởng thêm vào workshop: Làm một trang biểu đồ dữ liệu đơn giản host trên S3, dùng API Gateway và Lambda để lấy dữ liệu điều tra từ Amazon Athena (Đang nghiên cứu) 22/10/2025 22/10/2025 T5 - Thử chơi AWS Card Clash cùng thành viên nhóm: Khá bất ngờ vì hiệu quả tốt để học về các dịch vụ, chức năng và vị trí của chúng trong Kiến trúc\n- Ôn tập kiến thức dịch vụ AWS cho kỳ thi giữa kỳ: Sử dụng Google Gemini để tạo câu hỏi trắc nghiệm dựa trên yêu cầu 23/10/2025 23/10/2025 AWS Card Clash T6 - Cấu hình thành công GuardDuty threat list để kích hoạt phát hiện từ các hoạt động của EC2 Instance 08/15/2025 08/15/2025 Pháp luật và đạo đức trong công nghệ số Thành tựu Tuần 7: Thực hành GuardDuty:\nHoàn thành \u0026ldquo;Getting Hands on with Amazon GuardDuty - AWS Virtual Workshop\u0026rdquo; và bài lab chuyên sâu tạo bởi Amazon Q. Tạo, kiểm thử và kích hoạt thành công nhiều loại phát hiện GuardDuty thông qua cài đặt console, hoạt động EC2 và truy cập CloudTrail API. Thiết lập môi trường kiểm thử dễ dàng hơn bằng cách kích hoạt thành công các cảnh báo mẫu với mức độ nghiêm trọng và loại khác nhau qua CloudShell CLI. Cấu hình thành công GuardDuty threat list để kích hoạt phát hiện từ hoạt động của EC2 Instance. Đề xuất Workshop và Cải tiến Kiến trúc:\nCập nhật đề xuất và Kiến trúc AWS để tích hợp AWS Detective cho khả năng điều tra sâu hơn. Thêm kế hoạch triển khai CDK sau khi hoàn thành workshop. Bắt đầu nghiên cứu các khuyến nghị của mentor, bao gồm trực quan hóa dữ liệu tự code và lưu phát hiện GuardDuty vào S3 để phân tích. Hình thành ý tưởng workshop mới về trang biểu đồ dữ liệu đơn giản host trên S3 sử dụng API Gateway và Lambda. Tích hợp Dịch vụ và Tự động hóa:\nCấu hình thành công EventBridge để xử lý các phát hiện cụ thể của GuardDuty. Tự động hóa thông báo bằng cách gửi email SNS cho thành viên nhóm và kích hoạt script Lambda dựa trên cảnh báo GuardDuty. Nghiên cứu An ninh Mạng \u0026amp; Cô lập:\nNghiên cứu và kiểm chứng thuật toán cô lập EC2 bằng cách thử nghiệm Security Group (SG) với các quy tắc chặn inbound/outbound để ngăn chặn hiệu quả các instance bị xâm nhập. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/","title":"Báo cáo Thực tập","tags":[],"description":"","content":"Báo cáo Thực tập Thông tin Sinh viên: Họ và tên: Lê Trần Gia Huy\nSố điện thoại: 0822746264\nEmail: huyletran188205@gmail.com\nTrường: Đại học FPT TP. Hồ Chí Minh\nChuyên ngành: An toàn Thông tin\nĐơn vị thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: Thực tập sinh FCJ Cloud\nThời gian thực tập: Từ 08/09/2025 đến 12/12/2025\nNội dung Báo cáo Nhật ký công việc Đề xuất Bài viết đã dịch Sự kiện đã tham gia Workshop Tự đánh giá Chia sẻ và Phản hồi "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/7-feedback/","title":"Chia sẻ và Đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá Tổng quan 1. Môi trường làm việc Môi trường làm việc tại FCJ thực sự cởi mở và thân thiện. Các thành viên luôn sẵn sàng hỗ trợ bất cứ khi nào tôi gặp khó khăn về kỹ thuật, thậm chí là ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái giúp tôi tập trung tốt hơn. Tuy nhiên, tôi nghĩ nếu có thêm các hoạt động giao lưu hoặc gắn kết (teambuilding) thường xuyên hơn thì sẽ giúp tình cảm anh em trong team gắn bó hơn nữa.\n2. Sự hỗ trợ từ Mentor / Admin Team Mentor hướng dẫn cực kỳ chi tiết, giải thích cặn kẽ các vấn đề phức tạp và luôn khuyến khích tôi đặt câu hỏi. Tôi đặc biệt đánh giá cao phương pháp hướng dẫn: mentor luôn để tôi tự thử tìm cách giải quyết vấn đề trước, thay vì đưa ngay đáp án, điều này giúp tư duy của tôi phát triển rất nhiều. Đội ngũ Admin cũng hỗ trợ nhiệt tình các thủ tục hành chính, cung cấp tài liệu cần thiết, tạo điều kiện thuận lợi nhất để tôi làm việc.\n3. Mức độ phù hợp với chuyên ngành Các công việc được giao rất sát với kiến thức tôi đã học ở trường, đồng thời giúp tôi tiếp cận những mảng công nghệ mới chưa từng được dạy (như Tự động hóa Bảo mật Cloud). Đây là cầu nối tuyệt vời giúp tôi củng cố nền tảng lý thuyết và rèn luyện kỹ năng thực chiến.\n4. Cơ hội học hỏi và phát triển kỹ năng Trong quá trình thực tập, tôi đã học được rất nhiều kỹ năng mới từ việc sử dụng các công cụ quản lý dự án, kỹ năng làm việc nhóm đến cách giao tiếp chuyên nghiệp trong môi trường doanh nghiệp. Những chia sẻ về kinh nghiệm thực tế và lộ trình nghề nghiệp từ Mentor cũng là hành trang quý giá cho định hướng Cloud Engineering của tôi sau này.\n5. Văn hóa công ty và Tinh thần đồng đội Văn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng không khí vẫn vui vẻ, không gò bó. Tôi rất ấn tượng với tinh thần đồng đội khi chạy các dự án gấp, mọi người không phân biệt vị trí đều xắn tay vào hỗ trợ nhau. Điều này khiến tôi cảm thấy mình thực sự là một phần của tập thể chứ không chỉ là thực tập sinh.\n6. Chính sách / Quyền lợi thực tập Công ty có chính sách linh hoạt về thời gian làm việc khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ (internal training) là một điểm cộng lớn cho thấy công ty thực sự đầu tư vào con người.\nCâu hỏi bổ sung Điều gì làm bạn cảm thấy hài lòng nhất trong kỳ thực tập? Điều khiến tôi hài lòng nhất là đã tự tay triển khai thành công hệ thống Autonomous Incident Response sử dụng AWS Step Functions tích hợp trực tiếp SDK mà không cần qua Lambda trung gian. Cảm giác nhìn thấy hệ thống tự động phát hiện, cô lập và snapshot instance trong kịch bản thực tế mang lại cho tôi sự tự tin rất lớn về năng lực kỹ thuật của mình.\nBạn nghĩ công ty nên cải thiện điều gì cho các kỳ thực tập sau? Mặc dù hướng dẫn chuyên môn rất tốt, tôi nghĩ công ty nên có một buổi định hướng kỹ hơn về tác phong chuyên nghiệp và kỷ luật tổ chức ngay trong tuần đầu tiên. Điều này sẽ giúp các bạn thực tập sinh mới nắm bắt và tuân thủ nội quy, quy trình làm việc chuẩn chỉnh ngay từ đầu.\nNếu được giới thiệu cho bạn bè, bạn có khuyên họ nên thực tập tại đây không? Tại sao? Tôi chắc chắn sẽ giới thiệu. Đây là môi trường cho phép bạn \u0026ldquo;thực chiến\u0026rdquo; với hạ tầng Cloud thật thay vì chỉ ngồi quan sát. Sự hướng dẫn tận tình nhưng cũng đầy thử thách ở đây là điều kiện lý tưởng cho bất kỳ ai nghiêm túc muốn theo đuổi con đường DevOps hoặc Cloud Security.\nĐề xuất \u0026amp; Nguyện vọng Bạn có đề xuất gì để nâng cao trải nghiệm thực tập không? Tôi đề xuất nên có các buổi \u0026ldquo;Lightning Talk\u0026rdquo; hàng tuần hoặc 2 tuần/lần để thực tập sinh có cơ hội trình bày về những gì mình mới học được hoặc các lỗi (bug) thú vị đã xử lý. Việc này sẽ giúp cải thiện kỹ năng thuyết trình và chia sẻ kiến thức giữa các nhóm.\nBạn có muốn tiếp tục gắn bó với công ty trong tương lai không? Có, tôi rất mong muốn được tiếp tục đóng góp cho công ty, có thể ở vai trò thực tập sinh nâng cao hoặc Fresher, để phát triển sâu hơn các dự án tự động hóa mà tôi đang dang dở.\nÝ kiến khác (chia sẻ tự do): Tôi muốn gửi lời cảm ơn chân thành đến các Mentor và team FCJ vì sự kiên nhẫn và tâm huyết. Kỳ thực tập này không chỉ nâng cao kỹ năng code của tôi mà còn giúp tôi trưởng thành hơn rất nhiều trong tư duy hệ thống và trách nhiệm công việc.\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.7-isolate-ec2/","title":"Mã Isolate EC2","tags":[],"description":"","content":" import json import boto3 import os from botocore.exceptions import ClientError ISOLATION_SG_ID = os.getenv(\u0026#39;ISOLATION_SG_ID\u0026#39;) def lambda_handler(event, context): print(\u0026#34;=== ISOLATE EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) instance_id = event.get(\u0026#39;InstanceId\u0026#39;) region = event.get(\u0026#39;Region\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) if not instance_id or not ISOLATION_SG_ID: print(\u0026#34;[ERROR] Missing InstanceId or IsolationSGId in input. Cannot isolate.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: \u0026#34;Missing input data\u0026#34;} try: ec2 = boto3.client(\u0026#39;ec2\u0026#39;, region_name=region) response = ec2.describe_instances(InstanceIds=[instance_id]) instance = response[\u0026#39;Reservations\u0026#39;][0][\u0026#39;Instances\u0026#39;][0] current_sgs = [sg[\u0026#39;GroupId\u0026#39;] for sg in instance.get(\u0026#39;SecurityGroups\u0026#39;, [])] if ISOLATION_SG_ID in current_sgs: print(f\u0026#34;[INFO] {instance_id} already has isolation SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;already_isolated\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: None } print(f\u0026#34;[ACTION] Isolating {instance_id} in {region} with SG {ISOLATION_SG_ID}\u0026#34;) ec2.modify_instance_attribute( InstanceId=instance_id, Groups=[ISOLATION_SG_ID] ) print(f\u0026#34;[SUCCESS] {instance_id} isolated with SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;isolation_complete\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: ISOLATION_SG_ID } except ClientError as e: error_code = e.response.get(\u0026#39;Error\u0026#39;, {}).get(\u0026#39;Code\u0026#39;) print(f\u0026#34;[ERROR] Isolation FAILED for {instance_id} ({error_code}): {str(e)}\u0026#34;) return { \u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: str(e) } except Exception as e: print(f\u0026#34;[ERROR] Isolation FAILED (General) for {instance_id}: {str(e)}\u0026#34;) raise e "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.7-dashboard-setup/","title":"Thiết lập Dashboard","tags":[],"description":"","content":"Hướng dẫn này sẽ chỉ cho bạn cách thiết lập security dashboard. Security dashboard sẽ sử dụng S3 để chứa các file và thư mục web, Lambda để truy vấn dữ liệu bằng Athena, API Gateway để định tuyến api tới Lambda và Cloudfront để caching và truy cập web bằng URL của nó.\nNội dung Thiết lập S3 Thiết lập Lambda Thiết lập API Gateway Thiết lập Cloudfront Thiết lập Cognito "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.8-week8/","title":"Nhật ký công việc Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8: Ôn tập kiến thức AWS. Hoàn thành bài thi giữa kỳ FCJ. Thúc đẩy dự án Ứng phó sự cố bằng cách triển khai cơ chế cô lập và nghiên cứu cải tiến quy trình điều phối. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Xem lại các video học tập của FCJ Bootcamp\n- Hoàn thành bài kiểm tra AWS Cloud Essentials - Tìm hiểu sâu về các dịch vụ AWS đã học và so sánh các dịch vụ tương tự nhau - Xem qua một số AWS Well-Architected Lab để hiểu rõ hơn về các trụ cột chính - Tạo thành công Lambda function để cô lập EC2 và hiện đang chờ kiểm thử - Kiến trúc AWS: + Nghiên cứu cách tích hợp AWS Step Functions để tự động hóa, thay vì chỉ sử dụng một Lambda cho tất cả các hành động IR 27/10/2025 27/10/2025 AWS Cloud Essentials Quiz AWS Well Architected Lab T3 - Tạo 500 Flashcard AWS cùng các thành viên trong nhóm để học tập 28/10/2025 28/10/2025 https://cloudjourney.awsstudygroup.com/ T4 - Ôn thi giữa kỳ 29/10/2025 29/10/2025 Introduction to Research for Essay Writing T5 - Luyện tập sử dụng ghi chú AWS Certified Cloud Practitioner của học viên khác: Làm 5 bài kiểm tra thử\n- Luyện tập câu hỏi AWS Certified Solutions Architect Associate: Làm 40 câu hỏi 30/10/2025 30/10/2025 AWS Certified Cloud Practitioner notes AWS Certified Solutions Architect Associate practice T6 - Tham gia kỳ thi giữa kỳ FCJ 31/10/2025 31/10/2025 Thành tựu Tuần 8: Kỳ thi giữa kỳ FCJ:\nHoàn thành việc luyện tập kỹ càng bằng cách làm 5 bài test thử AWS Certified Cloud Practitioner và trả lời 40 câu hỏi luyện tập AWS Certified Solutions Architect Associate. Phối hợp với thành viên nhóm tạo 500 Flashcard AWS để tập trung học tập. Hoàn thành bài kiểm tra AWS Cloud Essentials và xem lại video học tập FCJ Bootcamp. Tham gia thành công kỳ thi giữa kỳ FCJ và đạt điểm số 320/650. Ôn tập các dịch vụ AWS chính và AWS Well-Architected Labs để hiểu các trụ cột cốt lõi. Nghiên cứu Kiến trúc Workshop:\nNghiên cứu tích hợp kiến trúc AWS Step Functions để điều phối các hành động Ứng phó sự cố (Incident Response - IR), thay thế cho việc dùng một Lambda function duy nhất. Phát triển \u0026amp; Phân tích Dịch vụ:\nTự động hóa Cô lập: Lập trình và triển khai thành công Lambda function chuyên biệt để cô lập EC2 instance, chuyển dự án từ giai đoạn nghiên cứu sang triển khai thực tế. Ra quyết định về Kiến trúc: Thực hiện so sánh chuyên sâu giữa AWS Lambda và AWS Step Functions để xác định chiến lược điều phối tối ưu cho quy trình Ứng phó sự cố. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.8-verify-setup/","title":"Kiểm tra thiết lập","tags":[],"description":"","content":"Sau tất cả các giai đoạn thiết lập, vui lòng tham khảo checklist để đảm bảo việc tạo tài nguyên đã hoàn tất.\nXác minh thiết lập Checklist xác minh hoàn thành:\nIncident Response and Forensics:\n✅ S3 Buckets: Tất cả 5 buckets đã được tạo với versioning/encryption ✅ IAM Roles: Tất cả 17 roles với đúng policies ✅ CloudTrail: Logging đã được bật ✅ GuardDuty: Đã bật với S3 export ✅ VPC Flow Logs: Đang hoạt động (Active) ✅ Lambda Functions: Tất cả 9 functions đã deploy ✅ Firehose Streams: Tất cả 3 streams đang hoạt động ✅ Glue Tables: Tất cả 4 tables đã được tạo ✅ S3 Events: Tất cả 4 triggers đã được cấu hình ✅ SNS Topic: Đã tạo với subscription ✅ Step Functions: Đang hoạt động (Active) ✅ EventBridge Rule: Đã bật với 2 targets Security Dashboard:\n✅ S3 Buckets: Bucket đã được tạo với file dashboard được lưu trữ và bật hosting ✅ Query Lambda: Lambda đã được tạo với các roles thích hợp ✅ API Gateway: API Gateway đã được tạo với đúng API và tài nguyên ✅ CloudFront: Distribution đã được tạo với API và S3 origins đã cấu hình ✅ Cognito: Đã liên kết với CloudFront distribution và tạo user trong user pool Kiểm tra đầu cuối (End-to-End Test)\nTạo mẫu các phát hiện GuardDuty: 1.1 GuardDuty Console → Settings → Generate sample findings (200+ findings) hoặc 1.2 Kích hoạt một finding đơn lẻ qua CloudShell (Detector Id nằm trong GuardDuty Console → Settings ) aws guardduty create-sample-findings --detector-id [$dectector-id] --finding-types \u0026#34;Recon:EC2/PortProbeUnprotectedPort\u0026#34; Giám sát workflow: Kiểm tra EventBridge, SNS, Step Functions, Lambda logs Xác minh cảnh báo: Kiểm tra email và Slack Truy vấn dữ liệu trong Athena: "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.8-quarantine-iam/","title":"Mã Quarantine IAM","tags":[],"description":"","content":" import json import boto3 import os QUARANTINE_POLICY_ARN = os.environ.get(\u0026#34;QUARANTINE_POLICY_ARN\u0026#34;) def lambda_handler(event, context): print(\u0026#34;=== EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) try: finding = event.get(\u0026#39;detail\u0026#39;, {}) user_name = ( finding.get(\u0026#39;resource\u0026#39;, {}) .get(\u0026#39;accessKeyDetails\u0026#39;, {}) .get(\u0026#39;userName\u0026#39;) ) if not user_name: print(\u0026#34;[WARNING] No IAM user found in this finding. Skipping.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;no_user\u0026#34;} print(f\u0026#34;[ACTION] Quarantining IAM User \u0026#39;{user_name}\u0026#39;...\u0026#34;) iam = boto3.client(\u0026#39;iam\u0026#39;) # Kiểm tra nếu policy đã được gán (Check if policy is already attached) attached_policies = iam.list_attached_user_policies(UserName=user_name)[\u0026#39;AttachedPolicies\u0026#39;] policy_arns = [p[\u0026#39;PolicyArn\u0026#39;] for p in attached_policies] if QUARANTINE_POLICY_ARN in policy_arns: print(f\u0026#34;[INFO] Policy {QUARANTINE_POLICY_ARN} is already attached to user {user_name}.\u0026#34;) else: iam.attach_user_policy( UserName=user_name, PolicyArn=QUARANTINE_POLICY_ARN ) print(f\u0026#34;[SUCCESS] Policy attached. User {user_name} is now quarantined.\u0026#34;) except Exception as e: print(f\u0026#34;[ERROR] Failed to quarantine user: {str(e)}\u0026#34;) raise e return {\u0026#34;status\u0026#34;: \u0026#34;processed\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;iam_quarantined\u0026#34;} "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.9-week9/","title":"Nhật ký công việc Tuần 9","tags":[],"description":"","content":"Mục tiêu Tuần 9: Tiếp tục làm việc với workshop Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Chỉnh sửa Kiến trúc AWS:\n+ Loại bỏ AWS Detective + Cập nhật Step Function Workflow thay cho một AWS Lambda Function duy nhất + Thêm Custom Dashboard: Một trang web dashboard tĩnh tùy chỉnh được host trên S3 và dùng Athena để truy vấn từ data lake 03/11/2025 03/11/2025 T3 - Bắt đầu viết và xem xét các inline policy cho Lambda và User Role. 04/11/2025 04/11/2025 T4 - Họp nhóm: Báo cáo tiến độ:\n+ IR Workflow: Hoàn thành một nửa, function cô lập EC2 đã xong, chưa kiểm thử với các finding thực tế. 05/11/2025 05/11/2025 T5 - Họp nhóm\n- Nghiên cứu phương pháp ETL Pipeline: + Thay vì dùng Glue ELT Job, sử dụng custom Lambda ELT pipeline cho CloudTrail và CloudWatch logs + Lưu log thô vào một Raw Log S3 Bucket sau đó dùng ETL Lambda để xử lý dữ liệu và ghi vào Processed Data S3 để Crawl - Chỉnh sửa Kiến trúc AWS: Thêm nhóm mới: nhóm DATA PREP chứa Raw Log S3 Bucket và ETL Lambda - Môn học ở trường: 06/11/2025 06/11/2025 Advanced Writing T6 - Nghiên cứu Kinesis Data Firehose để thu thập log: Tốt cho việc sử dụng trong tương lai, không phù hợp với dự án hiện tại vì dữ liệu streaming thời gian thực là không cần thiết, sử dụng xử lý theo lô (batch processing) tốt hơn\n- Xây dựng thành công ETL Pipeline cho CloudTrail log: Được kích hoạt bởi việc tạo object trong CloudTrail Raw Log Bucket và định dạng lại log thô thành JSONL rồi lưu vào Processed S3 - Crawl và truy vấn thành công log đã xử lý để hiển thị các sự kiện CloudTrail 07/11/2025 07/11/2025 Thành tựu Tuần 9: Tinh chỉnh Kiến trúc \u0026amp; Ra quyết định:\nCập nhật cơ chế Ứng phó sự cố (IR) để sử dụng Step Functions Workflow thay vì một Lambda function duy nhất nhằm cải thiện khả năng điều phối. Giới thiệu chiến lược Custom Dashboard (trang web tĩnh host trên S3) sử dụng Athena để truy vấn data lake. Thực hiện phân tích so sánh giữa AWS Kinesis Data Firehose và xử lý theo lô; chọn phương pháp xử lý theo lô để tiết kiệm chi phí vì không yêu cầu streaming thời gian thực. Triển khai Data Pipeline:\nTạo nhóm kiến trúc DATA PREP mới, bao gồm Raw Log S3 Bucket và custom ETL Lambda. Xây dựng và triển khai serverless ETL Lambda pipeline để xử lý CloudTrail log, tự động kích hoạt khi có object mới được tạo trong Raw Log S3 Bucket. Crawl và truy vấn thành công CloudTrail log đã xử lý (định dạng JSONL) sử dụng AWS Glue và Athena. Cấu hình Bảo mật \u0026amp; IAM:\nBắt đầu quy trình thắt chặt bảo mật bằng cách viết và xem xét các inline policy cho Lambda function và User Role để đảm bảo quyền truy cập tối thiểu (least-privilege). Tiến độ Dự án:\nĐạt 50% tiến độ hoàn thành IR Step Functions Workflow, với EC2 quarantine function đã được code xong (chờ kiểm thử finding). "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.9-alert-dispatch/","title":"Mã Alert Dispatch","tags":[],"description":"","content":" import os import json import logging import urllib.request import boto3 from botocore.exceptions import ClientError import html # --- Telegram ENV --- # BOT_TOKEN = os.environ.get(\u0026#39;BOT_TOKEN\u0026#39;) # CHAT_ID = os.environ.get(\u0026#39;CHAT_ID\u0026#39;) # MESSAGE_THREAD_ID = os.environ.get(\u0026#39;MESSAGE_THREAD_ID\u0026#39;) # --- Slack ENV --- SLACK_WEBHOOK_URL = os.environ.get(\u0026#34;SLACK_WEBHOOK_URL\u0026#34;) # --- SES ENV --- SENDER_EMAIL = os.environ.get(\u0026#39;SENDER_EMAIL\u0026#39;) RECIPIENT_EMAIL = os.environ.get(\u0026#39;RECIPIENT_EMAIL\u0026#39;) # Can now be \u0026#34;a@b.com, c@d.com\u0026#34; AWS_REGION = os.environ.get(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) # --- Setup --- # TELEGRAM_URL = f\u0026#34;https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\u0026#34; if BOT_TOKEN else None logger = logging.getLogger() logger.setLevel(logging.INFO) # Initialize SES Client ses_client = boto3.client(\u0026#39;ses\u0026#39;, region_name=AWS_REGION) # ==================================================================== # SEND TO TELEGRAM # ==================================================================== # def send_to_telegram(finding, chat_id, thread_id): # logger.info(\u0026#34;Formatting message for Telegram...\u0026#34;) # ... (Code commented out, keeping as is or translating if needed, but it is commented out so skipping detailed translation for brevity unless enabled) # ==================================================================== # SEND TO SLACK # ==================================================================== def send_to_slack(finding): if not SLACK_WEBHOOK_URL: logger.warning(\u0026#34;Slack ENV missing. Skipping.\u0026#34;) return severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;🔴 CAO (HIGH)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;🟠 TRUNG BÌNH (MEDIUM)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;🔵 THẤP (LOW)\u0026#34; payload = { \u0026#34;text\u0026#34;: f\u0026#34;🚨 {sev} – {title}\u0026#34;, \u0026#34;attachments\u0026#34;: [{ \u0026#34;color\u0026#34;: color, \u0026#34;blocks\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;header\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;plain_text\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;🚨 GuardDuty Finding: {title}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mức độ (Severity):*\\n{sev}\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Khu vực (Region):*\\n{region}\u0026#34;} ]}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mô tả (Description):*\\n{description}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;divider\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;, \u0026#34;elements\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Tài khoản (Account):* `{account_id}`\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Loại (Type):* `{finding_type}`\u0026#34;} ]} ] }] } try: req = urllib.request.Request( SLACK_WEBHOOK_URL, data=json.dumps(payload).encode(\u0026#34;utf-8\u0026#34;), headers={\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;} ) with urllib.request.urlopen(req) as response: logger.info(\u0026#34;Slack response: \u0026#34; + response.read().decode(\u0026#34;utf-8\u0026#34;)) except Exception as e: logger.error(f\u0026#34;SLACK FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SES EMAIL (UPDATED FOR MULTIPLE RECIPIENTS) # ==================================================================== def send_to_ses(finding): if not SENDER_EMAIL or not RECIPIENT_EMAIL: logger.warning(\u0026#34;SES Env vars missing. Skipping Email.\u0026#34;) return logger.info(\u0026#34;Formatting message for SES Email...\u0026#34;) recipient_list = [email.strip() for email in RECIPIENT_EMAIL.split(\u0026#39;,\u0026#39;)] severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) finding_id = finding.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;HIGH (CAO)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;MEDIUM (TRUNG BÌNH)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;LOW (THẤP)\u0026#34; html_body = f\u0026#34;\u0026#34;\u0026#34; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }} .container {{ width: 100%; max-width: 600px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; }} .header {{ background-color: {color}; color: white; padding: 15px; text-align: center; }} .content {{ padding: 20px; }} .footer {{ background-color: #f4f4f4; padding: 10px; text-align: center; font-size: 12px; color: #666; }} .label {{ font-weight: bold; color: #555; }} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;🚨 Cảnh báo GuardDuty: {sev}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{title}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;{description}\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Tài khoản:\u0026lt;/span\u0026gt; {account_id}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Khu vực:\u0026lt;/span\u0026gt; {region}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Loại:\u0026lt;/span\u0026gt; {finding_type}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Phát hiện:\u0026lt;/span\u0026gt; {finding_id}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; Được tạo bởi AWS Lambda Alert Dispatch \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026#34;\u0026#34;\u0026#34; try: response = ses_client.send_email( Source=SENDER_EMAIL, Destination={\u0026#39;ToAddresses\u0026#39;: recipient_list}, # Uses the list now Message={ \u0026#39;Subject\u0026#39;: {\u0026#39;Data\u0026#39;: f\u0026#34;GuardDuty Alert [{sev}]: {title}\u0026#34;, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}, \u0026#39;Body\u0026#39;: {\u0026#39;Html\u0026#39;: {\u0026#39;Data\u0026#39;: html_body, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}} } ) logger.info(f\u0026#34;SES Email sent to {len(recipient_list)} recipients! MessageId: {response[\u0026#39;MessageId\u0026#39;]}\u0026#34;) except ClientError as e: logger.error(f\u0026#34;SES FAILED: {e.response[\u0026#39;Error\u0026#39;][\u0026#39;Message\u0026#39;]}\u0026#34;) # ==================================================================== # MAIN HANDLER # ==================================================================== def lambda_handler(event, context): logger.info(f\u0026#34;Event received: {json.dumps(event)}\u0026#34;) try: sns_message_raw = event[\u0026#34;Records\u0026#34;][0][\u0026#34;Sns\u0026#34;][\u0026#34;Message\u0026#34;] message_data = json.loads(sns_message_raw) # Normalization Logic finding = {} if \u0026#34;detail-type\u0026#34; in message_data and message_data[\u0026#34;detail-type\u0026#34;] == \u0026#34;GuardDuty Finding\u0026#34;: detail = message_data[\u0026#34;detail\u0026#34;] finding = { \u0026#34;severity\u0026#34;: detail.get(\u0026#34;severity\u0026#34;, 0), \u0026#34;title\u0026#34;: detail.get(\u0026#34;title\u0026#34;, \u0026#34;GuardDuty Finding\u0026#34;), \u0026#34;description\u0026#34;: detail.get(\u0026#34;description\u0026#34;, \u0026#34;No description provided\u0026#34;), \u0026#34;accountId\u0026#34;: detail.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: detail.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: detail.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;id\u0026#34;: detail.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) } elif \u0026#34;AlarmName\u0026#34; in message_data: state = message_data.get(\u0026#34;NewStateValue\u0026#34;) severity = 8 if state == \u0026#34;ALARM\u0026#34; else 0 finding = { \u0026#34;severity\u0026#34;: severity, \u0026#34;title\u0026#34;: f\u0026#34;CloudWatch Alarm: {message_data.get(\u0026#39;AlarmName\u0026#39;)}\u0026#34;, \u0026#34;description\u0026#34;: message_data.get(\u0026#34;NewStateReason\u0026#34;, \u0026#34;State change detected\u0026#34;), \u0026#34;accountId\u0026#34;: message_data.get(\u0026#34;AWSAccountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: message_data.get(\u0026#34;Region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: \u0026#34;CloudWatch Alarm\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } else: finding = { \u0026#34;severity\u0026#34;: 0, \u0026#34;title\u0026#34;: \u0026#34;Unknown Alert\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;Raw Payload: {json.dumps(message_data)}\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } except Exception as e: logger.error(f\u0026#34;FATAL: Could not parse incoming SNS event: {e}\u0026#34;) return {\u0026#34;statusCode\u0026#34;: 500} # --- Send Telegram --- # if BOT_TOKEN and CHAT_ID: # send_to_telegram(finding, CHAT_ID, MESSAGE_THREAD_ID) # --- Send Slack --- if SLACK_WEBHOOK_URL: send_to_slack(finding) # --- Send SES Email --- if SENDER_EMAIL and RECIPIENT_EMAIL: send_to_ses(finding) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;Dispatch complete\u0026#34;} "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.9-use-cdk/","title":"Sử dụng CDK","tags":[],"description":"","content":"Tổng quan Chúng tôi đã cung cấp CDK stack để tạo toàn bộ cơ sở hạ tầng cần thiết cho workshop này.\nĐể lấy các file, vui lòng truy cập Github Link và clone hoặc tải xuống tất cả các file về một thư mục.\nHướng dẫn cài đặt Trước khi triển khai CDK stack, bạn phải cấu hình môi trường cục bộ của mình để xác thực với tài khoản AWS bằng AWS Command Line Interface (CLI).\nCài đặt AWS CLI.\nLấy Credentials: Bạn cần một Access Key ID và một Secret Access Key từ một IAM user có quyền deployment.\nChạy lệnh cấu hình: Mở terminal và chạy lệnh aws configure.\n$ aws configure Khi được nhắc, nhập credentials và các cài đặt mong muốn. Default region name nên khớp với region nơi bạn định triển khai stack (ví dụ: ap-southeast-1):\nPrompt Example Value AWS Access Key ID AKIA... AWS Secret Access Key wJalr... Default region name ap-southeast-1 Default output format json Xác minh cấu hình: Kiểm tra thiết lập bằng cách lấy user identity. Kết quả thành công xác nhận bạn đã xác thực.\n$ aws sts get-caller-identity Điều kiện tiên quyết Đảm bảo các công cụ và dịch vụ sau đã được cài đặt và cấu hình trên hệ thống của bạn:\nPython 3.8+ và pip: Cần thiết để thực thi ứng dụng CDK và build Lambda function assets. Node.js và npm: Cần thiết để chạy AWS CDK CLI và build React dashboard. AWS CDK Toolkit: Cài đặt CDK CLI global: $ npm install -g aws-cdk Thiết lập môi trường Python Định nghĩa cơ sở hạ tầng được viết bằng Python. Một virtual environment chuyên dụng được sử dụng để quản lý các dependencies của dự án.\nTạo Virtual Environment:\n$ python -m venv .venv Kích hoạt Virtual Environment:\nOperating System Command macOS / Linux source .venv/bin/activate Windows (Command Prompt) .venv\\Scripts\\activate.bat Windows (PowerShell) .venv\\Scripts\\Activate.ps1 Cài đặt Python Dependencies:\n$ pip install -r requirements.txt Bước build dashboard Tại vị trí thư mục dự án, kiểm tra bên trong thư mục react. Nếu thư mục dist đã tồn tại, bạn không cần phải build. Nếu chưa, vui lòng làm theo các bước dưới đây. Nếu bạn đang dùng cmd sử dụng lệnh này để di chuyển vào thư mục react:\n$ cd react Và sử dụng lệnh này để liệt kê tất cả nội dung trong react:\n$ ls Điều kiện tiên quyết Đảm bảo bạn đã cài đặt Node.js và npm. Bạn có thể kiểm tra phiên bản hiện tại bằng cách chạy:\n$ npm --version Nếu lệnh không được nhận diện, vui lòng tải và cài đặt Node.js từ nodejs.org\nCài đặt dependencies Chạy lệnh sau để cài đặt tất cả các thư viện cần thiết:\n$ npm install Build Project Sau khi cài đặt hoàn tất, chạy lệnh build:\n$ npm run build Sau khi hoàn tất, một thư mục dist sẽ được tạo ra chứa index.html và thư mục assets.\nCấu hình Deployment Context Stack sử dụng các biến context (context variables). Các biến này được đọc từ cdk.context.json hoặc cung cấp qua cờ (flags) dòng lệnh.\nVariable Name Description Required if functionality is desired Default Value (in cdk.context.json) vpc_ids Danh sách các VPC IDs cho Flow Logs và DNS Query Logging. Có [] alert_email Danh sách các địa chỉ email cho thông báo cảnh báo (yêu cầu SES). Có [] sender_email Địa chỉ email người gửi SES đã xác thực. Có (nếu alert_email được thiết lập) \u0026quot;\u0026quot; slack_webhook_url Slack webhook URL để gửi cảnh báo. Không \u0026quot;\u0026quot; Ví dụ\n{ \u0026#34;vpc_ids\u0026#34;: [ \u0026#34;vpc-a1b2c3d4e5f6g7h8i\u0026#34; ], \u0026#34;alert_email\u0026#34;: [ \u0026#34;admin@example.com\u0026#34; ], \u0026#34;sender_email\u0026#34;: \u0026#34;alerts@your-domain.com\u0026#34;, \u0026#34;slack_webhook_url\u0026#34;: \u0026#34;\u0026#34; } Triển khai Stacks (Deploy) Trước khi xử lý tiếp, nếu đang ở trong thư mục /react, nhập lệnh này để quay lại thư mục chính:\n$ cd.. CDK Bootstrapping: Nếu bạn chưa từng sử dụng AWS CDK trong tài khoản AWS và region mục tiêu trước đây, chạy lệnh bootstrap một lần để cung cấp các tài nguyên cần thiết (ví dụ: S3 deployment bucket).\n$ cdk bootstrap (Tùy chọn) Synthesize và Diff: Xem lại các thay đổi CloudFormation được đề xuất trước khi deployment:\n$ cdk synth --all $ cdk diff --all Execute Deployment: Chạy lệnh deployment và phê duyệt bất kỳ thay đổi bảo mật IAM nào được yêu cầu khi được nhắc.\n$ cdk deploy --all Việc deployment hoàn tất khi CDK CLI báo cáo thành công cho stack: AwsIncidentResponseAutomationCdkStack và DashboardCdkStack\nLƯU Ý QUAN TRỌNG: Sau khi deployment hoàn tất, bạn nên xác minh email trong SES. Tạo một user trong Cognito để có thể đăng nhập vào Dashboard. Truy cập Security Group và xóa quy tắc outbound mặc định khỏi QuarantineSecurityGroup "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Nghiên cứu kỹ lưỡng và kiểm thử tất cả các thành phần để chuẩn bị tích hợp vào bản dựng cuối cùng của workshop. Các công việc cần triển khai trong tuần này\u0026mdash; title: \u0026ldquo;Nhật ký công việc Tuần 10\u0026rdquo; date: \u0026ldquo;2025-11-10\u0026rdquo; weight: 2 chapter: false pre: \u0026quot; 1.10. \u0026quot; Mục tiêu Tuần 10: Nghiên cứu và kiểm thử toàn diện tất cả các thành phần để chuẩn bị tích hợp vào bản build cuối cùng của workshop. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Kiểm thử cô lập EC2 với sự kiện giả lập (mock events) và phát hiện thực tế từ GuardDuty (đã debug và sửa các hàm xử lý dữ liệu để phù hợp với cấu trúc JSON của phát hiện thực tế).\n- Cập nhật đề xuất:\n+ Bao gồm Kiến trúc AWS và các Dịch vụ đã cập nhật.\n+ Tính toán lại ước tính chi phí. 10/11/2025 10/11/2025 T3 - Kiểm thử cô lập IAM (quarantine) và hiện đang giải quyết các vấn đề xử lý dữ liệu tương tự.\n- Xây dựng thành công tất cả các policy và role với quyền truy cập tối thiểu (least-privilege). 11/11/2025 11/11/2025 T4 - Xây dựng thành công thiết kế Step Functions bao gồm các trạng thái: Kiểm tra loại phát hiện (Check Finding Types), Cô lập EC2, Cách ly người dùng (Quarantine Users), và Không cần hành động (No Action Needed). 12/11/2025 12/11/2025 T5 - Kiểm thử thành công các Lambda function với cả sự kiện giả lập và một số phát hiện thực tế sử dụng các script mới.\n- Hiện đang hướng tới việc xây dựng các script có khả năng phân tích mọi loại phát hiện.\n- Nghiên cứu cách tối ưu hóa cấu trúc Lambda -\u0026gt; EventBridge -\u0026gt; Step Functions. 13/11/2025 13/11/2025 Thành tựu Tuần 10: Điều phối Ứng phó sự cố:\nThiết kế và triển khai thành công quy trình AWS Step Functions, với các trạng thái logic riêng biệt cho \u0026ldquo;Check Finding Types,\u0026rdquo; \u0026ldquo;Isolate EC2,\u0026rdquo; \u0026ldquo;Quarantine IAM User,\u0026rdquo; và \u0026ldquo;No Action Needed.\u0026rdquo; Kiểm thử \u0026amp; Debug thực tế:\nChuyển từ kiểm thử với sự kiện giả lập sang xử lý các phát hiện thực tế từ Amazon GuardDuty. Debug và tinh chỉnh thành công logic phân tích dữ liệu của Lambda để diễn giải chính xác cấu trúc JSON phức tạp của các cảnh báo GuardDuty thực tế cho cả kịch bản EC2 và IAM. Triển khai Bảo mật \u0026amp; IAM:\nKiến trúc và triển khai thành công tất cả các IAM role và inline policy cần thiết cho các function cách ly, tuân thủ nghiêm ngặt nguyên tắc quyền truy cập tối thiểu (least-privilege) để đảm bảo an toàn. Tài liệu Dự án \u0026amp; Tối ưu hóa:\nCập nhật đề xuất dự án để phản ánh việc chuyển đổi sang kiến trúc Step Functions và cung cấp các tính toán lại cho chi phí đám mây dự kiến. Bắt đầu nghiên cứu tối ưu hóa mô hình tích hợp giữa AWS EventBridge và Step Functions để đảm bảo kích hoạt tự động nhanh hơn và tin cậy hơn. Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.10-cleanup/","title":"Dọn dẹp","tags":[],"description":"","content":"Chúc mừng bạn đã hoàn thành workshop này! Trong workshop này, bạn đã tạo một Hệ thống Phản hồi Sự cố và Điều tra số Tự động và làm quen với Lambda, Step Functions, EventBridge, Glue, Athena, CloudFront, Cognito, S3 Buckets\nHướng dẫn dọn dẹp: Hướng dẫn dọn dẹp cho thiết lập thủ công Hướng dẫn dọn dẹp cho thiết lập CDK "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.10-cleanup/5.10.1-manual-cleanup/","title":"Dọn dẹp thủ công","tags":[],"description":"","content":"Clean up (Thiết lập cơ sở hạ tầng thủ công) Giai đoạn 1: Dọn dẹp Automation và Monitoring Mục tiêu ở đây là dừng tất cả các tiến trình đang hoạt động và xóa các tài nguyên monitoring và automation cốt lõi (EventBridge, Step Functions, SNS, GuardDuty, Flow Logs, CloudTrail).\n1. Xóa Incident Response Automation 1.1 Xóa EventBridge Rule\nVào EventBridge Console → Rules. Chọn rule: IncidentResponseAlert. Nhấn \u0026ldquo;Delete\u0026rdquo;. 1.2 Xóa Step Functions State Machine\nVào Step Functions Console → State Machines. Chọn State Machine: IncidentResponseStepFunctions. Nhấn \u0026ldquo;Delete\u0026rdquo;. 1.3 Xóa SNS Topic và Subscription\nVào SNS Console → Topics → IncidentResponseAlerts. Đầu tiên, xóa subscription liên kết với ir-alert-dispatch. Sau đó, xóa chính topic bằng cách nhấn \u0026ldquo;Delete topic\u0026rdquo;. 1.4 Xóa GuardDuty Detector\nVào GuardDuty Console → Settings → General. Nhấn \u0026ldquo;Suspend\u0026rdquo; để dừng xử lý, sau đó nhấn \u0026ldquo;Disable GuardDuty\u0026rdquo; (hoặc \u0026ldquo;Delete detector\u0026rdquo;). 1.5 Vô hiệu hóa VPC Flow Logs\nVào VPC Console → VPC Flow Logs. Chọn flow log đã tạo (liên kết với YOUR_VPC_ID). Nhấn \u0026ldquo;Delete flow log\u0026rdquo;. 1.6 Xóa CloudTrail Trail\nVào CloudTrail Console → Trails. Chọn trail: incident-responses-cloudtrail-ACCOUNT_ID-REGION. Nhấn \u0026ldquo;Delete\u0026rdquo;. Giai đoạn 2: Dọn dẹp Lambda và Compute 2. Xóa tất cả Lambda Functions (9 Functions) Vào Lambda Console và xóa các functions sau:\nincident-response-cloudtrail-etl incident-response-guardduty-etl cloudwatch-etl-lambda cloudwatch-eni-etl-lambda cloudwatch-export-lambda ir-parse-findings-lambda ir-isolate-ec2-lambda ir-quarantine-iam-lambda ir-alert-dispatch 3. Xóa Isolation Security Group Vào EC2 Console → Security Groups. Tìm và chọn Security Group: IR-Isolation-SG (sử dụng ID sg-XXXXXXX). Nhấn \u0026ldquo;Delete security group\u0026rdquo;. 4. Xóa CloudWatch Log Groups Vào CloudWatch Console → Log Groups và xóa:\nCentralized log group: /aws/incident-response/centralized-logs. Bất kỳ Lambda log groups nào liên quan đến 9 functions đã xóa (ví dụ: /aws/lambda/ir-parse-findings-lambda). Giai đoạn 3: Dọn dẹp Processing và Data Lake 5. Xóa Kinesis Data Firehose Streams Vào Kinesis Console → Delivery Streams và xóa:\ncloudtrail-firehose-stream vpc-dns-firehose-stream vpc-flow-firehose-stream 6. Xóa AWS Glue Tables và Database 6.1 Xóa Glue Tables\nVào Glue Console → Tables. Chọn và xóa: security_logs.processed_cloudtrail, security_logs.processed_guardduty, security_logs.vpc_logs, và security_logs.eni_flow_logs. 6.2 Xóa Glue Database\nVào Glue Console → Databases. Chọn database: security_logs và nhấn \u0026ldquo;Delete\u0026rdquo;. 7. Xóa IAM Roles và Policies 7.1 Xóa IAM Policies\nVào IAM Console → Policies. Xóa custom managed policy: IrQuarantineIAMPolicy. Lưu ý: Inline policies được tạo trong quá trình cài đặt sẽ tự động bị xóa khi role tương ứng bị xóa. 7.2 Xóa IAM Roles\nVào IAM Console → Roles. Xóa 17 roles sau: Lambda Execution Roles: CloudTrailETLLambdaServiceRole, GuardDutyETLLambdaServiceRole, CloudWatchETLLambdaServiceRole, CloudWatchENIETLLambdaServiceRole, CloudWatchExportLambdaServiceRole, ParseFindingsLambdaServiceRole, IsolateEC2LambdaServiceRole, QuarantineIAMLambdaServiceRole, AlertDispatchLambdaServiceRole. Service Roles: CloudTrailFirehoseRole, CloudWatchFirehoseRole, StepFunctionsRole, IncidentResponseStepFunctionsEventRole, FlowLogsIAMRole, GlueCloudWatchRole. Giai đoạn 4: Dọn dẹp S3 Bucket (Xóa dữ liệu) 8. Làm trống và Xóa S3 Buckets Đây là bước cuối cùng để đảm bảo tất cả các khoản phí lưu trữ được dừng lại.\nBucket Name Mục đích incident-response-log-list-bucket-ACCOUNT_ID-REGION Nguồn Log Chính (CloudTrail/GuardDuty/Exported CW) processed-cloudtrail-logs-ACCOUNT_ID-REGION Firehose Destination cho CloudTrail logs processed-cloudwatch-logs-ACCOUNT_ID-REGION Firehose Destination cho VPC DNS/Flow logs processed-guardduty-findings-ACCOUNT_ID-REGION ETL Destination cho GuardDuty logs athena-query-results-ACCOUNT_ID-REGION Lưu trữ kết quả truy vấn Athena Vào S3 Console. Đối với mỗi bucket trong 5 buckets: Nhấn vào tên bucket. Vào tab \u0026ldquo;Objects\u0026rdquo;. Nhấn \u0026ldquo;Empty\u0026rdquo; để xóa tất cả dữ liệu. Bạn phải xác nhận việc xóa vĩnh viễn bằng cách gõ permanently delete. Quay lại danh sách S3 bucket, chọn bucket, và nhấn \u0026ldquo;Delete\u0026rdquo;. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/5.11.10-step-functions-state-machine-definition/","title":"Mã Định nghĩa Step Functions ASL","tags":[],"description":"","content":" { \u0026#34;Comment\u0026#34;: \u0026#34;Guardduty Incident Response Automation\u0026#34;, \u0026#34;StartAt\u0026#34;: \u0026#34;CheckFindingType\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;CheckFindingType\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Comment\u0026#34;: \u0026#34;Check if EC2 (Kiểm tra nếu là EC2)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;ParseFindings\u0026#34; }, { \u0026#34;Comment\u0026#34;: \u0026#34;Check if IAM (Kiểm tra nếu là IAM)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;AccessKey\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;Quarantine_IAM_User\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;NoActionNeeded\u0026#34; }, \u0026#34;ParseFindings\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34;, \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-parse-findings-lambda\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34;, \u0026#34;Lambda.TooManyRequestsException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 1, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2, \u0026#34;JitterStrategy\u0026#34;: \u0026#34;FULL\u0026#34; } ], \u0026#34;Next\u0026#34;: \u0026#34;Isolate_EC2_Instance\u0026#34; }, \u0026#34;Isolate_EC2_Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;Payload\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceIds[0]\u0026#34;, \u0026#34;Region.$\u0026#34;: \u0026#34;$.Region\u0026#34; } }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;Next\u0026#34;: \u0026#34;CheckIsolationStatus\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34; }, \u0026#34;CheckIsolationStatus\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.IsolationSG\u0026#34;, \u0026#34;IsNull\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;AlreadyIsolated\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;EnableTerminationProtection\u0026#34; }, \u0026#34;AlreadyIsolated\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; }, \u0026#34;EnableTerminationProtection\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:modifyInstanceAttribute\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceId\u0026#34;, \u0026#34;DisableApiTermination\u0026#34;: { \u0026#34;Value\u0026#34;: true } }, \u0026#34;Next\u0026#34;: \u0026#34;CreateQuarantineTag\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;CreateQuarantineTag\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createTags\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Resources.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;Security Group\u0026#34;, \u0026#34;Value.$\u0026#34;: \u0026#34;$.IsolationSG\u0026#34; } ] }, \u0026#34;Next\u0026#34;: \u0026#34;DescribeInstanceASG\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;DescribeInstanceASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:describeAutoScalingInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.ASGInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CheckIfASGExists\u0026#34; }, \u0026#34;CheckIfASGExists\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0]\u0026#34;, \u0026#34;IsPresent\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;UpdateASGConfiguration\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;UpdateASGConfiguration\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:updateAutoScalingGroup\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;MinSize\u0026#34;: 0 }, \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;Wait for ASG\u0026#34; }, \u0026#34;Wait for ASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 10, \u0026#34;Next\u0026#34;: \u0026#34;DetachFromASG\u0026#34; }, \u0026#34;DetachFromASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:detachInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;ShouldDecrementDesiredCapacity\u0026#34;: false }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;AutoScaling.ValidationException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 15, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;DescribeVolumes\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:describeVolumes\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Filters\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;attachment.instance-id\u0026#34;, \u0026#34;Values.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; } ] }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.VolumeInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshots\u0026#34; }, \u0026#34;CreateSnapshots\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Map\u0026#34;, \u0026#34;ItemsPath\u0026#34;: \u0026#34;$.VolumeInfo.Volumes\u0026#34;, \u0026#34;MaxConcurrency\u0026#34;: 1, \u0026#34;Iterator\u0026#34;: { \u0026#34;StartAt\u0026#34;: \u0026#34;Wait before calling CreateSnapshot API\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;Wait before calling CreateSnapshot API\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 15, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshot\u0026#34; }, \u0026#34;CreateSnapshot\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createSnapshot\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;VolumeId.$\u0026#34;: \u0026#34;$.VolumeId\u0026#34;, \u0026#34;Description.$\u0026#34;: \u0026#34;States.Format(\u0026#39;IR Snapshot for {} - {}\u0026#39;, $.Attachments[0].InstanceId, $.VolumeId)\u0026#34;, \u0026#34;TagSpecifications\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;snapshot\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; } ] } ] }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Ec2.RequestLimitExceeded\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 60, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true } } }, \u0026#34;End\u0026#34;: true }, \u0026#34;Quarantine_IAM_User\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.accessKeyDetails.userType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Root\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;RootUserDetected\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;ExecuteIAMQuarantine\u0026#34; }, \u0026#34;RootUserDetected\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;Cannot quarantine root user\u0026#34; }, \u0026#34;ExecuteIAMQuarantine\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-quarantine-iam-lambda\u0026#34;, \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true }, \u0026#34;NoActionNeeded\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; } } } "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.11-week11/","title":"Nhật ký công việc Tuần 11","tags":[],"description":"","content":"Mục tiêu Tuần 11: Tối ưu hóa kiến trúc về chi phí và độ tin cậy (tích hợp SQS \u0026amp; phân tích API S3). Nâng cao kiến thức về Bảo mật biên (WAF/CloudFront) và Cơ sở hạ tầng dưới dạng mã (IaC - CDK). Hoàn tất kiểm thử cô lập EC2 và tinh chỉnh dashboard tùy chỉnh. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T2 - Tham gia AWS Cloud Mastery Series #2: Có được cái nhìn sâu sắc về CDK và CloudFormation cho dự án và nhận được khuyến nghị từ mentor về chiến lược demo.\n- Viết bài tổng kết trải nghiệm sự kiện. 17/11/2025 17/11/2025 T3 - Tổng quan Dashboard: Cập nhật giao diện frontend để hiển thị các trường thông tin quan trọng hơn.\n- Chỉnh sửa Kiến trúc: + Loại bỏ Glue Crawler để giảm độ phức tạp.\n+ Thêm Amazon SQS vào giữa EventBridge và Step Functions để làm bộ đệm.\n- Phân tích Chi phí: Phát hiện các lệnh gọi API S3 GET quá mức từ Lambda xử lý CloudTrail; lên kế hoạch cập nhật giá.\n- Triển khai:\n+ Cô lập thành công EC2 trong môi trường kiểm thử.\n+ Nâng cấp CloudWatch ETL Lambda để xử lý log thông qua trigger mà không cần Crawler.\n- Sao lưu mã nguồn của tất cả các Lambda function. 18/11/2025 18/11/2025 T4 - Tham gia Workshop Bảo vệ Ứng dụng: AWS Perimeter Protection.\n+ Tìm hiểu sâu về cấu hình CloudFront và WAF.\n+ Xem xét gói giá (pricing tier) mới của CloudFront.\n- Học cách thiết lập API Gateway REST APIs để chuẩn bị tích hợp dashboard. 19/11/2025 19/11/2025 AWS Perimeter Protection T6 - Nghiên cứu AWS CDK: Cài đặt, sử dụng và cấu hình stack để chuẩn bị cho việc di chuyển sang IaC vào tuần tới. 21/11/2025 21/11/2025 AWS CDK Github AWS CDK Document Thành tựu Tuần 11: Tối ưu hóa Kiến trúc \u0026amp; Quản lý Chi phí:\nTinh chỉnh kiến trúc hướng sự kiện (event-driven) bằng cách tách biệt EventBridge và Step Functions sử dụng Amazon SQS để đảm bảo độ bền và tin cậy của tin nhắn.\nThực hiện phân tích chi phí quan trọng cho pipeline log, xác định cấu hình Lambda hiện tại đang tạo ra quá nhiều yêu cầu S3 GET và lập kế hoạch tối ưu hóa chi phí API.\nTinh gọn ETL Pipeline bằng cách loại bỏ AWS Glue Crawler và nâng cấp CloudWatch Lambda để hoạt động hoàn toàn dựa trên sự kiện kích hoạt từ S3 (S3 event triggers).\nHọc tập về Bảo mật \u0026amp; Mạng:\nCó kinh nghiệm thực tế về bảo vệ biên (perimeter protection) thông qua việc hoàn thành AWS Perimeter Protection Workshop, tập trung vào cấu hình AWS WAF (Web Application Firewall) và Amazon CloudFront. [Image of AWS CloudFront and WAF architecture]\nNghiên cứu API Gateway REST APIs để hỗ trợ việc tích hợp dashboard bảo mật tùy chỉnh trong tương lai.\nChuẩn bị cho Infrastructure as Code (IaC):\nTận dụng kiến thức từ AWS Cloud Mastery Series #2 để lên kế hoạch chuyển đổi dự án sang Infrastructure as Code. Hoàn thành nghiên cứu nền tảng về AWS CDK, bao gồm cài đặt, cấu hình stack và sử dụng construct để chuẩn bị cho giai đoạn triển khai. Triển khai Dự án:\nThực thi và xác minh thành công logic Cô lập EC2 trong môi trường kiểm thử thực tế. Cập nhật frontend của dashboard tùy chỉnh để hiển thị các trường thông tin bảo mật liên quan hơn. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/5-workshop/5.11-appendices/","title":"Phụ lục","tags":[],"description":"","content":"Phụ lục Lambda Codes: CloudTrail ETL GuardDuty ETL CloudWatch ETL CloudWatch ENI ETL CloudWatch Auto Export Parse Findings Isolate EC2 Instance Quarantine IAM Alert Dispatch Step Functions ASL Code: Step Functions ASL Code "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/1-worklog/1.12-week12/","title":"Nhật ký công việc Tuần 12","tags":[],"description":"","content":"Mục tiêu Tuần 12: Nâng cao quy trình Phản ứng sự cố với khả năng thu thập chứng cứ pháp y tự động (SSM). Debug và tinh chỉnh Lambda function và IAM role để đảm bảo hoạt động tin cậy. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo T3 - Cập nhật IR Step Functions: Thêm Map State để lặp qua các Instance bị cô lập và kích hoạt SSM Lambda cho các Instance đó để thu thập log phục vụ điều tra số (forensics).\n- CDK: Chuyển môi trường kiểm thử CDK sang một tài khoản chuyên biệt mới. 26/11/2025 26/11/2025 T6 - Họp nhóm:\n+ Phân công nhiệm vụ CDK cho các thành viên + Bắt đầu cập nhật đề xuất và sơ đồ kiến trúc - Sửa lỗi và cải tiến IR Step Functions: + Sửa lỗi EC2Isolate Lambda: Chỉnh lại phương thức parse dữ liệu + Cải thiện trạng thái: Thêm Parsing Lambda và sắp xếp lại các function + SSM bị lỗi do thiếu IAM: Đã thêm các role cần thiết vào SSM Forensics Function. 28/11/2025 30/11/2025 Thành tựu Tuần 12: Logic Phản ứng sự cố \u0026amp; Điều tra số:\nNâng cấp quy trình Step Functions bằng cách triển khai Map State, cho phép hệ thống lặp và xử lý đồng thời nhiều EC2 instance bị cô lập.\nTích hợp SSM (Systems Manager) Lambda để tự động kích hoạt thu thập log chứng cứ pháp y trên các instance bị xâm nhập.\nDebug \u0026amp; Tối ưu hóa:\nTinh chỉnh logic xử lý dữ liệu bằng cách sửa các lỗi parse JSON trong EC2Isolate Lambda. Giải quyết các vấn đề về quyền hạn bằng cách gán đúng IAM Role cho SSM Forensics function, đảm bảo function có quyền thực thi lệnh trên EC2 instance. Tối ưu hóa cấu trúc quy trình bằng cách sắp xếp lại các trạng thái và thêm một Parsing Lambda chuyên biệt để luồng dữ liệu tốt hơn. "},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://huyletran999.github.io/AWS-WorkLogS/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]